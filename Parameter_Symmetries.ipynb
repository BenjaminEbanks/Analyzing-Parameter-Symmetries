{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "authorship_tag": "ABX9TyOq/gVeDw+MK1Bk9xpmio5n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BenjaminEbanks/Analyzing-Parameter-Symmetries/blob/main/Parameter_Symmetries.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Utils**"
      ],
      "metadata": {
        "id": "BROii2Vxyc2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "\n",
        "def flatten_params(model):\n",
        "  return model.state_dict()\n",
        "\n",
        "def lerp(lam, t1, t2):\n",
        "  t3 = copy.deepcopy(t2)\n",
        "  for p in t1:\n",
        "    t3[p] = (1 - lam) * t1[p] + lam * t2[p]\n",
        "  return t3"
      ],
      "metadata": {
        "id": "c8uZJBV_xwgL"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_interp_acc(lambdas, train_acc_interp_naive, test_acc_interp_naive,\n",
        "                    train_acc_interp_clever, test_acc_interp_clever):\n",
        "  fig = plt.figure()\n",
        "  ax = fig.add_subplot(111)\n",
        "  ax.plot(lambdas,\n",
        "          train_acc_interp_naive,\n",
        "          linestyle=\"dashed\",\n",
        "          color=\"tab:blue\",\n",
        "          alpha=0.5,\n",
        "          linewidth=2,\n",
        "          label=\"Train, naïve interp.\")\n",
        "  ax.plot(lambdas,\n",
        "          test_acc_interp_naive,\n",
        "          linestyle=\"dashed\",\n",
        "          color=\"tab:orange\",\n",
        "          alpha=0.5,\n",
        "          linewidth=2,\n",
        "          label=\"Test, naïve interp.\")\n",
        "  ax.plot(lambdas,\n",
        "          train_acc_interp_clever,\n",
        "          linestyle=\"solid\",\n",
        "          color=\"tab:blue\",\n",
        "          linewidth=2,\n",
        "          label=\"Train, permuted interp.\")\n",
        "  ax.plot(lambdas,\n",
        "          test_acc_interp_clever,\n",
        "          linestyle=\"solid\",\n",
        "          color=\"tab:orange\",\n",
        "          linewidth=2,\n",
        "          label=\"Test, permuted interp.\")\n",
        "  ax.set_xlabel(\"$\\lambda$\")\n",
        "  ax.set_xticks([0, 1])\n",
        "  ax.set_xticklabels([\"Model $A$\", \"Model $B$\"])\n",
        "  ax.set_ylabel(\"Accuracy\")\n",
        "  # TODO label x=0 tick as \\theta_1, and x=1 tick as \\theta_2\n",
        "  ax.set_title(f\"Accuracy between the two models\")\n",
        "  ax.legend(loc=\"lower right\", framealpha=0.5)\n",
        "  fig.tight_layout()\n",
        "  return fig"
      ],
      "metadata": {
        "id": "fg7OpDIw9BMI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "from re import L\n",
        "from typing import NamedTuple\n",
        "import torch\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "\n",
        "\n",
        "\n",
        "class PermutationSpec(NamedTuple):\n",
        "  perm_to_axes: dict\n",
        "  axes_to_perm: dict\n",
        "\n",
        "def permutation_spec_from_axes_to_perm(axes_to_perm: dict) -> PermutationSpec:\n",
        "  perm_to_axes = defaultdict(list)\n",
        "  for wk, axis_perms in axes_to_perm.items():\n",
        "    for axis, perm in enumerate(axis_perms):\n",
        "      if perm is not None:\n",
        "        perm_to_axes[perm].append((wk, axis))\n",
        "  return PermutationSpec(perm_to_axes=dict(perm_to_axes), axes_to_perm=axes_to_perm)\n",
        "\n",
        "def mlp_permutation_spec(num_hidden_layers: int) -> PermutationSpec:\n",
        "  \"\"\"We assume that one permutation cannot appear in two axes of the same weight array.\"\"\"\n",
        "  assert num_hidden_layers >= 1\n",
        "  return permutation_spec_from_axes_to_perm({\n",
        "      \"layer0.weight\": (\"P_0\", None),\n",
        "      **{f\"layer{i}.weight\": ( f\"P_{i}\", f\"P_{i-1}\")\n",
        "         for i in range(1, num_hidden_layers)},\n",
        "      **{f\"layer{i}.bias\": (f\"P_{i}\", )\n",
        "         for i in range(num_hidden_layers)},\n",
        "      f\"layer{num_hidden_layers}.weight\": (None, f\"P_{num_hidden_layers-1}\"),\n",
        "      f\"layer{num_hidden_layers}.bias\": (None, ),\n",
        "  })\n",
        "\n",
        "\"\"\"\n",
        "def cnn_permutation_spec() -> PermutationSpec:\n",
        "  conv = lambda name, p_in, p_out: {f\"{name}.weight\": (p_out, p_in, None, None, )}\n",
        "  dense = lambda name, p_in, p_out, bias=True: {f\"{name}.weight\": (p_out, p_in), f\"{name}.bias\": (p_out, )} if bias else  {f\"{name}.weight\": (p_out, p_in)}\n",
        "\n",
        "  return permutation_spec_from_axes_to_perm({\n",
        "     **conv(\"conv1\", None, \"P_bg0\"),\n",
        "     **conv(\"conv2\", \"P_bg0\", \"P_bg1\"),\n",
        "     **dense(\"fc1\", \"P_bg1\", \"P_bg2\"),\n",
        "     **dense(\"fc2\", \"P_bg2\", None, False),\n",
        "  })\n",
        "\"\"\"\n",
        "\n",
        "def get_permuted_param(ps: PermutationSpec, perm, k: str, params, except_axis=None):\n",
        "  \"\"\"Get parameter `k` from `params`, with the permutations applied.\"\"\"\n",
        "  w = params[k]\n",
        "  for axis, p in enumerate(ps.axes_to_perm[k]):\n",
        "    # Skip the axis we're trying to permute.\n",
        "    if axis == except_axis:\n",
        "      continue\n",
        "\n",
        "    # None indicates that there is no permutation relevant to that axis.\n",
        "    if p is not None:\n",
        "        w = torch.index_select(w, axis, perm[p].int())\n",
        "\n",
        "  return w\n",
        "\n",
        "def apply_permutation(ps: PermutationSpec, perm, params):\n",
        "  \"\"\"Apply a `perm` to `params`.\"\"\"\n",
        "  return {k: get_permuted_param(ps, perm, k, params) for k in params.keys()}\n",
        "\n",
        "def weight_matching(ps: PermutationSpec, params_a, params_b, max_iter=100, init_perm=None):\n",
        "  \"\"\"Find a permutation of `params_b` to make them match `params_a`.\"\"\"\n",
        "  perm_sizes = {p: params_a[axes[0][0]].shape[axes[0][1]] for p, axes in ps.perm_to_axes.items()}\n",
        "\n",
        "  perm = {p: torch.arange(n) for p, n in perm_sizes.items()} if init_perm is None else init_perm\n",
        "  perm_names = list(perm.keys())\n",
        "\n",
        "  for iteration in range(max_iter):\n",
        "    progress = False\n",
        "    for p_ix in torch.randperm(len(perm_names)):\n",
        "      p = perm_names[p_ix]\n",
        "      n = perm_sizes[p]\n",
        "      A = torch.zeros((n, n))\n",
        "      for wk, axis in ps.perm_to_axes[p]:\n",
        "        w_a = params_a[wk]\n",
        "        w_b = get_permuted_param(ps, perm, wk, params_b, except_axis=axis)\n",
        "        w_a = torch.moveaxis(w_a, axis, 0).reshape((n, -1))\n",
        "        w_b = torch.moveaxis(w_b, axis, 0).reshape((n, -1))\n",
        "\n",
        "        A += w_a @ w_b.T\n",
        "\n",
        "      ri, ci = linear_sum_assignment(A.detach().numpy(), maximize=True)\n",
        "      assert (torch.tensor(ri) == torch.arange(len(ri))).all()\n",
        "      oldL = torch.einsum('ij,ij->i', A, torch.eye(n)[perm[p].long()]).sum()\n",
        "      newL = torch.einsum('ij,ij->i', A,torch.eye(n)[ci, :]).sum()\n",
        "      print(f\"{iteration}/{p}: {newL - oldL}\")\n",
        "      progress = progress or newL > oldL + 1e-12\n",
        "\n",
        "      perm[p] = torch.Tensor(ci)\n",
        "\n",
        "    if not progress:\n",
        "      break\n",
        "\n",
        "  return perm\n",
        "\n",
        "# def test_weight_matching():\n",
        "#   \"\"\"If we just have a single hidden layer then it should converge after just one step.\"\"\"\n",
        "#   ps = mlp_permutation_spec(num_hidden_layers=3)\n",
        "#   print(ps.axes_to_perm)\n",
        "#   rng = torch.Generator()\n",
        "#   rng.manual_seed(13)\n",
        "#   num_hidden = 10\n",
        "#   shapes = {\n",
        "#       \"layer0.weight\": (2, num_hidden),\n",
        "#       \"layer0.bias\": (num_hidden, ),\n",
        "#       \"layer1.weight\": (num_hidden, 3),\n",
        "#       \"layer1.bias\": (3, )\n",
        "#   }\n",
        "\n",
        "#   params_a = {k: torch.randn(shape, generator=rng) for k, shape in shapes.items()}\n",
        "#   params_b = {k: torch.randn(shape, generator=rng) for k, shape in shapes.items()}\n",
        "#   perm = weight_matching(ps, params_a, params_b)  # Removed rng from the arguments\n",
        "#   print(perm)\n",
        "\n",
        "# test_weight_matching()"
      ],
      "metadata": {
        "id": "4-zpjBgb0mJA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "def train(args, model, device, train_loader, optimizer, epoch, softmax=False):\n",
        "    model.train()\n",
        "    correct = 0\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        if softmax:\n",
        "            output = F.log_softmax(output, dim=1)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % args.log_interval == 0:\n",
        "            acc = 100. * correct / len(train_loader.dataset)\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "    acc = 100. * correct / len(train_loader.dataset)\n",
        "    print('Train Accuracy: ({:.0f}%) '.format(acc))\n",
        "\n",
        "\n",
        "def test(model, device, test_loader, softmax=False):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            if softmax:\n",
        "                output = F.log_softmax(output, dim=1)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    acc = 100. * correct / len(test_loader.dataset)\n",
        "    print('\\nAverage loss: {:.4f}, Accuracy: ({:.0f}%)\\n'.format(\n",
        "        test_loss, acc))\n",
        "    return test_loss, acc"
      ],
      "metadata": {
        "id": "g9z0I2dVyVmN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0vhvf97xhqg"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "class MLP(nn.Module):\n",
        "  def __init__(self, input=28*28):\n",
        "\n",
        "    super().__init__()\n",
        "    self.input = input\n",
        "    self.layer0 = nn.Linear(input, 512)\n",
        "    self.layer1 = nn.Linear(512, 512)\n",
        "    self.layer2 = nn.Linear(512, 512)\n",
        "    self.layer3 = nn.Linear(512, 256)\n",
        "    self.layer4 = nn.Linear(256, 10)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.view(-1, self.input)\n",
        "    x = nn.functional.relu(self.layer0(x))\n",
        "    x = nn.functional.relu(self.layer1(x))\n",
        "    x = nn.functional.relu(self.layer2(x))\n",
        "    x = nn.functional.relu(self.layer3(x))\n",
        "    x = self.layer4(x)\n",
        "\n",
        "    return nn.functional.log_softmax(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Args:\n",
        "    def __init__(self, seed, batch_size=512, epochs=50, lr=0.001, log_interval=10):\n",
        "        self.seed = seed\n",
        "        self.batch_size = batch_size\n",
        "        self.epochs = epochs\n",
        "        self.lr = lr\n",
        "        self.log_interval = log_interval\n",
        "\n",
        "args_1 = Args(seed=1)\n",
        "args_2 = Args(seed=2)\n",
        "args_3 = Args(seed=3)\n",
        "args_4 = Args(seed=4)"
      ],
      "metadata": {
        "id": "CzgIpJe5iskv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "\n",
        "# def main():\n",
        "  # print('hello')\n",
        "  # parser = argparse.ArgumentParser()\n",
        "  # parser.add_argument('--seed', type=int, default=1)\n",
        "  # parser.add_argument('--batch_size', type=int, default=512)\n",
        "  # parser.add_argument('--epochs', type=int, default=50)\n",
        "  # parser.add_argument(\"--lr\", type=float, required=True)\n",
        "  # parser.add_argument('--log-interval', type=int, default=10, metavar='N',help='how many batches to wait before logging training status')\n",
        "  # args = parser.parse_args()\n",
        "\n",
        "  # # Get data\n",
        "  # print(args)\n",
        "  # args = parser.parse_args()\n",
        "\n",
        "# class Args:\n",
        "#   seed = 1\n",
        "#   batch_size = 512\n",
        "#   epochs = 50\n",
        "#   lr = 0.001  # Set your desired learning rate here\n",
        "#   log_interval = 10\n",
        "\n",
        "# args_2 = Args()\n",
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "torch.manual_seed(args_2.seed)\n",
        "\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "train_kwargs = {'batch_size': args_2.batch_size}\n",
        "test_kwargs = {'batch_size': args_2.batch_size}\n",
        "if use_cuda:\n",
        "    cuda_kwargs = {'num_workers': 1,\n",
        "                    'pin_memory': True,\n",
        "                    'shuffle': True}\n",
        "    train_kwargs.update(cuda_kwargs)\n",
        "    test_kwargs.update(cuda_kwargs)\n",
        "\n",
        "transform=transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "dataset1 = datasets.MNIST('../data', train=True, download=True,\n",
        "                    transform=transform)\n",
        "dataset2 = datasets.MNIST('../data', train=False,\n",
        "                    transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n",
        "\n",
        "model_b = MLP().to(device)\n",
        "optimizer = optim.Adam(model_b.parameters(), lr=args_2.lr)\n",
        "\n",
        "for epoch in range(1, args_2.epochs + 1):\n",
        "    train(args_2, model_b, device, train_loader, optimizer, epoch)\n",
        "    test(model_b, device, test_loader)\n",
        "\n",
        "torch.save(model_b.state_dict(), f\"mnist_mlp_{str(args_2.seed)}.pt\")\n",
        "\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#   main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4RFP3cCUSgM",
        "outputId": "2533894a-e3e0-4149-f6c9-ea545f229542"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-35-3775b565d8d0>:22: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return nn.functional.log_softmax(x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.304119\n",
            "Train Epoch: 1 [5120/60000 (8%)]\tLoss: 0.861866\n",
            "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.464231\n",
            "Train Epoch: 1 [15360/60000 (25%)]\tLoss: 0.412749\n",
            "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.406430\n",
            "Train Epoch: 1 [25600/60000 (42%)]\tLoss: 0.234064\n",
            "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.278593\n",
            "Train Epoch: 1 [35840/60000 (59%)]\tLoss: 0.243973\n",
            "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.301197\n",
            "Train Epoch: 1 [46080/60000 (76%)]\tLoss: 0.244700\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.138244\n",
            "Train Epoch: 1 [56320/60000 (93%)]\tLoss: 0.147130\n",
            "Train Accuracy: (87%) \n",
            "\n",
            "Average loss: 0.1929, Accuracy: (94%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.184348\n",
            "Train Epoch: 2 [5120/60000 (8%)]\tLoss: 0.148041\n",
            "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.135490\n",
            "Train Epoch: 2 [15360/60000 (25%)]\tLoss: 0.162000\n",
            "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.212680\n",
            "Train Epoch: 2 [25600/60000 (42%)]\tLoss: 0.114324\n",
            "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.125971\n",
            "Train Epoch: 2 [35840/60000 (59%)]\tLoss: 0.124478\n",
            "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.171876\n",
            "Train Epoch: 2 [46080/60000 (76%)]\tLoss: 0.143732\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.083708\n",
            "Train Epoch: 2 [56320/60000 (93%)]\tLoss: 0.075713\n",
            "Train Accuracy: (96%) \n",
            "\n",
            "Average loss: 0.1072, Accuracy: (96%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.117367\n",
            "Train Epoch: 3 [5120/60000 (8%)]\tLoss: 0.088752\n",
            "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.063999\n",
            "Train Epoch: 3 [15360/60000 (25%)]\tLoss: 0.097317\n",
            "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.135725\n",
            "Train Epoch: 3 [25600/60000 (42%)]\tLoss: 0.063495\n",
            "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.103460\n",
            "Train Epoch: 3 [35840/60000 (59%)]\tLoss: 0.077055\n",
            "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.102800\n",
            "Train Epoch: 3 [46080/60000 (76%)]\tLoss: 0.099466\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.060651\n",
            "Train Epoch: 3 [56320/60000 (93%)]\tLoss: 0.061687\n",
            "Train Accuracy: (97%) \n",
            "\n",
            "Average loss: 0.0970, Accuracy: (97%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.103884\n",
            "Train Epoch: 4 [5120/60000 (8%)]\tLoss: 0.066694\n",
            "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.042319\n",
            "Train Epoch: 4 [15360/60000 (25%)]\tLoss: 0.085295\n",
            "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.100367\n",
            "Train Epoch: 4 [25600/60000 (42%)]\tLoss: 0.043943\n",
            "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.101969\n",
            "Train Epoch: 4 [35840/60000 (59%)]\tLoss: 0.059090\n",
            "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.101251\n",
            "Train Epoch: 4 [46080/60000 (76%)]\tLoss: 0.075515\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.047534\n",
            "Train Epoch: 4 [56320/60000 (93%)]\tLoss: 0.057377\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.0925, Accuracy: (97%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.093143\n",
            "Train Epoch: 5 [5120/60000 (8%)]\tLoss: 0.044690\n",
            "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.062110\n",
            "Train Epoch: 5 [15360/60000 (25%)]\tLoss: 0.052699\n",
            "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.057843\n",
            "Train Epoch: 5 [25600/60000 (42%)]\tLoss: 0.045234\n",
            "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.059706\n",
            "Train Epoch: 5 [35840/60000 (59%)]\tLoss: 0.055218\n",
            "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.065731\n",
            "Train Epoch: 5 [46080/60000 (76%)]\tLoss: 0.064426\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.064207\n",
            "Train Epoch: 5 [56320/60000 (93%)]\tLoss: 0.040679\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.1034, Accuracy: (97%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.072571\n",
            "Train Epoch: 6 [5120/60000 (8%)]\tLoss: 0.037923\n",
            "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.025794\n",
            "Train Epoch: 6 [15360/60000 (25%)]\tLoss: 0.028387\n",
            "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 0.032933\n",
            "Train Epoch: 6 [25600/60000 (42%)]\tLoss: 0.040164\n",
            "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.030585\n",
            "Train Epoch: 6 [35840/60000 (59%)]\tLoss: 0.029312\n",
            "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.069377\n",
            "Train Epoch: 6 [46080/60000 (76%)]\tLoss: 0.043252\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.045742\n",
            "Train Epoch: 6 [56320/60000 (93%)]\tLoss: 0.026361\n",
            "Train Accuracy: (99%) \n",
            "\n",
            "Average loss: 0.1007, Accuracy: (97%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.073042\n",
            "Train Epoch: 7 [5120/60000 (8%)]\tLoss: 0.032050\n",
            "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.016249\n",
            "Train Epoch: 7 [15360/60000 (25%)]\tLoss: 0.060530\n",
            "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.039643\n",
            "Train Epoch: 7 [25600/60000 (42%)]\tLoss: 0.034597\n",
            "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.055487\n",
            "Train Epoch: 7 [35840/60000 (59%)]\tLoss: 0.049179\n",
            "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 0.048492\n",
            "Train Epoch: 7 [46080/60000 (76%)]\tLoss: 0.033235\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.046746\n",
            "Train Epoch: 7 [56320/60000 (93%)]\tLoss: 0.017202\n",
            "Train Accuracy: (99%) \n",
            "\n",
            "Average loss: 0.1242, Accuracy: (97%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.101511\n",
            "Train Epoch: 8 [5120/60000 (8%)]\tLoss: 0.020736\n",
            "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.033923\n",
            "Train Epoch: 8 [15360/60000 (25%)]\tLoss: 0.009806\n",
            "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 0.024946\n",
            "Train Epoch: 8 [25600/60000 (42%)]\tLoss: 0.017618\n",
            "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.015888\n",
            "Train Epoch: 8 [35840/60000 (59%)]\tLoss: 0.064919\n",
            "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 0.042466\n",
            "Train Epoch: 8 [46080/60000 (76%)]\tLoss: 0.013560\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.028251\n",
            "Train Epoch: 8 [56320/60000 (93%)]\tLoss: 0.012438\n",
            "Train Accuracy: (99%) \n",
            "\n",
            "Average loss: 0.0959, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.033358\n",
            "Train Epoch: 9 [5120/60000 (8%)]\tLoss: 0.025391\n",
            "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 0.010265\n",
            "Train Epoch: 9 [15360/60000 (25%)]\tLoss: 0.014439\n",
            "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 0.020767\n",
            "Train Epoch: 9 [25600/60000 (42%)]\tLoss: 0.021763\n",
            "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 0.024185\n",
            "Train Epoch: 9 [35840/60000 (59%)]\tLoss: 0.012194\n",
            "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 0.054338\n",
            "Train Epoch: 9 [46080/60000 (76%)]\tLoss: 0.023664\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.019611\n",
            "Train Epoch: 9 [56320/60000 (93%)]\tLoss: 0.016543\n",
            "Train Accuracy: (99%) \n",
            "\n",
            "Average loss: 0.0870, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.031943\n",
            "Train Epoch: 10 [5120/60000 (8%)]\tLoss: 0.009152\n",
            "Train Epoch: 10 [10240/60000 (17%)]\tLoss: 0.015418\n",
            "Train Epoch: 10 [15360/60000 (25%)]\tLoss: 0.017465\n",
            "Train Epoch: 10 [20480/60000 (34%)]\tLoss: 0.044645\n",
            "Train Epoch: 10 [25600/60000 (42%)]\tLoss: 0.034210\n",
            "Train Epoch: 10 [30720/60000 (51%)]\tLoss: 0.023222\n",
            "Train Epoch: 10 [35840/60000 (59%)]\tLoss: 0.027177\n",
            "Train Epoch: 10 [40960/60000 (68%)]\tLoss: 0.024694\n",
            "Train Epoch: 10 [46080/60000 (76%)]\tLoss: 0.037601\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.048124\n",
            "Train Epoch: 10 [56320/60000 (93%)]\tLoss: 0.020127\n",
            "Train Accuracy: (99%) \n",
            "\n",
            "Average loss: 0.1001, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.055722\n",
            "Train Epoch: 11 [5120/60000 (8%)]\tLoss: 0.031060\n",
            "Train Epoch: 11 [10240/60000 (17%)]\tLoss: 0.016997\n",
            "Train Epoch: 11 [15360/60000 (25%)]\tLoss: 0.020230\n",
            "Train Epoch: 11 [20480/60000 (34%)]\tLoss: 0.010943\n",
            "Train Epoch: 11 [25600/60000 (42%)]\tLoss: 0.028917\n",
            "Train Epoch: 11 [30720/60000 (51%)]\tLoss: 0.023551\n",
            "Train Epoch: 11 [35840/60000 (59%)]\tLoss: 0.023617\n",
            "Train Epoch: 11 [40960/60000 (68%)]\tLoss: 0.012533\n",
            "Train Epoch: 11 [46080/60000 (76%)]\tLoss: 0.010464\n",
            "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.018570\n",
            "Train Epoch: 11 [56320/60000 (93%)]\tLoss: 0.010147\n",
            "Train Accuracy: (99%) \n",
            "\n",
            "Average loss: 0.0987, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.025926\n",
            "Train Epoch: 12 [5120/60000 (8%)]\tLoss: 0.019017\n",
            "Train Epoch: 12 [10240/60000 (17%)]\tLoss: 0.010386\n",
            "Train Epoch: 12 [15360/60000 (25%)]\tLoss: 0.005788\n",
            "Train Epoch: 12 [20480/60000 (34%)]\tLoss: 0.007760\n",
            "Train Epoch: 12 [25600/60000 (42%)]\tLoss: 0.004065\n",
            "Train Epoch: 12 [30720/60000 (51%)]\tLoss: 0.010454\n",
            "Train Epoch: 12 [35840/60000 (59%)]\tLoss: 0.016745\n",
            "Train Epoch: 12 [40960/60000 (68%)]\tLoss: 0.041013\n",
            "Train Epoch: 12 [46080/60000 (76%)]\tLoss: 0.028810\n",
            "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.016747\n",
            "Train Epoch: 12 [56320/60000 (93%)]\tLoss: 0.028091\n",
            "Train Accuracy: (99%) \n",
            "\n",
            "Average loss: 0.0774, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.021098\n",
            "Train Epoch: 13 [5120/60000 (8%)]\tLoss: 0.010490\n",
            "Train Epoch: 13 [10240/60000 (17%)]\tLoss: 0.008832\n",
            "Train Epoch: 13 [15360/60000 (25%)]\tLoss: 0.007140\n",
            "Train Epoch: 13 [20480/60000 (34%)]\tLoss: 0.008095\n",
            "Train Epoch: 13 [25600/60000 (42%)]\tLoss: 0.003299\n",
            "Train Epoch: 13 [30720/60000 (51%)]\tLoss: 0.021537\n",
            "Train Epoch: 13 [35840/60000 (59%)]\tLoss: 0.007517\n",
            "Train Epoch: 13 [40960/60000 (68%)]\tLoss: 0.005418\n",
            "Train Epoch: 13 [46080/60000 (76%)]\tLoss: 0.008190\n",
            "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.011776\n",
            "Train Epoch: 13 [56320/60000 (93%)]\tLoss: 0.014660\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.1112, Accuracy: (97%)\n",
            "\n",
            "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.017514\n",
            "Train Epoch: 14 [5120/60000 (8%)]\tLoss: 0.011033\n",
            "Train Epoch: 14 [10240/60000 (17%)]\tLoss: 0.002724\n",
            "Train Epoch: 14 [15360/60000 (25%)]\tLoss: 0.017144\n",
            "Train Epoch: 14 [20480/60000 (34%)]\tLoss: 0.010669\n",
            "Train Epoch: 14 [25600/60000 (42%)]\tLoss: 0.012887\n",
            "Train Epoch: 14 [30720/60000 (51%)]\tLoss: 0.006495\n",
            "Train Epoch: 14 [35840/60000 (59%)]\tLoss: 0.019469\n",
            "Train Epoch: 14 [40960/60000 (68%)]\tLoss: 0.010197\n",
            "Train Epoch: 14 [46080/60000 (76%)]\tLoss: 0.009833\n",
            "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.020044\n",
            "Train Epoch: 14 [56320/60000 (93%)]\tLoss: 0.010673\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.0938, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.025565\n",
            "Train Epoch: 15 [5120/60000 (8%)]\tLoss: 0.008481\n",
            "Train Epoch: 15 [10240/60000 (17%)]\tLoss: 0.014418\n",
            "Train Epoch: 15 [15360/60000 (25%)]\tLoss: 0.003116\n",
            "Train Epoch: 15 [20480/60000 (34%)]\tLoss: 0.039591\n",
            "Train Epoch: 15 [25600/60000 (42%)]\tLoss: 0.009483\n",
            "Train Epoch: 15 [30720/60000 (51%)]\tLoss: 0.006544\n",
            "Train Epoch: 15 [35840/60000 (59%)]\tLoss: 0.007629\n",
            "Train Epoch: 15 [40960/60000 (68%)]\tLoss: 0.006460\n",
            "Train Epoch: 15 [46080/60000 (76%)]\tLoss: 0.027759\n",
            "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.014369\n",
            "Train Epoch: 15 [56320/60000 (93%)]\tLoss: 0.011492\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.1131, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.034555\n",
            "Train Epoch: 16 [5120/60000 (8%)]\tLoss: 0.007904\n",
            "Train Epoch: 16 [10240/60000 (17%)]\tLoss: 0.003150\n",
            "Train Epoch: 16 [15360/60000 (25%)]\tLoss: 0.022553\n",
            "Train Epoch: 16 [20480/60000 (34%)]\tLoss: 0.022077\n",
            "Train Epoch: 16 [25600/60000 (42%)]\tLoss: 0.020213\n",
            "Train Epoch: 16 [30720/60000 (51%)]\tLoss: 0.030353\n",
            "Train Epoch: 16 [35840/60000 (59%)]\tLoss: 0.021983\n",
            "Train Epoch: 16 [40960/60000 (68%)]\tLoss: 0.005687\n",
            "Train Epoch: 16 [46080/60000 (76%)]\tLoss: 0.003751\n",
            "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 0.007693\n",
            "Train Epoch: 16 [56320/60000 (93%)]\tLoss: 0.006924\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.1197, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.039092\n",
            "Train Epoch: 17 [5120/60000 (8%)]\tLoss: 0.004989\n",
            "Train Epoch: 17 [10240/60000 (17%)]\tLoss: 0.002757\n",
            "Train Epoch: 17 [15360/60000 (25%)]\tLoss: 0.016944\n",
            "Train Epoch: 17 [20480/60000 (34%)]\tLoss: 0.018492\n",
            "Train Epoch: 17 [25600/60000 (42%)]\tLoss: 0.005705\n",
            "Train Epoch: 17 [30720/60000 (51%)]\tLoss: 0.006507\n",
            "Train Epoch: 17 [35840/60000 (59%)]\tLoss: 0.029461\n",
            "Train Epoch: 17 [40960/60000 (68%)]\tLoss: 0.018648\n",
            "Train Epoch: 17 [46080/60000 (76%)]\tLoss: 0.013410\n",
            "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 0.021638\n",
            "Train Epoch: 17 [56320/60000 (93%)]\tLoss: 0.016203\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.1144, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.013696\n",
            "Train Epoch: 18 [5120/60000 (8%)]\tLoss: 0.010669\n",
            "Train Epoch: 18 [10240/60000 (17%)]\tLoss: 0.009341\n",
            "Train Epoch: 18 [15360/60000 (25%)]\tLoss: 0.012986\n",
            "Train Epoch: 18 [20480/60000 (34%)]\tLoss: 0.001498\n",
            "Train Epoch: 18 [25600/60000 (42%)]\tLoss: 0.006439\n",
            "Train Epoch: 18 [30720/60000 (51%)]\tLoss: 0.001783\n",
            "Train Epoch: 18 [35840/60000 (59%)]\tLoss: 0.000867\n",
            "Train Epoch: 18 [40960/60000 (68%)]\tLoss: 0.004263\n",
            "Train Epoch: 18 [46080/60000 (76%)]\tLoss: 0.019388\n",
            "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 0.016739\n",
            "Train Epoch: 18 [56320/60000 (93%)]\tLoss: 0.022057\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.2080, Accuracy: (96%)\n",
            "\n",
            "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.077153\n",
            "Train Epoch: 19 [5120/60000 (8%)]\tLoss: 0.008182\n",
            "Train Epoch: 19 [10240/60000 (17%)]\tLoss: 0.014703\n",
            "Train Epoch: 19 [15360/60000 (25%)]\tLoss: 0.008434\n",
            "Train Epoch: 19 [20480/60000 (34%)]\tLoss: 0.015631\n",
            "Train Epoch: 19 [25600/60000 (42%)]\tLoss: 0.020179\n",
            "Train Epoch: 19 [30720/60000 (51%)]\tLoss: 0.001656\n",
            "Train Epoch: 19 [35840/60000 (59%)]\tLoss: 0.012645\n",
            "Train Epoch: 19 [40960/60000 (68%)]\tLoss: 0.017010\n",
            "Train Epoch: 19 [46080/60000 (76%)]\tLoss: 0.022359\n",
            "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 0.031937\n",
            "Train Epoch: 19 [56320/60000 (93%)]\tLoss: 0.016748\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.1050, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.014938\n",
            "Train Epoch: 20 [5120/60000 (8%)]\tLoss: 0.006411\n",
            "Train Epoch: 20 [10240/60000 (17%)]\tLoss: 0.005184\n",
            "Train Epoch: 20 [15360/60000 (25%)]\tLoss: 0.028936\n",
            "Train Epoch: 20 [20480/60000 (34%)]\tLoss: 0.005795\n",
            "Train Epoch: 20 [25600/60000 (42%)]\tLoss: 0.006115\n",
            "Train Epoch: 20 [30720/60000 (51%)]\tLoss: 0.030191\n",
            "Train Epoch: 20 [35840/60000 (59%)]\tLoss: 0.014761\n",
            "Train Epoch: 20 [40960/60000 (68%)]\tLoss: 0.029623\n",
            "Train Epoch: 20 [46080/60000 (76%)]\tLoss: 0.022188\n",
            "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 0.012711\n",
            "Train Epoch: 20 [56320/60000 (93%)]\tLoss: 0.010696\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.1198, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 21 [0/60000 (0%)]\tLoss: 0.006121\n",
            "Train Epoch: 21 [5120/60000 (8%)]\tLoss: 0.021243\n",
            "Train Epoch: 21 [10240/60000 (17%)]\tLoss: 0.015427\n",
            "Train Epoch: 21 [15360/60000 (25%)]\tLoss: 0.002319\n",
            "Train Epoch: 21 [20480/60000 (34%)]\tLoss: 0.001575\n",
            "Train Epoch: 21 [25600/60000 (42%)]\tLoss: 0.008709\n",
            "Train Epoch: 21 [30720/60000 (51%)]\tLoss: 0.012166\n",
            "Train Epoch: 21 [35840/60000 (59%)]\tLoss: 0.004313\n",
            "Train Epoch: 21 [40960/60000 (68%)]\tLoss: 0.022210\n",
            "Train Epoch: 21 [46080/60000 (76%)]\tLoss: 0.000699\n",
            "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 0.023183\n",
            "Train Epoch: 21 [56320/60000 (93%)]\tLoss: 0.027845\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.0958, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 22 [0/60000 (0%)]\tLoss: 0.008902\n",
            "Train Epoch: 22 [5120/60000 (8%)]\tLoss: 0.009043\n",
            "Train Epoch: 22 [10240/60000 (17%)]\tLoss: 0.027471\n",
            "Train Epoch: 22 [15360/60000 (25%)]\tLoss: 0.007496\n",
            "Train Epoch: 22 [20480/60000 (34%)]\tLoss: 0.023687\n",
            "Train Epoch: 22 [25600/60000 (42%)]\tLoss: 0.007850\n",
            "Train Epoch: 22 [30720/60000 (51%)]\tLoss: 0.008674\n",
            "Train Epoch: 22 [35840/60000 (59%)]\tLoss: 0.027203\n",
            "Train Epoch: 22 [40960/60000 (68%)]\tLoss: 0.017305\n",
            "Train Epoch: 22 [46080/60000 (76%)]\tLoss: 0.019487\n",
            "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 0.025447\n",
            "Train Epoch: 22 [56320/60000 (93%)]\tLoss: 0.004440\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.0830, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 23 [0/60000 (0%)]\tLoss: 0.007753\n",
            "Train Epoch: 23 [5120/60000 (8%)]\tLoss: 0.002027\n",
            "Train Epoch: 23 [10240/60000 (17%)]\tLoss: 0.005253\n",
            "Train Epoch: 23 [15360/60000 (25%)]\tLoss: 0.000924\n",
            "Train Epoch: 23 [20480/60000 (34%)]\tLoss: 0.008041\n",
            "Train Epoch: 23 [25600/60000 (42%)]\tLoss: 0.000968\n",
            "Train Epoch: 23 [30720/60000 (51%)]\tLoss: 0.005472\n",
            "Train Epoch: 23 [35840/60000 (59%)]\tLoss: 0.007057\n",
            "Train Epoch: 23 [40960/60000 (68%)]\tLoss: 0.011649\n",
            "Train Epoch: 23 [46080/60000 (76%)]\tLoss: 0.006515\n",
            "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 0.005126\n",
            "Train Epoch: 23 [56320/60000 (93%)]\tLoss: 0.011804\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.0977, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 24 [0/60000 (0%)]\tLoss: 0.017158\n",
            "Train Epoch: 24 [5120/60000 (8%)]\tLoss: 0.005570\n",
            "Train Epoch: 24 [10240/60000 (17%)]\tLoss: 0.005398\n",
            "Train Epoch: 24 [15360/60000 (25%)]\tLoss: 0.006347\n",
            "Train Epoch: 24 [20480/60000 (34%)]\tLoss: 0.000838\n",
            "Train Epoch: 24 [25600/60000 (42%)]\tLoss: 0.001127\n",
            "Train Epoch: 24 [30720/60000 (51%)]\tLoss: 0.005020\n",
            "Train Epoch: 24 [35840/60000 (59%)]\tLoss: 0.015817\n",
            "Train Epoch: 24 [40960/60000 (68%)]\tLoss: 0.004295\n",
            "Train Epoch: 24 [46080/60000 (76%)]\tLoss: 0.006747\n",
            "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 0.008196\n",
            "Train Epoch: 24 [56320/60000 (93%)]\tLoss: 0.000533\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.0988, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 25 [0/60000 (0%)]\tLoss: 0.001966\n",
            "Train Epoch: 25 [5120/60000 (8%)]\tLoss: 0.011650\n",
            "Train Epoch: 25 [10240/60000 (17%)]\tLoss: 0.003529\n",
            "Train Epoch: 25 [15360/60000 (25%)]\tLoss: 0.029414\n",
            "Train Epoch: 25 [20480/60000 (34%)]\tLoss: 0.010057\n",
            "Train Epoch: 25 [25600/60000 (42%)]\tLoss: 0.014068\n",
            "Train Epoch: 25 [30720/60000 (51%)]\tLoss: 0.003885\n",
            "Train Epoch: 25 [35840/60000 (59%)]\tLoss: 0.038309\n",
            "Train Epoch: 25 [40960/60000 (68%)]\tLoss: 0.007739\n",
            "Train Epoch: 25 [46080/60000 (76%)]\tLoss: 0.004150\n",
            "Train Epoch: 25 [51200/60000 (85%)]\tLoss: 0.001591\n",
            "Train Epoch: 25 [56320/60000 (93%)]\tLoss: 0.017317\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.0776, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 26 [0/60000 (0%)]\tLoss: 0.001712\n",
            "Train Epoch: 26 [5120/60000 (8%)]\tLoss: 0.007802\n",
            "Train Epoch: 26 [10240/60000 (17%)]\tLoss: 0.004826\n",
            "Train Epoch: 26 [15360/60000 (25%)]\tLoss: 0.003833\n",
            "Train Epoch: 26 [20480/60000 (34%)]\tLoss: 0.028395\n",
            "Train Epoch: 26 [25600/60000 (42%)]\tLoss: 0.016554\n",
            "Train Epoch: 26 [30720/60000 (51%)]\tLoss: 0.001046\n",
            "Train Epoch: 26 [35840/60000 (59%)]\tLoss: 0.020893\n",
            "Train Epoch: 26 [40960/60000 (68%)]\tLoss: 0.007409\n",
            "Train Epoch: 26 [46080/60000 (76%)]\tLoss: 0.010248\n",
            "Train Epoch: 26 [51200/60000 (85%)]\tLoss: 0.023577\n",
            "Train Epoch: 26 [56320/60000 (93%)]\tLoss: 0.019320\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.0917, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 27 [0/60000 (0%)]\tLoss: 0.001658\n",
            "Train Epoch: 27 [5120/60000 (8%)]\tLoss: 0.002294\n",
            "Train Epoch: 27 [10240/60000 (17%)]\tLoss: 0.001710\n",
            "Train Epoch: 27 [15360/60000 (25%)]\tLoss: 0.001451\n",
            "Train Epoch: 27 [20480/60000 (34%)]\tLoss: 0.008882\n",
            "Train Epoch: 27 [25600/60000 (42%)]\tLoss: 0.002314\n",
            "Train Epoch: 27 [30720/60000 (51%)]\tLoss: 0.000911\n",
            "Train Epoch: 27 [35840/60000 (59%)]\tLoss: 0.000457\n",
            "Train Epoch: 27 [40960/60000 (68%)]\tLoss: 0.001766\n",
            "Train Epoch: 27 [46080/60000 (76%)]\tLoss: 0.005132\n",
            "Train Epoch: 27 [51200/60000 (85%)]\tLoss: 0.032722\n",
            "Train Epoch: 27 [56320/60000 (93%)]\tLoss: 0.004699\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.1090, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 28 [0/60000 (0%)]\tLoss: 0.009574\n",
            "Train Epoch: 28 [5120/60000 (8%)]\tLoss: 0.023876\n",
            "Train Epoch: 28 [10240/60000 (17%)]\tLoss: 0.003691\n",
            "Train Epoch: 28 [15360/60000 (25%)]\tLoss: 0.006941\n",
            "Train Epoch: 28 [20480/60000 (34%)]\tLoss: 0.004803\n",
            "Train Epoch: 28 [25600/60000 (42%)]\tLoss: 0.021480\n",
            "Train Epoch: 28 [30720/60000 (51%)]\tLoss: 0.003896\n",
            "Train Epoch: 28 [35840/60000 (59%)]\tLoss: 0.003842\n",
            "Train Epoch: 28 [40960/60000 (68%)]\tLoss: 0.001979\n",
            "Train Epoch: 28 [46080/60000 (76%)]\tLoss: 0.006098\n",
            "Train Epoch: 28 [51200/60000 (85%)]\tLoss: 0.003519\n",
            "Train Epoch: 28 [56320/60000 (93%)]\tLoss: 0.003990\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.1049, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 29 [0/60000 (0%)]\tLoss: 0.000371\n",
            "Train Epoch: 29 [5120/60000 (8%)]\tLoss: 0.005072\n",
            "Train Epoch: 29 [10240/60000 (17%)]\tLoss: 0.000575\n",
            "Train Epoch: 29 [15360/60000 (25%)]\tLoss: 0.005546\n",
            "Train Epoch: 29 [20480/60000 (34%)]\tLoss: 0.005190\n",
            "Train Epoch: 29 [25600/60000 (42%)]\tLoss: 0.008615\n",
            "Train Epoch: 29 [30720/60000 (51%)]\tLoss: 0.012373\n",
            "Train Epoch: 29 [35840/60000 (59%)]\tLoss: 0.032958\n",
            "Train Epoch: 29 [40960/60000 (68%)]\tLoss: 0.013805\n",
            "Train Epoch: 29 [46080/60000 (76%)]\tLoss: 0.003624\n",
            "Train Epoch: 29 [51200/60000 (85%)]\tLoss: 0.006945\n",
            "Train Epoch: 29 [56320/60000 (93%)]\tLoss: 0.003223\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.0973, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 30 [0/60000 (0%)]\tLoss: 0.018275\n",
            "Train Epoch: 30 [5120/60000 (8%)]\tLoss: 0.001809\n",
            "Train Epoch: 30 [10240/60000 (17%)]\tLoss: 0.001529\n",
            "Train Epoch: 30 [15360/60000 (25%)]\tLoss: 0.003995\n",
            "Train Epoch: 30 [20480/60000 (34%)]\tLoss: 0.017494\n",
            "Train Epoch: 30 [25600/60000 (42%)]\tLoss: 0.003084\n",
            "Train Epoch: 30 [30720/60000 (51%)]\tLoss: 0.010885\n",
            "Train Epoch: 30 [35840/60000 (59%)]\tLoss: 0.003709\n",
            "Train Epoch: 30 [40960/60000 (68%)]\tLoss: 0.014686\n",
            "Train Epoch: 30 [46080/60000 (76%)]\tLoss: 0.000720\n",
            "Train Epoch: 30 [51200/60000 (85%)]\tLoss: 0.003225\n",
            "Train Epoch: 30 [56320/60000 (93%)]\tLoss: 0.004707\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.1068, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 31 [0/60000 (0%)]\tLoss: 0.009968\n",
            "Train Epoch: 31 [5120/60000 (8%)]\tLoss: 0.002319\n",
            "Train Epoch: 31 [10240/60000 (17%)]\tLoss: 0.003761\n",
            "Train Epoch: 31 [15360/60000 (25%)]\tLoss: 0.007489\n",
            "Train Epoch: 31 [20480/60000 (34%)]\tLoss: 0.001004\n",
            "Train Epoch: 31 [25600/60000 (42%)]\tLoss: 0.006195\n",
            "Train Epoch: 31 [30720/60000 (51%)]\tLoss: 0.001086\n",
            "Train Epoch: 31 [35840/60000 (59%)]\tLoss: 0.003936\n",
            "Train Epoch: 31 [40960/60000 (68%)]\tLoss: 0.018031\n",
            "Train Epoch: 31 [46080/60000 (76%)]\tLoss: 0.027978\n",
            "Train Epoch: 31 [51200/60000 (85%)]\tLoss: 0.011182\n",
            "Train Epoch: 31 [56320/60000 (93%)]\tLoss: 0.003043\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.1164, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 32 [0/60000 (0%)]\tLoss: 0.009657\n",
            "Train Epoch: 32 [5120/60000 (8%)]\tLoss: 0.003919\n",
            "Train Epoch: 32 [10240/60000 (17%)]\tLoss: 0.001649\n",
            "Train Epoch: 32 [15360/60000 (25%)]\tLoss: 0.000507\n",
            "Train Epoch: 32 [20480/60000 (34%)]\tLoss: 0.001553\n",
            "Train Epoch: 32 [25600/60000 (42%)]\tLoss: 0.000693\n",
            "Train Epoch: 32 [30720/60000 (51%)]\tLoss: 0.003447\n",
            "Train Epoch: 32 [35840/60000 (59%)]\tLoss: 0.005792\n",
            "Train Epoch: 32 [40960/60000 (68%)]\tLoss: 0.027241\n",
            "Train Epoch: 32 [46080/60000 (76%)]\tLoss: 0.003380\n",
            "Train Epoch: 32 [51200/60000 (85%)]\tLoss: 0.016850\n",
            "Train Epoch: 32 [56320/60000 (93%)]\tLoss: 0.000748\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.0800, Accuracy: (99%)\n",
            "\n",
            "Train Epoch: 33 [0/60000 (0%)]\tLoss: 0.002029\n",
            "Train Epoch: 33 [5120/60000 (8%)]\tLoss: 0.005160\n",
            "Train Epoch: 33 [10240/60000 (17%)]\tLoss: 0.003187\n",
            "Train Epoch: 33 [15360/60000 (25%)]\tLoss: 0.000439\n",
            "Train Epoch: 33 [20480/60000 (34%)]\tLoss: 0.014722\n",
            "Train Epoch: 33 [25600/60000 (42%)]\tLoss: 0.000675\n",
            "Train Epoch: 33 [30720/60000 (51%)]\tLoss: 0.003677\n",
            "Train Epoch: 33 [35840/60000 (59%)]\tLoss: 0.002415\n",
            "Train Epoch: 33 [40960/60000 (68%)]\tLoss: 0.000937\n",
            "Train Epoch: 33 [46080/60000 (76%)]\tLoss: 0.000664\n",
            "Train Epoch: 33 [51200/60000 (85%)]\tLoss: 0.031831\n",
            "Train Epoch: 33 [56320/60000 (93%)]\tLoss: 0.013731\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.0843, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 34 [0/60000 (0%)]\tLoss: 0.002981\n",
            "Train Epoch: 34 [5120/60000 (8%)]\tLoss: 0.011979\n",
            "Train Epoch: 34 [10240/60000 (17%)]\tLoss: 0.001105\n",
            "Train Epoch: 34 [15360/60000 (25%)]\tLoss: 0.010651\n",
            "Train Epoch: 34 [20480/60000 (34%)]\tLoss: 0.001522\n",
            "Train Epoch: 34 [25600/60000 (42%)]\tLoss: 0.001697\n",
            "Train Epoch: 34 [30720/60000 (51%)]\tLoss: 0.008468\n",
            "Train Epoch: 34 [35840/60000 (59%)]\tLoss: 0.008760\n",
            "Train Epoch: 34 [40960/60000 (68%)]\tLoss: 0.019916\n",
            "Train Epoch: 34 [46080/60000 (76%)]\tLoss: 0.004999\n",
            "Train Epoch: 34 [51200/60000 (85%)]\tLoss: 0.000889\n",
            "Train Epoch: 34 [56320/60000 (93%)]\tLoss: 0.000729\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.1023, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 35 [0/60000 (0%)]\tLoss: 0.002868\n",
            "Train Epoch: 35 [5120/60000 (8%)]\tLoss: 0.012202\n",
            "Train Epoch: 35 [10240/60000 (17%)]\tLoss: 0.007461\n",
            "Train Epoch: 35 [15360/60000 (25%)]\tLoss: 0.006323\n",
            "Train Epoch: 35 [20480/60000 (34%)]\tLoss: 0.000489\n",
            "Train Epoch: 35 [25600/60000 (42%)]\tLoss: 0.007049\n",
            "Train Epoch: 35 [30720/60000 (51%)]\tLoss: 0.000253\n",
            "Train Epoch: 35 [35840/60000 (59%)]\tLoss: 0.004289\n",
            "Train Epoch: 35 [40960/60000 (68%)]\tLoss: 0.000286\n",
            "Train Epoch: 35 [46080/60000 (76%)]\tLoss: 0.008309\n",
            "Train Epoch: 35 [51200/60000 (85%)]\tLoss: 0.001140\n",
            "Train Epoch: 35 [56320/60000 (93%)]\tLoss: 0.011214\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.1049, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 36 [0/60000 (0%)]\tLoss: 0.003029\n",
            "Train Epoch: 36 [5120/60000 (8%)]\tLoss: 0.003460\n",
            "Train Epoch: 36 [10240/60000 (17%)]\tLoss: 0.000495\n",
            "Train Epoch: 36 [15360/60000 (25%)]\tLoss: 0.004433\n",
            "Train Epoch: 36 [20480/60000 (34%)]\tLoss: 0.005613\n",
            "Train Epoch: 36 [25600/60000 (42%)]\tLoss: 0.002218\n",
            "Train Epoch: 36 [30720/60000 (51%)]\tLoss: 0.000426\n",
            "Train Epoch: 36 [35840/60000 (59%)]\tLoss: 0.004838\n",
            "Train Epoch: 36 [40960/60000 (68%)]\tLoss: 0.001954\n",
            "Train Epoch: 36 [46080/60000 (76%)]\tLoss: 0.000792\n",
            "Train Epoch: 36 [51200/60000 (85%)]\tLoss: 0.002940\n",
            "Train Epoch: 36 [56320/60000 (93%)]\tLoss: 0.002397\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.1058, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 37 [0/60000 (0%)]\tLoss: 0.008939\n",
            "Train Epoch: 37 [5120/60000 (8%)]\tLoss: 0.001544\n",
            "Train Epoch: 37 [10240/60000 (17%)]\tLoss: 0.015146\n",
            "Train Epoch: 37 [15360/60000 (25%)]\tLoss: 0.052323\n",
            "Train Epoch: 37 [20480/60000 (34%)]\tLoss: 0.024590\n",
            "Train Epoch: 37 [25600/60000 (42%)]\tLoss: 0.007148\n",
            "Train Epoch: 37 [30720/60000 (51%)]\tLoss: 0.001385\n",
            "Train Epoch: 37 [35840/60000 (59%)]\tLoss: 0.011010\n",
            "Train Epoch: 37 [40960/60000 (68%)]\tLoss: 0.012131\n",
            "Train Epoch: 37 [46080/60000 (76%)]\tLoss: 0.020314\n",
            "Train Epoch: 37 [51200/60000 (85%)]\tLoss: 0.000838\n",
            "Train Epoch: 37 [56320/60000 (93%)]\tLoss: 0.002487\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.1150, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 38 [0/60000 (0%)]\tLoss: 0.023476\n",
            "Train Epoch: 38 [5120/60000 (8%)]\tLoss: 0.003328\n",
            "Train Epoch: 38 [10240/60000 (17%)]\tLoss: 0.005281\n",
            "Train Epoch: 38 [15360/60000 (25%)]\tLoss: 0.002627\n",
            "Train Epoch: 38 [20480/60000 (34%)]\tLoss: 0.012109\n",
            "Train Epoch: 38 [25600/60000 (42%)]\tLoss: 0.003214\n",
            "Train Epoch: 38 [30720/60000 (51%)]\tLoss: 0.000504\n",
            "Train Epoch: 38 [35840/60000 (59%)]\tLoss: 0.002170\n",
            "Train Epoch: 38 [40960/60000 (68%)]\tLoss: 0.002899\n",
            "Train Epoch: 38 [46080/60000 (76%)]\tLoss: 0.012173\n",
            "Train Epoch: 38 [51200/60000 (85%)]\tLoss: 0.001352\n",
            "Train Epoch: 38 [56320/60000 (93%)]\tLoss: 0.000215\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.0961, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 39 [0/60000 (0%)]\tLoss: 0.000830\n",
            "Train Epoch: 39 [5120/60000 (8%)]\tLoss: 0.007208\n",
            "Train Epoch: 39 [10240/60000 (17%)]\tLoss: 0.000260\n",
            "Train Epoch: 39 [15360/60000 (25%)]\tLoss: 0.004902\n",
            "Train Epoch: 39 [20480/60000 (34%)]\tLoss: 0.003568\n",
            "Train Epoch: 39 [25600/60000 (42%)]\tLoss: 0.000244\n",
            "Train Epoch: 39 [30720/60000 (51%)]\tLoss: 0.006190\n",
            "Train Epoch: 39 [35840/60000 (59%)]\tLoss: 0.001277\n",
            "Train Epoch: 39 [40960/60000 (68%)]\tLoss: 0.000524\n",
            "Train Epoch: 39 [46080/60000 (76%)]\tLoss: 0.012247\n",
            "Train Epoch: 39 [51200/60000 (85%)]\tLoss: 0.003552\n",
            "Train Epoch: 39 [56320/60000 (93%)]\tLoss: 0.012104\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.1033, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 40 [0/60000 (0%)]\tLoss: 0.000584\n",
            "Train Epoch: 40 [5120/60000 (8%)]\tLoss: 0.001231\n",
            "Train Epoch: 40 [10240/60000 (17%)]\tLoss: 0.006896\n",
            "Train Epoch: 40 [15360/60000 (25%)]\tLoss: 0.000680\n",
            "Train Epoch: 40 [20480/60000 (34%)]\tLoss: 0.005908\n",
            "Train Epoch: 40 [25600/60000 (42%)]\tLoss: 0.011377\n",
            "Train Epoch: 40 [30720/60000 (51%)]\tLoss: 0.002017\n",
            "Train Epoch: 40 [35840/60000 (59%)]\tLoss: 0.004728\n",
            "Train Epoch: 40 [40960/60000 (68%)]\tLoss: 0.008513\n",
            "Train Epoch: 40 [46080/60000 (76%)]\tLoss: 0.001292\n",
            "Train Epoch: 40 [51200/60000 (85%)]\tLoss: 0.018693\n",
            "Train Epoch: 40 [56320/60000 (93%)]\tLoss: 0.001952\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.0874, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 41 [0/60000 (0%)]\tLoss: 0.015169\n",
            "Train Epoch: 41 [5120/60000 (8%)]\tLoss: 0.001967\n",
            "Train Epoch: 41 [10240/60000 (17%)]\tLoss: 0.000746\n",
            "Train Epoch: 41 [15360/60000 (25%)]\tLoss: 0.006003\n",
            "Train Epoch: 41 [20480/60000 (34%)]\tLoss: 0.009342\n",
            "Train Epoch: 41 [25600/60000 (42%)]\tLoss: 0.018789\n",
            "Train Epoch: 41 [30720/60000 (51%)]\tLoss: 0.004757\n",
            "Train Epoch: 41 [35840/60000 (59%)]\tLoss: 0.003160\n",
            "Train Epoch: 41 [40960/60000 (68%)]\tLoss: 0.004947\n",
            "Train Epoch: 41 [46080/60000 (76%)]\tLoss: 0.005288\n",
            "Train Epoch: 41 [51200/60000 (85%)]\tLoss: 0.003157\n",
            "Train Epoch: 41 [56320/60000 (93%)]\tLoss: 0.014891\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.1127, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 42 [0/60000 (0%)]\tLoss: 0.010187\n",
            "Train Epoch: 42 [5120/60000 (8%)]\tLoss: 0.001688\n",
            "Train Epoch: 42 [10240/60000 (17%)]\tLoss: 0.004858\n",
            "Train Epoch: 42 [15360/60000 (25%)]\tLoss: 0.004854\n",
            "Train Epoch: 42 [20480/60000 (34%)]\tLoss: 0.009366\n",
            "Train Epoch: 42 [25600/60000 (42%)]\tLoss: 0.000234\n",
            "Train Epoch: 42 [30720/60000 (51%)]\tLoss: 0.022492\n",
            "Train Epoch: 42 [35840/60000 (59%)]\tLoss: 0.016206\n",
            "Train Epoch: 42 [40960/60000 (68%)]\tLoss: 0.004187\n",
            "Train Epoch: 42 [46080/60000 (76%)]\tLoss: 0.020204\n",
            "Train Epoch: 42 [51200/60000 (85%)]\tLoss: 0.001855\n",
            "Train Epoch: 42 [56320/60000 (93%)]\tLoss: 0.013848\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.1154, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 43 [0/60000 (0%)]\tLoss: 0.005229\n",
            "Train Epoch: 43 [5120/60000 (8%)]\tLoss: 0.009393\n",
            "Train Epoch: 43 [10240/60000 (17%)]\tLoss: 0.006694\n",
            "Train Epoch: 43 [15360/60000 (25%)]\tLoss: 0.000432\n",
            "Train Epoch: 43 [20480/60000 (34%)]\tLoss: 0.002162\n",
            "Train Epoch: 43 [25600/60000 (42%)]\tLoss: 0.001937\n",
            "Train Epoch: 43 [30720/60000 (51%)]\tLoss: 0.010407\n",
            "Train Epoch: 43 [35840/60000 (59%)]\tLoss: 0.002381\n",
            "Train Epoch: 43 [40960/60000 (68%)]\tLoss: 0.004312\n",
            "Train Epoch: 43 [46080/60000 (76%)]\tLoss: 0.005425\n",
            "Train Epoch: 43 [51200/60000 (85%)]\tLoss: 0.000562\n",
            "Train Epoch: 43 [56320/60000 (93%)]\tLoss: 0.002325\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.1171, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 44 [0/60000 (0%)]\tLoss: 0.009346\n",
            "Train Epoch: 44 [5120/60000 (8%)]\tLoss: 0.008600\n",
            "Train Epoch: 44 [10240/60000 (17%)]\tLoss: 0.000871\n",
            "Train Epoch: 44 [15360/60000 (25%)]\tLoss: 0.012577\n",
            "Train Epoch: 44 [20480/60000 (34%)]\tLoss: 0.010015\n",
            "Train Epoch: 44 [25600/60000 (42%)]\tLoss: 0.003848\n",
            "Train Epoch: 44 [30720/60000 (51%)]\tLoss: 0.002229\n",
            "Train Epoch: 44 [35840/60000 (59%)]\tLoss: 0.003613\n",
            "Train Epoch: 44 [40960/60000 (68%)]\tLoss: 0.019136\n",
            "Train Epoch: 44 [46080/60000 (76%)]\tLoss: 0.005445\n",
            "Train Epoch: 44 [51200/60000 (85%)]\tLoss: 0.000942\n",
            "Train Epoch: 44 [56320/60000 (93%)]\tLoss: 0.001880\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.1045, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 45 [0/60000 (0%)]\tLoss: 0.002174\n",
            "Train Epoch: 45 [5120/60000 (8%)]\tLoss: 0.000992\n",
            "Train Epoch: 45 [10240/60000 (17%)]\tLoss: 0.000674\n",
            "Train Epoch: 45 [15360/60000 (25%)]\tLoss: 0.007060\n",
            "Train Epoch: 45 [20480/60000 (34%)]\tLoss: 0.022282\n",
            "Train Epoch: 45 [25600/60000 (42%)]\tLoss: 0.003941\n",
            "Train Epoch: 45 [30720/60000 (51%)]\tLoss: 0.011348\n",
            "Train Epoch: 45 [35840/60000 (59%)]\tLoss: 0.002964\n",
            "Train Epoch: 45 [40960/60000 (68%)]\tLoss: 0.008814\n",
            "Train Epoch: 45 [46080/60000 (76%)]\tLoss: 0.001679\n",
            "Train Epoch: 45 [51200/60000 (85%)]\tLoss: 0.000880\n",
            "Train Epoch: 45 [56320/60000 (93%)]\tLoss: 0.000694\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.0767, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 46 [0/60000 (0%)]\tLoss: 0.002009\n",
            "Train Epoch: 46 [5120/60000 (8%)]\tLoss: 0.002194\n",
            "Train Epoch: 46 [10240/60000 (17%)]\tLoss: 0.001227\n",
            "Train Epoch: 46 [15360/60000 (25%)]\tLoss: 0.001584\n",
            "Train Epoch: 46 [20480/60000 (34%)]\tLoss: 0.002910\n",
            "Train Epoch: 46 [25600/60000 (42%)]\tLoss: 0.003494\n",
            "Train Epoch: 46 [30720/60000 (51%)]\tLoss: 0.005969\n",
            "Train Epoch: 46 [35840/60000 (59%)]\tLoss: 0.001750\n",
            "Train Epoch: 46 [40960/60000 (68%)]\tLoss: 0.001473\n",
            "Train Epoch: 46 [46080/60000 (76%)]\tLoss: 0.002267\n",
            "Train Epoch: 46 [51200/60000 (85%)]\tLoss: 0.000592\n",
            "Train Epoch: 46 [56320/60000 (93%)]\tLoss: 0.001693\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.0965, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 47 [0/60000 (0%)]\tLoss: 0.000781\n",
            "Train Epoch: 47 [5120/60000 (8%)]\tLoss: 0.005765\n",
            "Train Epoch: 47 [10240/60000 (17%)]\tLoss: 0.000668\n",
            "Train Epoch: 47 [15360/60000 (25%)]\tLoss: 0.002714\n",
            "Train Epoch: 47 [20480/60000 (34%)]\tLoss: 0.004427\n",
            "Train Epoch: 47 [25600/60000 (42%)]\tLoss: 0.000631\n",
            "Train Epoch: 47 [30720/60000 (51%)]\tLoss: 0.001169\n",
            "Train Epoch: 47 [35840/60000 (59%)]\tLoss: 0.006597\n",
            "Train Epoch: 47 [40960/60000 (68%)]\tLoss: 0.001398\n",
            "Train Epoch: 47 [46080/60000 (76%)]\tLoss: 0.012886\n",
            "Train Epoch: 47 [51200/60000 (85%)]\tLoss: 0.010706\n",
            "Train Epoch: 47 [56320/60000 (93%)]\tLoss: 0.001381\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.0766, Accuracy: (99%)\n",
            "\n",
            "Train Epoch: 48 [0/60000 (0%)]\tLoss: 0.000712\n",
            "Train Epoch: 48 [5120/60000 (8%)]\tLoss: 0.000136\n",
            "Train Epoch: 48 [10240/60000 (17%)]\tLoss: 0.000408\n",
            "Train Epoch: 48 [15360/60000 (25%)]\tLoss: 0.000154\n",
            "Train Epoch: 48 [20480/60000 (34%)]\tLoss: 0.000074\n",
            "Train Epoch: 48 [25600/60000 (42%)]\tLoss: 0.000396\n",
            "Train Epoch: 48 [30720/60000 (51%)]\tLoss: 0.003097\n",
            "Train Epoch: 48 [35840/60000 (59%)]\tLoss: 0.011375\n",
            "Train Epoch: 48 [40960/60000 (68%)]\tLoss: 0.001377\n",
            "Train Epoch: 48 [46080/60000 (76%)]\tLoss: 0.000260\n",
            "Train Epoch: 48 [51200/60000 (85%)]\tLoss: 0.003200\n",
            "Train Epoch: 48 [56320/60000 (93%)]\tLoss: 0.000692\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.0810, Accuracy: (99%)\n",
            "\n",
            "Train Epoch: 49 [0/60000 (0%)]\tLoss: 0.000493\n",
            "Train Epoch: 49 [5120/60000 (8%)]\tLoss: 0.001011\n",
            "Train Epoch: 49 [10240/60000 (17%)]\tLoss: 0.004162\n",
            "Train Epoch: 49 [15360/60000 (25%)]\tLoss: 0.000971\n",
            "Train Epoch: 49 [20480/60000 (34%)]\tLoss: 0.000364\n",
            "Train Epoch: 49 [25600/60000 (42%)]\tLoss: 0.001255\n",
            "Train Epoch: 49 [30720/60000 (51%)]\tLoss: 0.000269\n",
            "Train Epoch: 49 [35840/60000 (59%)]\tLoss: 0.002337\n",
            "Train Epoch: 49 [40960/60000 (68%)]\tLoss: 0.000860\n",
            "Train Epoch: 49 [46080/60000 (76%)]\tLoss: 0.000480\n",
            "Train Epoch: 49 [51200/60000 (85%)]\tLoss: 0.000122\n",
            "Train Epoch: 49 [56320/60000 (93%)]\tLoss: 0.003160\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.0881, Accuracy: (99%)\n",
            "\n",
            "Train Epoch: 50 [0/60000 (0%)]\tLoss: 0.001812\n",
            "Train Epoch: 50 [5120/60000 (8%)]\tLoss: 0.001000\n",
            "Train Epoch: 50 [10240/60000 (17%)]\tLoss: 0.000602\n",
            "Train Epoch: 50 [15360/60000 (25%)]\tLoss: 0.008619\n",
            "Train Epoch: 50 [20480/60000 (34%)]\tLoss: 0.000058\n",
            "Train Epoch: 50 [25600/60000 (42%)]\tLoss: 0.000699\n",
            "Train Epoch: 50 [30720/60000 (51%)]\tLoss: 0.000191\n",
            "Train Epoch: 50 [35840/60000 (59%)]\tLoss: 0.000301\n",
            "Train Epoch: 50 [40960/60000 (68%)]\tLoss: 0.003406\n",
            "Train Epoch: 50 [46080/60000 (76%)]\tLoss: 0.001005\n",
            "Train Epoch: 50 [51200/60000 (85%)]\tLoss: 0.001755\n",
            "Train Epoch: 50 [56320/60000 (93%)]\tLoss: 0.000877\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.0935, Accuracy: (99%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "\n",
        "# def main():\n",
        "  # print('hello')\n",
        "  # parser = argparse.ArgumentParser()\n",
        "  # parser.add_argument('--seed', type=int, default=1)\n",
        "  # parser.add_argument('--batch_size', type=int, default=512)\n",
        "  # parser.add_argument('--epochs', type=int, default=50)\n",
        "  # parser.add_argument(\"--lr\", type=float, required=True)\n",
        "  # parser.add_argument('--log-interval', type=int, default=10, metavar='N',help='how many batches to wait before logging training status')\n",
        "  # args = parser.parse_args()\n",
        "\n",
        "  # # Get data\n",
        "  # print(args)\n",
        "  # args = parser.parse_args()\n",
        "\n",
        "# class Args:\n",
        "#   seed = 1\n",
        "#   batch_size = 512\n",
        "#   epochs = 50\n",
        "#   lr = 0.001  # Set your desired learning rate here\n",
        "#   log_interval = 10\n",
        "\n",
        "# args_1 = Args()\n",
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "torch.manual_seed(args_1.seed)\n",
        "\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "train_kwargs = {'batch_size': args_1.batch_size}\n",
        "test_kwargs = {'batch_size': args_1.batch_size}\n",
        "if use_cuda:\n",
        "    cuda_kwargs = {'num_workers': 1,\n",
        "                    'pin_memory': True,\n",
        "                    'shuffle': True}\n",
        "    train_kwargs.update(cuda_kwargs)\n",
        "    test_kwargs.update(cuda_kwargs)\n",
        "\n",
        "transform=transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "dataset1 = datasets.MNIST('../data', train=True, download=True,\n",
        "                    transform=transform)\n",
        "dataset2 = datasets.MNIST('../data', train=False,\n",
        "                    transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n",
        "\n",
        "model_a = MLP().to(device)\n",
        "optimizer = optim.Adam(model_a.parameters(), lr=args_1.lr)\n",
        "\n",
        "for epoch in range(1, args_1.epochs + 1):\n",
        "    train(args_1, model_a, device, train_loader, optimizer, epoch)\n",
        "    test(model_a, device, test_loader)\n",
        "\n",
        "torch.save(model_a.state_dict(), f\"mnist_mlp_{str(args_1.seed)}.pt\")\n",
        "\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#   main()"
      ],
      "metadata": {
        "id": "kDO0Y10yyPjQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "feae1102-2611-41d8-94d8-7d2d79596869"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-35-3775b565d8d0>:22: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return nn.functional.log_softmax(x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.301238\n",
            "Train Epoch: 1 [5120/60000 (8%)]\tLoss: 0.837421\n",
            "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.370069\n",
            "Train Epoch: 1 [15360/60000 (25%)]\tLoss: 0.437956\n",
            "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.448421\n",
            "Train Epoch: 1 [25600/60000 (42%)]\tLoss: 0.255471\n",
            "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.292597\n",
            "Train Epoch: 1 [35840/60000 (59%)]\tLoss: 0.252196\n",
            "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.268243\n",
            "Train Epoch: 1 [46080/60000 (76%)]\tLoss: 0.249866\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.150546\n",
            "Train Epoch: 1 [56320/60000 (93%)]\tLoss: 0.156378\n",
            "Train Accuracy: (87%) \n",
            "\n",
            "Average loss: 0.1810, Accuracy: (94%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.168576\n",
            "Train Epoch: 2 [5120/60000 (8%)]\tLoss: 0.143115\n",
            "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.129787\n",
            "Train Epoch: 2 [15360/60000 (25%)]\tLoss: 0.157175\n",
            "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.205519\n",
            "Train Epoch: 2 [25600/60000 (42%)]\tLoss: 0.120471\n",
            "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.130757\n",
            "Train Epoch: 2 [35840/60000 (59%)]\tLoss: 0.141258\n",
            "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.177783\n",
            "Train Epoch: 2 [46080/60000 (76%)]\tLoss: 0.149881\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.091875\n",
            "Train Epoch: 2 [56320/60000 (93%)]\tLoss: 0.083609\n",
            "Train Accuracy: (96%) \n",
            "\n",
            "Average loss: 0.1156, Accuracy: (96%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.107616\n",
            "Train Epoch: 3 [5120/60000 (8%)]\tLoss: 0.093603\n",
            "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.055365\n",
            "Train Epoch: 3 [15360/60000 (25%)]\tLoss: 0.095866\n",
            "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.143008\n",
            "Train Epoch: 3 [25600/60000 (42%)]\tLoss: 0.080038\n",
            "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.108784\n",
            "Train Epoch: 3 [35840/60000 (59%)]\tLoss: 0.083263\n",
            "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.097535\n",
            "Train Epoch: 3 [46080/60000 (76%)]\tLoss: 0.095182\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.067802\n",
            "Train Epoch: 3 [56320/60000 (93%)]\tLoss: 0.072822\n",
            "Train Accuracy: (97%) \n",
            "\n",
            "Average loss: 0.1084, Accuracy: (97%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.103742\n",
            "Train Epoch: 4 [5120/60000 (8%)]\tLoss: 0.058172\n",
            "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.052648\n",
            "Train Epoch: 4 [15360/60000 (25%)]\tLoss: 0.078443\n",
            "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.099137\n",
            "Train Epoch: 4 [25600/60000 (42%)]\tLoss: 0.065376\n",
            "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.104245\n",
            "Train Epoch: 4 [35840/60000 (59%)]\tLoss: 0.066459\n",
            "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.084389\n",
            "Train Epoch: 4 [46080/60000 (76%)]\tLoss: 0.078456\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.042866\n",
            "Train Epoch: 4 [56320/60000 (93%)]\tLoss: 0.050805\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.1004, Accuracy: (97%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.089043\n",
            "Train Epoch: 5 [5120/60000 (8%)]\tLoss: 0.056198\n",
            "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.025608\n",
            "Train Epoch: 5 [15360/60000 (25%)]\tLoss: 0.047144\n",
            "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.041716\n",
            "Train Epoch: 5 [25600/60000 (42%)]\tLoss: 0.060095\n",
            "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.068383\n",
            "Train Epoch: 5 [35840/60000 (59%)]\tLoss: 0.035096\n",
            "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.085493\n",
            "Train Epoch: 5 [46080/60000 (76%)]\tLoss: 0.048912\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.054172\n",
            "Train Epoch: 5 [56320/60000 (93%)]\tLoss: 0.063509\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.1125, Accuracy: (97%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.069850\n",
            "Train Epoch: 6 [5120/60000 (8%)]\tLoss: 0.038732\n",
            "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.040144\n",
            "Train Epoch: 6 [15360/60000 (25%)]\tLoss: 0.031522\n",
            "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 0.045304\n",
            "Train Epoch: 6 [25600/60000 (42%)]\tLoss: 0.024728\n",
            "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.055840\n",
            "Train Epoch: 6 [35840/60000 (59%)]\tLoss: 0.035257\n",
            "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.066448\n",
            "Train Epoch: 6 [46080/60000 (76%)]\tLoss: 0.037798\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.063738\n",
            "Train Epoch: 6 [56320/60000 (93%)]\tLoss: 0.024177\n",
            "Train Accuracy: (99%) \n",
            "\n",
            "Average loss: 0.1446, Accuracy: (96%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.067504\n",
            "Train Epoch: 7 [5120/60000 (8%)]\tLoss: 0.035175\n",
            "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.009605\n",
            "Train Epoch: 7 [15360/60000 (25%)]\tLoss: 0.054376\n",
            "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.051084\n",
            "Train Epoch: 7 [25600/60000 (42%)]\tLoss: 0.034546\n",
            "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.041355\n",
            "Train Epoch: 7 [35840/60000 (59%)]\tLoss: 0.044939\n",
            "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 0.075246\n",
            "Train Epoch: 7 [46080/60000 (76%)]\tLoss: 0.041837\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.026263\n",
            "Train Epoch: 7 [56320/60000 (93%)]\tLoss: 0.022391\n",
            "Train Accuracy: (99%) \n",
            "\n",
            "Average loss: 0.0841, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.054090\n",
            "Train Epoch: 8 [5120/60000 (8%)]\tLoss: 0.022918\n",
            "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.015210\n",
            "Train Epoch: 8 [15360/60000 (25%)]\tLoss: 0.049221\n",
            "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 0.046686\n",
            "Train Epoch: 8 [25600/60000 (42%)]\tLoss: 0.032124\n",
            "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.039682\n",
            "Train Epoch: 8 [35840/60000 (59%)]\tLoss: 0.031896\n",
            "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 0.069106\n",
            "Train Epoch: 8 [46080/60000 (76%)]\tLoss: 0.021093\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.019236\n",
            "Train Epoch: 8 [56320/60000 (93%)]\tLoss: 0.018811\n",
            "Train Accuracy: (99%) \n",
            "\n",
            "Average loss: 0.1032, Accuracy: (97%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.061264\n",
            "Train Epoch: 9 [5120/60000 (8%)]\tLoss: 0.039297\n",
            "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 0.030592\n",
            "Train Epoch: 9 [15360/60000 (25%)]\tLoss: 0.032707\n",
            "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 0.023360\n",
            "Train Epoch: 9 [25600/60000 (42%)]\tLoss: 0.026276\n",
            "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 0.026711\n",
            "Train Epoch: 9 [35840/60000 (59%)]\tLoss: 0.034779\n",
            "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 0.026722\n",
            "Train Epoch: 9 [46080/60000 (76%)]\tLoss: 0.038776\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.032208\n",
            "Train Epoch: 9 [56320/60000 (93%)]\tLoss: 0.016559\n",
            "Train Accuracy: (99%) \n",
            "\n",
            "Average loss: 0.0932, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.037133\n",
            "Train Epoch: 10 [5120/60000 (8%)]\tLoss: 0.012575\n",
            "Train Epoch: 10 [10240/60000 (17%)]\tLoss: 0.005625\n",
            "Train Epoch: 10 [15360/60000 (25%)]\tLoss: 0.005676\n",
            "Train Epoch: 10 [20480/60000 (34%)]\tLoss: 0.013566\n",
            "Train Epoch: 10 [25600/60000 (42%)]\tLoss: 0.005313\n",
            "Train Epoch: 10 [30720/60000 (51%)]\tLoss: 0.015403\n",
            "Train Epoch: 10 [35840/60000 (59%)]\tLoss: 0.033682\n",
            "Train Epoch: 10 [40960/60000 (68%)]\tLoss: 0.037601\n",
            "Train Epoch: 10 [46080/60000 (76%)]\tLoss: 0.038731\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.014321\n",
            "Train Epoch: 10 [56320/60000 (93%)]\tLoss: 0.018091\n",
            "Train Accuracy: (99%) \n",
            "\n",
            "Average loss: 0.0942, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.034531\n",
            "Train Epoch: 11 [5120/60000 (8%)]\tLoss: 0.012171\n",
            "Train Epoch: 11 [10240/60000 (17%)]\tLoss: 0.023385\n",
            "Train Epoch: 11 [15360/60000 (25%)]\tLoss: 0.011232\n",
            "Train Epoch: 11 [20480/60000 (34%)]\tLoss: 0.007533\n",
            "Train Epoch: 11 [25600/60000 (42%)]\tLoss: 0.014813\n",
            "Train Epoch: 11 [30720/60000 (51%)]\tLoss: 0.014787\n",
            "Train Epoch: 11 [35840/60000 (59%)]\tLoss: 0.019302\n",
            "Train Epoch: 11 [40960/60000 (68%)]\tLoss: 0.015967\n",
            "Train Epoch: 11 [46080/60000 (76%)]\tLoss: 0.037307\n",
            "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.025439\n",
            "Train Epoch: 11 [56320/60000 (93%)]\tLoss: 0.029560\n",
            "Train Accuracy: (99%) \n",
            "\n",
            "Average loss: 0.1126, Accuracy: (97%)\n",
            "\n",
            "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.031500\n",
            "Train Epoch: 12 [5120/60000 (8%)]\tLoss: 0.019599\n",
            "Train Epoch: 12 [10240/60000 (17%)]\tLoss: 0.022911\n",
            "Train Epoch: 12 [15360/60000 (25%)]\tLoss: 0.012996\n",
            "Train Epoch: 12 [20480/60000 (34%)]\tLoss: 0.006202\n",
            "Train Epoch: 12 [25600/60000 (42%)]\tLoss: 0.006348\n",
            "Train Epoch: 12 [30720/60000 (51%)]\tLoss: 0.021045\n",
            "Train Epoch: 12 [35840/60000 (59%)]\tLoss: 0.011833\n",
            "Train Epoch: 12 [40960/60000 (68%)]\tLoss: 0.021525\n",
            "Train Epoch: 12 [46080/60000 (76%)]\tLoss: 0.050103\n",
            "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.031798\n",
            "Train Epoch: 12 [56320/60000 (93%)]\tLoss: 0.031022\n",
            "Train Accuracy: (99%) \n",
            "\n",
            "Average loss: 0.1338, Accuracy: (97%)\n",
            "\n",
            "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.034596\n",
            "Train Epoch: 13 [5120/60000 (8%)]\tLoss: 0.012812\n",
            "Train Epoch: 13 [10240/60000 (17%)]\tLoss: 0.007675\n",
            "Train Epoch: 13 [15360/60000 (25%)]\tLoss: 0.005358\n",
            "Train Epoch: 13 [20480/60000 (34%)]\tLoss: 0.010109\n",
            "Train Epoch: 13 [25600/60000 (42%)]\tLoss: 0.005877\n",
            "Train Epoch: 13 [30720/60000 (51%)]\tLoss: 0.027425\n",
            "Train Epoch: 13 [35840/60000 (59%)]\tLoss: 0.049752\n",
            "Train Epoch: 13 [40960/60000 (68%)]\tLoss: 0.018315\n",
            "Train Epoch: 13 [46080/60000 (76%)]\tLoss: 0.016073\n",
            "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.007650\n",
            "Train Epoch: 13 [56320/60000 (93%)]\tLoss: 0.011952\n",
            "Train Accuracy: (99%) \n",
            "\n",
            "Average loss: 0.0962, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.016734\n",
            "Train Epoch: 14 [5120/60000 (8%)]\tLoss: 0.007038\n",
            "Train Epoch: 14 [10240/60000 (17%)]\tLoss: 0.002741\n",
            "Train Epoch: 14 [15360/60000 (25%)]\tLoss: 0.024935\n",
            "Train Epoch: 14 [20480/60000 (34%)]\tLoss: 0.014704\n",
            "Train Epoch: 14 [25600/60000 (42%)]\tLoss: 0.017157\n",
            "Train Epoch: 14 [30720/60000 (51%)]\tLoss: 0.003155\n",
            "Train Epoch: 14 [35840/60000 (59%)]\tLoss: 0.009654\n",
            "Train Epoch: 14 [40960/60000 (68%)]\tLoss: 0.012902\n",
            "Train Epoch: 14 [46080/60000 (76%)]\tLoss: 0.008783\n",
            "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.055074\n",
            "Train Epoch: 14 [56320/60000 (93%)]\tLoss: 0.017770\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.1182, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.019615\n",
            "Train Epoch: 15 [5120/60000 (8%)]\tLoss: 0.022930\n",
            "Train Epoch: 15 [10240/60000 (17%)]\tLoss: 0.025230\n",
            "Train Epoch: 15 [15360/60000 (25%)]\tLoss: 0.012689\n",
            "Train Epoch: 15 [20480/60000 (34%)]\tLoss: 0.004037\n",
            "Train Epoch: 15 [25600/60000 (42%)]\tLoss: 0.017916\n",
            "Train Epoch: 15 [30720/60000 (51%)]\tLoss: 0.022978\n",
            "Train Epoch: 15 [35840/60000 (59%)]\tLoss: 0.014544\n",
            "Train Epoch: 15 [40960/60000 (68%)]\tLoss: 0.025139\n",
            "Train Epoch: 15 [46080/60000 (76%)]\tLoss: 0.019152\n",
            "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.040581\n",
            "Train Epoch: 15 [56320/60000 (93%)]\tLoss: 0.025896\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.1230, Accuracy: (97%)\n",
            "\n",
            "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.034746\n",
            "Train Epoch: 16 [5120/60000 (8%)]\tLoss: 0.025517\n",
            "Train Epoch: 16 [10240/60000 (17%)]\tLoss: 0.014107\n",
            "Train Epoch: 16 [15360/60000 (25%)]\tLoss: 0.014983\n",
            "Train Epoch: 16 [20480/60000 (34%)]\tLoss: 0.010840\n",
            "Train Epoch: 16 [25600/60000 (42%)]\tLoss: 0.002255\n",
            "Train Epoch: 16 [30720/60000 (51%)]\tLoss: 0.016137\n",
            "Train Epoch: 16 [35840/60000 (59%)]\tLoss: 0.008413\n",
            "Train Epoch: 16 [40960/60000 (68%)]\tLoss: 0.025955\n",
            "Train Epoch: 16 [46080/60000 (76%)]\tLoss: 0.023661\n",
            "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 0.008132\n",
            "Train Epoch: 16 [56320/60000 (93%)]\tLoss: 0.001031\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.1072, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.014591\n",
            "Train Epoch: 17 [5120/60000 (8%)]\tLoss: 0.012712\n",
            "Train Epoch: 17 [10240/60000 (17%)]\tLoss: 0.008355\n",
            "Train Epoch: 17 [15360/60000 (25%)]\tLoss: 0.022899\n",
            "Train Epoch: 17 [20480/60000 (34%)]\tLoss: 0.025843\n",
            "Train Epoch: 17 [25600/60000 (42%)]\tLoss: 0.003689\n",
            "Train Epoch: 17 [30720/60000 (51%)]\tLoss: 0.003358\n",
            "Train Epoch: 17 [35840/60000 (59%)]\tLoss: 0.018976\n",
            "Train Epoch: 17 [40960/60000 (68%)]\tLoss: 0.006634\n",
            "Train Epoch: 17 [46080/60000 (76%)]\tLoss: 0.010851\n",
            "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 0.026387\n",
            "Train Epoch: 17 [56320/60000 (93%)]\tLoss: 0.025685\n",
            "Train Accuracy: (99%) \n",
            "\n",
            "Average loss: 0.0947, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.009016\n",
            "Train Epoch: 18 [5120/60000 (8%)]\tLoss: 0.003142\n",
            "Train Epoch: 18 [10240/60000 (17%)]\tLoss: 0.009545\n",
            "Train Epoch: 18 [15360/60000 (25%)]\tLoss: 0.014917\n",
            "Train Epoch: 18 [20480/60000 (34%)]\tLoss: 0.005140\n",
            "Train Epoch: 18 [25600/60000 (42%)]\tLoss: 0.031934\n",
            "Train Epoch: 18 [30720/60000 (51%)]\tLoss: 0.017053\n",
            "Train Epoch: 18 [35840/60000 (59%)]\tLoss: 0.023584\n",
            "Train Epoch: 18 [40960/60000 (68%)]\tLoss: 0.022285\n",
            "Train Epoch: 18 [46080/60000 (76%)]\tLoss: 0.004073\n",
            "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 0.022158\n",
            "Train Epoch: 18 [56320/60000 (93%)]\tLoss: 0.009771\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.1147, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.031418\n",
            "Train Epoch: 19 [5120/60000 (8%)]\tLoss: 0.023210\n",
            "Train Epoch: 19 [10240/60000 (17%)]\tLoss: 0.002151\n",
            "Train Epoch: 19 [15360/60000 (25%)]\tLoss: 0.003191\n",
            "Train Epoch: 19 [20480/60000 (34%)]\tLoss: 0.008576\n",
            "Train Epoch: 19 [25600/60000 (42%)]\tLoss: 0.007733\n",
            "Train Epoch: 19 [30720/60000 (51%)]\tLoss: 0.010221\n",
            "Train Epoch: 19 [35840/60000 (59%)]\tLoss: 0.027288\n",
            "Train Epoch: 19 [40960/60000 (68%)]\tLoss: 0.010406\n",
            "Train Epoch: 19 [46080/60000 (76%)]\tLoss: 0.007988\n",
            "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 0.017869\n",
            "Train Epoch: 19 [56320/60000 (93%)]\tLoss: 0.010416\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.0934, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.005504\n",
            "Train Epoch: 20 [5120/60000 (8%)]\tLoss: 0.011370\n",
            "Train Epoch: 20 [10240/60000 (17%)]\tLoss: 0.013723\n",
            "Train Epoch: 20 [15360/60000 (25%)]\tLoss: 0.000710\n",
            "Train Epoch: 20 [20480/60000 (34%)]\tLoss: 0.003544\n",
            "Train Epoch: 20 [25600/60000 (42%)]\tLoss: 0.012191\n",
            "Train Epoch: 20 [30720/60000 (51%)]\tLoss: 0.000834\n",
            "Train Epoch: 20 [35840/60000 (59%)]\tLoss: 0.017734\n",
            "Train Epoch: 20 [40960/60000 (68%)]\tLoss: 0.004153\n",
            "Train Epoch: 20 [46080/60000 (76%)]\tLoss: 0.014545\n",
            "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 0.016352\n",
            "Train Epoch: 20 [56320/60000 (93%)]\tLoss: 0.006143\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.1162, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 21 [0/60000 (0%)]\tLoss: 0.023099\n",
            "Train Epoch: 21 [5120/60000 (8%)]\tLoss: 0.021189\n",
            "Train Epoch: 21 [10240/60000 (17%)]\tLoss: 0.019040\n",
            "Train Epoch: 21 [15360/60000 (25%)]\tLoss: 0.001213\n",
            "Train Epoch: 21 [20480/60000 (34%)]\tLoss: 0.015648\n",
            "Train Epoch: 21 [25600/60000 (42%)]\tLoss: 0.002007\n",
            "Train Epoch: 21 [30720/60000 (51%)]\tLoss: 0.007250\n",
            "Train Epoch: 21 [35840/60000 (59%)]\tLoss: 0.013362\n",
            "Train Epoch: 21 [40960/60000 (68%)]\tLoss: 0.008675\n",
            "Train Epoch: 21 [46080/60000 (76%)]\tLoss: 0.022597\n",
            "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 0.026065\n",
            "Train Epoch: 21 [56320/60000 (93%)]\tLoss: 0.011225\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.1125, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 22 [0/60000 (0%)]\tLoss: 0.019954\n",
            "Train Epoch: 22 [5120/60000 (8%)]\tLoss: 0.005323\n",
            "Train Epoch: 22 [10240/60000 (17%)]\tLoss: 0.003546\n",
            "Train Epoch: 22 [15360/60000 (25%)]\tLoss: 0.001225\n",
            "Train Epoch: 22 [20480/60000 (34%)]\tLoss: 0.029357\n",
            "Train Epoch: 22 [25600/60000 (42%)]\tLoss: 0.006142\n",
            "Train Epoch: 22 [30720/60000 (51%)]\tLoss: 0.021591\n",
            "Train Epoch: 22 [35840/60000 (59%)]\tLoss: 0.005196\n",
            "Train Epoch: 22 [40960/60000 (68%)]\tLoss: 0.035989\n",
            "Train Epoch: 22 [46080/60000 (76%)]\tLoss: 0.006406\n",
            "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 0.025767\n",
            "Train Epoch: 22 [56320/60000 (93%)]\tLoss: 0.004363\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.0987, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 23 [0/60000 (0%)]\tLoss: 0.002482\n",
            "Train Epoch: 23 [5120/60000 (8%)]\tLoss: 0.006876\n",
            "Train Epoch: 23 [10240/60000 (17%)]\tLoss: 0.003045\n",
            "Train Epoch: 23 [15360/60000 (25%)]\tLoss: 0.005693\n",
            "Train Epoch: 23 [20480/60000 (34%)]\tLoss: 0.005246\n",
            "Train Epoch: 23 [25600/60000 (42%)]\tLoss: 0.004132\n",
            "Train Epoch: 23 [30720/60000 (51%)]\tLoss: 0.008378\n",
            "Train Epoch: 23 [35840/60000 (59%)]\tLoss: 0.007253\n",
            "Train Epoch: 23 [40960/60000 (68%)]\tLoss: 0.004397\n",
            "Train Epoch: 23 [46080/60000 (76%)]\tLoss: 0.013568\n",
            "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 0.006153\n",
            "Train Epoch: 23 [56320/60000 (93%)]\tLoss: 0.013079\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.1027, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 24 [0/60000 (0%)]\tLoss: 0.010087\n",
            "Train Epoch: 24 [5120/60000 (8%)]\tLoss: 0.001614\n",
            "Train Epoch: 24 [10240/60000 (17%)]\tLoss: 0.004817\n",
            "Train Epoch: 24 [15360/60000 (25%)]\tLoss: 0.001756\n",
            "Train Epoch: 24 [20480/60000 (34%)]\tLoss: 0.010510\n",
            "Train Epoch: 24 [25600/60000 (42%)]\tLoss: 0.011985\n",
            "Train Epoch: 24 [30720/60000 (51%)]\tLoss: 0.005797\n",
            "Train Epoch: 24 [35840/60000 (59%)]\tLoss: 0.009589\n",
            "Train Epoch: 24 [40960/60000 (68%)]\tLoss: 0.005848\n",
            "Train Epoch: 24 [46080/60000 (76%)]\tLoss: 0.053440\n",
            "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 0.004502\n",
            "Train Epoch: 24 [56320/60000 (93%)]\tLoss: 0.001135\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.0907, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 25 [0/60000 (0%)]\tLoss: 0.005439\n",
            "Train Epoch: 25 [5120/60000 (8%)]\tLoss: 0.006024\n",
            "Train Epoch: 25 [10240/60000 (17%)]\tLoss: 0.005455\n",
            "Train Epoch: 25 [15360/60000 (25%)]\tLoss: 0.002051\n",
            "Train Epoch: 25 [20480/60000 (34%)]\tLoss: 0.002232\n",
            "Train Epoch: 25 [25600/60000 (42%)]\tLoss: 0.009630\n",
            "Train Epoch: 25 [30720/60000 (51%)]\tLoss: 0.001759\n",
            "Train Epoch: 25 [35840/60000 (59%)]\tLoss: 0.010926\n",
            "Train Epoch: 25 [40960/60000 (68%)]\tLoss: 0.023335\n",
            "Train Epoch: 25 [46080/60000 (76%)]\tLoss: 0.006283\n",
            "Train Epoch: 25 [51200/60000 (85%)]\tLoss: 0.025875\n",
            "Train Epoch: 25 [56320/60000 (93%)]\tLoss: 0.001621\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.1025, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 26 [0/60000 (0%)]\tLoss: 0.017056\n",
            "Train Epoch: 26 [5120/60000 (8%)]\tLoss: 0.013595\n",
            "Train Epoch: 26 [10240/60000 (17%)]\tLoss: 0.001739\n",
            "Train Epoch: 26 [15360/60000 (25%)]\tLoss: 0.001919\n",
            "Train Epoch: 26 [20480/60000 (34%)]\tLoss: 0.021856\n",
            "Train Epoch: 26 [25600/60000 (42%)]\tLoss: 0.016704\n",
            "Train Epoch: 26 [30720/60000 (51%)]\tLoss: 0.001590\n",
            "Train Epoch: 26 [35840/60000 (59%)]\tLoss: 0.007283\n",
            "Train Epoch: 26 [40960/60000 (68%)]\tLoss: 0.006919\n",
            "Train Epoch: 26 [46080/60000 (76%)]\tLoss: 0.005011\n",
            "Train Epoch: 26 [51200/60000 (85%)]\tLoss: 0.005216\n",
            "Train Epoch: 26 [56320/60000 (93%)]\tLoss: 0.001667\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.1154, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 27 [0/60000 (0%)]\tLoss: 0.012072\n",
            "Train Epoch: 27 [5120/60000 (8%)]\tLoss: 0.000573\n",
            "Train Epoch: 27 [10240/60000 (17%)]\tLoss: 0.000989\n",
            "Train Epoch: 27 [15360/60000 (25%)]\tLoss: 0.002832\n",
            "Train Epoch: 27 [20480/60000 (34%)]\tLoss: 0.005001\n",
            "Train Epoch: 27 [25600/60000 (42%)]\tLoss: 0.007017\n",
            "Train Epoch: 27 [30720/60000 (51%)]\tLoss: 0.020828\n",
            "Train Epoch: 27 [35840/60000 (59%)]\tLoss: 0.044202\n",
            "Train Epoch: 27 [40960/60000 (68%)]\tLoss: 0.008198\n",
            "Train Epoch: 27 [46080/60000 (76%)]\tLoss: 0.005538\n",
            "Train Epoch: 27 [51200/60000 (85%)]\tLoss: 0.015890\n",
            "Train Epoch: 27 [56320/60000 (93%)]\tLoss: 0.022881\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.0916, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 28 [0/60000 (0%)]\tLoss: 0.005132\n",
            "Train Epoch: 28 [5120/60000 (8%)]\tLoss: 0.002099\n",
            "Train Epoch: 28 [10240/60000 (17%)]\tLoss: 0.008921\n",
            "Train Epoch: 28 [15360/60000 (25%)]\tLoss: 0.002390\n",
            "Train Epoch: 28 [20480/60000 (34%)]\tLoss: 0.007396\n",
            "Train Epoch: 28 [25600/60000 (42%)]\tLoss: 0.005873\n",
            "Train Epoch: 28 [30720/60000 (51%)]\tLoss: 0.013134\n",
            "Train Epoch: 28 [35840/60000 (59%)]\tLoss: 0.001919\n",
            "Train Epoch: 28 [40960/60000 (68%)]\tLoss: 0.017491\n",
            "Train Epoch: 28 [46080/60000 (76%)]\tLoss: 0.011564\n",
            "Train Epoch: 28 [51200/60000 (85%)]\tLoss: 0.001626\n",
            "Train Epoch: 28 [56320/60000 (93%)]\tLoss: 0.005451\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.0967, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 29 [0/60000 (0%)]\tLoss: 0.004223\n",
            "Train Epoch: 29 [5120/60000 (8%)]\tLoss: 0.002683\n",
            "Train Epoch: 29 [10240/60000 (17%)]\tLoss: 0.000845\n",
            "Train Epoch: 29 [15360/60000 (25%)]\tLoss: 0.008493\n",
            "Train Epoch: 29 [20480/60000 (34%)]\tLoss: 0.008996\n",
            "Train Epoch: 29 [25600/60000 (42%)]\tLoss: 0.006031\n",
            "Train Epoch: 29 [30720/60000 (51%)]\tLoss: 0.001075\n",
            "Train Epoch: 29 [35840/60000 (59%)]\tLoss: 0.002213\n",
            "Train Epoch: 29 [40960/60000 (68%)]\tLoss: 0.005456\n",
            "Train Epoch: 29 [46080/60000 (76%)]\tLoss: 0.004954\n",
            "Train Epoch: 29 [51200/60000 (85%)]\tLoss: 0.010476\n",
            "Train Epoch: 29 [56320/60000 (93%)]\tLoss: 0.000378\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.0803, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 30 [0/60000 (0%)]\tLoss: 0.003524\n",
            "Train Epoch: 30 [5120/60000 (8%)]\tLoss: 0.001088\n",
            "Train Epoch: 30 [10240/60000 (17%)]\tLoss: 0.006676\n",
            "Train Epoch: 30 [15360/60000 (25%)]\tLoss: 0.006227\n",
            "Train Epoch: 30 [20480/60000 (34%)]\tLoss: 0.004813\n",
            "Train Epoch: 30 [25600/60000 (42%)]\tLoss: 0.002832\n",
            "Train Epoch: 30 [30720/60000 (51%)]\tLoss: 0.000922\n",
            "Train Epoch: 30 [35840/60000 (59%)]\tLoss: 0.000870\n",
            "Train Epoch: 30 [40960/60000 (68%)]\tLoss: 0.001456\n",
            "Train Epoch: 30 [46080/60000 (76%)]\tLoss: 0.003934\n",
            "Train Epoch: 30 [51200/60000 (85%)]\tLoss: 0.010040\n",
            "Train Epoch: 30 [56320/60000 (93%)]\tLoss: 0.005596\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.0987, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 31 [0/60000 (0%)]\tLoss: 0.000663\n",
            "Train Epoch: 31 [5120/60000 (8%)]\tLoss: 0.007062\n",
            "Train Epoch: 31 [10240/60000 (17%)]\tLoss: 0.006384\n",
            "Train Epoch: 31 [15360/60000 (25%)]\tLoss: 0.000773\n",
            "Train Epoch: 31 [20480/60000 (34%)]\tLoss: 0.000390\n",
            "Train Epoch: 31 [25600/60000 (42%)]\tLoss: 0.001543\n",
            "Train Epoch: 31 [30720/60000 (51%)]\tLoss: 0.000289\n",
            "Train Epoch: 31 [35840/60000 (59%)]\tLoss: 0.004731\n",
            "Train Epoch: 31 [40960/60000 (68%)]\tLoss: 0.001484\n",
            "Train Epoch: 31 [46080/60000 (76%)]\tLoss: 0.027127\n",
            "Train Epoch: 31 [51200/60000 (85%)]\tLoss: 0.012809\n",
            "Train Epoch: 31 [56320/60000 (93%)]\tLoss: 0.028986\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.1364, Accuracy: (97%)\n",
            "\n",
            "Train Epoch: 32 [0/60000 (0%)]\tLoss: 0.039508\n",
            "Train Epoch: 32 [5120/60000 (8%)]\tLoss: 0.007720\n",
            "Train Epoch: 32 [10240/60000 (17%)]\tLoss: 0.009236\n",
            "Train Epoch: 32 [15360/60000 (25%)]\tLoss: 0.010802\n",
            "Train Epoch: 32 [20480/60000 (34%)]\tLoss: 0.008358\n",
            "Train Epoch: 32 [25600/60000 (42%)]\tLoss: 0.000805\n",
            "Train Epoch: 32 [30720/60000 (51%)]\tLoss: 0.004293\n",
            "Train Epoch: 32 [35840/60000 (59%)]\tLoss: 0.001777\n",
            "Train Epoch: 32 [40960/60000 (68%)]\tLoss: 0.003943\n",
            "Train Epoch: 32 [46080/60000 (76%)]\tLoss: 0.007102\n",
            "Train Epoch: 32 [51200/60000 (85%)]\tLoss: 0.030737\n",
            "Train Epoch: 32 [56320/60000 (93%)]\tLoss: 0.002566\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.1169, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 33 [0/60000 (0%)]\tLoss: 0.016231\n",
            "Train Epoch: 33 [5120/60000 (8%)]\tLoss: 0.011309\n",
            "Train Epoch: 33 [10240/60000 (17%)]\tLoss: 0.027225\n",
            "Train Epoch: 33 [15360/60000 (25%)]\tLoss: 0.006317\n",
            "Train Epoch: 33 [20480/60000 (34%)]\tLoss: 0.001370\n",
            "Train Epoch: 33 [25600/60000 (42%)]\tLoss: 0.003563\n",
            "Train Epoch: 33 [30720/60000 (51%)]\tLoss: 0.006877\n",
            "Train Epoch: 33 [35840/60000 (59%)]\tLoss: 0.007239\n",
            "Train Epoch: 33 [40960/60000 (68%)]\tLoss: 0.003478\n",
            "Train Epoch: 33 [46080/60000 (76%)]\tLoss: 0.012475\n",
            "Train Epoch: 33 [51200/60000 (85%)]\tLoss: 0.016164\n",
            "Train Epoch: 33 [56320/60000 (93%)]\tLoss: 0.002414\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.1118, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 34 [0/60000 (0%)]\tLoss: 0.010319\n",
            "Train Epoch: 34 [5120/60000 (8%)]\tLoss: 0.001233\n",
            "Train Epoch: 34 [10240/60000 (17%)]\tLoss: 0.001628\n",
            "Train Epoch: 34 [15360/60000 (25%)]\tLoss: 0.000317\n",
            "Train Epoch: 34 [20480/60000 (34%)]\tLoss: 0.004383\n",
            "Train Epoch: 34 [25600/60000 (42%)]\tLoss: 0.010284\n",
            "Train Epoch: 34 [30720/60000 (51%)]\tLoss: 0.004977\n",
            "Train Epoch: 34 [35840/60000 (59%)]\tLoss: 0.002152\n",
            "Train Epoch: 34 [40960/60000 (68%)]\tLoss: 0.000548\n",
            "Train Epoch: 34 [46080/60000 (76%)]\tLoss: 0.002473\n",
            "Train Epoch: 34 [51200/60000 (85%)]\tLoss: 0.000438\n",
            "Train Epoch: 34 [56320/60000 (93%)]\tLoss: 0.002985\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.1074, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 35 [0/60000 (0%)]\tLoss: 0.003043\n",
            "Train Epoch: 35 [5120/60000 (8%)]\tLoss: 0.000568\n",
            "Train Epoch: 35 [10240/60000 (17%)]\tLoss: 0.005713\n",
            "Train Epoch: 35 [15360/60000 (25%)]\tLoss: 0.001837\n",
            "Train Epoch: 35 [20480/60000 (34%)]\tLoss: 0.002278\n",
            "Train Epoch: 35 [25600/60000 (42%)]\tLoss: 0.003405\n",
            "Train Epoch: 35 [30720/60000 (51%)]\tLoss: 0.001499\n",
            "Train Epoch: 35 [35840/60000 (59%)]\tLoss: 0.008539\n",
            "Train Epoch: 35 [40960/60000 (68%)]\tLoss: 0.003174\n",
            "Train Epoch: 35 [46080/60000 (76%)]\tLoss: 0.005396\n",
            "Train Epoch: 35 [51200/60000 (85%)]\tLoss: 0.011234\n",
            "Train Epoch: 35 [56320/60000 (93%)]\tLoss: 0.003415\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.1026, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 36 [0/60000 (0%)]\tLoss: 0.000885\n",
            "Train Epoch: 36 [5120/60000 (8%)]\tLoss: 0.002837\n",
            "Train Epoch: 36 [10240/60000 (17%)]\tLoss: 0.011274\n",
            "Train Epoch: 36 [15360/60000 (25%)]\tLoss: 0.002645\n",
            "Train Epoch: 36 [20480/60000 (34%)]\tLoss: 0.015806\n",
            "Train Epoch: 36 [25600/60000 (42%)]\tLoss: 0.010721\n",
            "Train Epoch: 36 [30720/60000 (51%)]\tLoss: 0.007474\n",
            "Train Epoch: 36 [35840/60000 (59%)]\tLoss: 0.001371\n",
            "Train Epoch: 36 [40960/60000 (68%)]\tLoss: 0.013864\n",
            "Train Epoch: 36 [46080/60000 (76%)]\tLoss: 0.017071\n",
            "Train Epoch: 36 [51200/60000 (85%)]\tLoss: 0.016387\n",
            "Train Epoch: 36 [56320/60000 (93%)]\tLoss: 0.029587\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.1142, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 37 [0/60000 (0%)]\tLoss: 0.013492\n",
            "Train Epoch: 37 [5120/60000 (8%)]\tLoss: 0.002374\n",
            "Train Epoch: 37 [10240/60000 (17%)]\tLoss: 0.000418\n",
            "Train Epoch: 37 [15360/60000 (25%)]\tLoss: 0.001280\n",
            "Train Epoch: 37 [20480/60000 (34%)]\tLoss: 0.014953\n",
            "Train Epoch: 37 [25600/60000 (42%)]\tLoss: 0.035494\n",
            "Train Epoch: 37 [30720/60000 (51%)]\tLoss: 0.005840\n",
            "Train Epoch: 37 [35840/60000 (59%)]\tLoss: 0.007220\n",
            "Train Epoch: 37 [40960/60000 (68%)]\tLoss: 0.019475\n",
            "Train Epoch: 37 [46080/60000 (76%)]\tLoss: 0.016614\n",
            "Train Epoch: 37 [51200/60000 (85%)]\tLoss: 0.006034\n",
            "Train Epoch: 37 [56320/60000 (93%)]\tLoss: 0.006087\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.0933, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 38 [0/60000 (0%)]\tLoss: 0.003144\n",
            "Train Epoch: 38 [5120/60000 (8%)]\tLoss: 0.002111\n",
            "Train Epoch: 38 [10240/60000 (17%)]\tLoss: 0.001338\n",
            "Train Epoch: 38 [15360/60000 (25%)]\tLoss: 0.014856\n",
            "Train Epoch: 38 [20480/60000 (34%)]\tLoss: 0.001603\n",
            "Train Epoch: 38 [25600/60000 (42%)]\tLoss: 0.001968\n",
            "Train Epoch: 38 [30720/60000 (51%)]\tLoss: 0.008355\n",
            "Train Epoch: 38 [35840/60000 (59%)]\tLoss: 0.013499\n",
            "Train Epoch: 38 [40960/60000 (68%)]\tLoss: 0.037364\n",
            "Train Epoch: 38 [46080/60000 (76%)]\tLoss: 0.015618\n",
            "Train Epoch: 38 [51200/60000 (85%)]\tLoss: 0.026105\n",
            "Train Epoch: 38 [56320/60000 (93%)]\tLoss: 0.002029\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.0970, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 39 [0/60000 (0%)]\tLoss: 0.014076\n",
            "Train Epoch: 39 [5120/60000 (8%)]\tLoss: 0.007124\n",
            "Train Epoch: 39 [10240/60000 (17%)]\tLoss: 0.000496\n",
            "Train Epoch: 39 [15360/60000 (25%)]\tLoss: 0.001277\n",
            "Train Epoch: 39 [20480/60000 (34%)]\tLoss: 0.003618\n",
            "Train Epoch: 39 [25600/60000 (42%)]\tLoss: 0.000122\n",
            "Train Epoch: 39 [30720/60000 (51%)]\tLoss: 0.000289\n",
            "Train Epoch: 39 [35840/60000 (59%)]\tLoss: 0.001858\n",
            "Train Epoch: 39 [40960/60000 (68%)]\tLoss: 0.000092\n",
            "Train Epoch: 39 [46080/60000 (76%)]\tLoss: 0.001780\n",
            "Train Epoch: 39 [51200/60000 (85%)]\tLoss: 0.006393\n",
            "Train Epoch: 39 [56320/60000 (93%)]\tLoss: 0.003891\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.0903, Accuracy: (99%)\n",
            "\n",
            "Train Epoch: 40 [0/60000 (0%)]\tLoss: 0.000204\n",
            "Train Epoch: 40 [5120/60000 (8%)]\tLoss: 0.000167\n",
            "Train Epoch: 40 [10240/60000 (17%)]\tLoss: 0.000458\n",
            "Train Epoch: 40 [15360/60000 (25%)]\tLoss: 0.000662\n",
            "Train Epoch: 40 [20480/60000 (34%)]\tLoss: 0.002994\n",
            "Train Epoch: 40 [25600/60000 (42%)]\tLoss: 0.004987\n",
            "Train Epoch: 40 [30720/60000 (51%)]\tLoss: 0.011832\n",
            "Train Epoch: 40 [35840/60000 (59%)]\tLoss: 0.004729\n",
            "Train Epoch: 40 [40960/60000 (68%)]\tLoss: 0.003023\n",
            "Train Epoch: 40 [46080/60000 (76%)]\tLoss: 0.001086\n",
            "Train Epoch: 40 [51200/60000 (85%)]\tLoss: 0.007857\n",
            "Train Epoch: 40 [56320/60000 (93%)]\tLoss: 0.002088\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.1160, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 41 [0/60000 (0%)]\tLoss: 0.010233\n",
            "Train Epoch: 41 [5120/60000 (8%)]\tLoss: 0.008225\n",
            "Train Epoch: 41 [10240/60000 (17%)]\tLoss: 0.009754\n",
            "Train Epoch: 41 [15360/60000 (25%)]\tLoss: 0.006729\n",
            "Train Epoch: 41 [20480/60000 (34%)]\tLoss: 0.013964\n",
            "Train Epoch: 41 [25600/60000 (42%)]\tLoss: 0.008059\n",
            "Train Epoch: 41 [30720/60000 (51%)]\tLoss: 0.003632\n",
            "Train Epoch: 41 [35840/60000 (59%)]\tLoss: 0.000476\n",
            "Train Epoch: 41 [40960/60000 (68%)]\tLoss: 0.000778\n",
            "Train Epoch: 41 [46080/60000 (76%)]\tLoss: 0.000326\n",
            "Train Epoch: 41 [51200/60000 (85%)]\tLoss: 0.008360\n",
            "Train Epoch: 41 [56320/60000 (93%)]\tLoss: 0.000168\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.1111, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 42 [0/60000 (0%)]\tLoss: 0.000459\n",
            "Train Epoch: 42 [5120/60000 (8%)]\tLoss: 0.004049\n",
            "Train Epoch: 42 [10240/60000 (17%)]\tLoss: 0.000507\n",
            "Train Epoch: 42 [15360/60000 (25%)]\tLoss: 0.001040\n",
            "Train Epoch: 42 [20480/60000 (34%)]\tLoss: 0.008169\n",
            "Train Epoch: 42 [25600/60000 (42%)]\tLoss: 0.010669\n",
            "Train Epoch: 42 [30720/60000 (51%)]\tLoss: 0.024268\n",
            "Train Epoch: 42 [35840/60000 (59%)]\tLoss: 0.014764\n",
            "Train Epoch: 42 [40960/60000 (68%)]\tLoss: 0.010949\n",
            "Train Epoch: 42 [46080/60000 (76%)]\tLoss: 0.020709\n",
            "Train Epoch: 42 [51200/60000 (85%)]\tLoss: 0.000271\n",
            "Train Epoch: 42 [56320/60000 (93%)]\tLoss: 0.005024\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.1024, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 43 [0/60000 (0%)]\tLoss: 0.006048\n",
            "Train Epoch: 43 [5120/60000 (8%)]\tLoss: 0.029696\n",
            "Train Epoch: 43 [10240/60000 (17%)]\tLoss: 0.003933\n",
            "Train Epoch: 43 [15360/60000 (25%)]\tLoss: 0.016379\n",
            "Train Epoch: 43 [20480/60000 (34%)]\tLoss: 0.001299\n",
            "Train Epoch: 43 [25600/60000 (42%)]\tLoss: 0.008390\n",
            "Train Epoch: 43 [30720/60000 (51%)]\tLoss: 0.005527\n",
            "Train Epoch: 43 [35840/60000 (59%)]\tLoss: 0.021226\n",
            "Train Epoch: 43 [40960/60000 (68%)]\tLoss: 0.002945\n",
            "Train Epoch: 43 [46080/60000 (76%)]\tLoss: 0.005125\n",
            "Train Epoch: 43 [51200/60000 (85%)]\tLoss: 0.003849\n",
            "Train Epoch: 43 [56320/60000 (93%)]\tLoss: 0.000413\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.1195, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 44 [0/60000 (0%)]\tLoss: 0.001482\n",
            "Train Epoch: 44 [5120/60000 (8%)]\tLoss: 0.024710\n",
            "Train Epoch: 44 [10240/60000 (17%)]\tLoss: 0.000257\n",
            "Train Epoch: 44 [15360/60000 (25%)]\tLoss: 0.030073\n",
            "Train Epoch: 44 [20480/60000 (34%)]\tLoss: 0.000802\n",
            "Train Epoch: 44 [25600/60000 (42%)]\tLoss: 0.001216\n",
            "Train Epoch: 44 [30720/60000 (51%)]\tLoss: 0.002121\n",
            "Train Epoch: 44 [35840/60000 (59%)]\tLoss: 0.021722\n",
            "Train Epoch: 44 [40960/60000 (68%)]\tLoss: 0.001849\n",
            "Train Epoch: 44 [46080/60000 (76%)]\tLoss: 0.003585\n",
            "Train Epoch: 44 [51200/60000 (85%)]\tLoss: 0.007084\n",
            "Train Epoch: 44 [56320/60000 (93%)]\tLoss: 0.001977\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.0852, Accuracy: (99%)\n",
            "\n",
            "Train Epoch: 45 [0/60000 (0%)]\tLoss: 0.002899\n",
            "Train Epoch: 45 [5120/60000 (8%)]\tLoss: 0.022004\n",
            "Train Epoch: 45 [10240/60000 (17%)]\tLoss: 0.003299\n",
            "Train Epoch: 45 [15360/60000 (25%)]\tLoss: 0.001944\n",
            "Train Epoch: 45 [20480/60000 (34%)]\tLoss: 0.004695\n",
            "Train Epoch: 45 [25600/60000 (42%)]\tLoss: 0.000109\n",
            "Train Epoch: 45 [30720/60000 (51%)]\tLoss: 0.004569\n",
            "Train Epoch: 45 [35840/60000 (59%)]\tLoss: 0.008227\n",
            "Train Epoch: 45 [40960/60000 (68%)]\tLoss: 0.009277\n",
            "Train Epoch: 45 [46080/60000 (76%)]\tLoss: 0.000526\n",
            "Train Epoch: 45 [51200/60000 (85%)]\tLoss: 0.000080\n",
            "Train Epoch: 45 [56320/60000 (93%)]\tLoss: 0.006648\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.1114, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 46 [0/60000 (0%)]\tLoss: 0.000805\n",
            "Train Epoch: 46 [5120/60000 (8%)]\tLoss: 0.000284\n",
            "Train Epoch: 46 [10240/60000 (17%)]\tLoss: 0.000999\n",
            "Train Epoch: 46 [15360/60000 (25%)]\tLoss: 0.001615\n",
            "Train Epoch: 46 [20480/60000 (34%)]\tLoss: 0.003913\n",
            "Train Epoch: 46 [25600/60000 (42%)]\tLoss: 0.000223\n",
            "Train Epoch: 46 [30720/60000 (51%)]\tLoss: 0.009763\n",
            "Train Epoch: 46 [35840/60000 (59%)]\tLoss: 0.000170\n",
            "Train Epoch: 46 [40960/60000 (68%)]\tLoss: 0.011870\n",
            "Train Epoch: 46 [46080/60000 (76%)]\tLoss: 0.007946\n",
            "Train Epoch: 46 [51200/60000 (85%)]\tLoss: 0.001178\n",
            "Train Epoch: 46 [56320/60000 (93%)]\tLoss: 0.010592\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.0998, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 47 [0/60000 (0%)]\tLoss: 0.000758\n",
            "Train Epoch: 47 [5120/60000 (8%)]\tLoss: 0.003987\n",
            "Train Epoch: 47 [10240/60000 (17%)]\tLoss: 0.001485\n",
            "Train Epoch: 47 [15360/60000 (25%)]\tLoss: 0.000921\n",
            "Train Epoch: 47 [20480/60000 (34%)]\tLoss: 0.004384\n",
            "Train Epoch: 47 [25600/60000 (42%)]\tLoss: 0.000891\n",
            "Train Epoch: 47 [30720/60000 (51%)]\tLoss: 0.027552\n",
            "Train Epoch: 47 [35840/60000 (59%)]\tLoss: 0.000555\n",
            "Train Epoch: 47 [40960/60000 (68%)]\tLoss: 0.025989\n",
            "Train Epoch: 47 [46080/60000 (76%)]\tLoss: 0.017713\n",
            "Train Epoch: 47 [51200/60000 (85%)]\tLoss: 0.007905\n",
            "Train Epoch: 47 [56320/60000 (93%)]\tLoss: 0.008194\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.1154, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 48 [0/60000 (0%)]\tLoss: 0.029261\n",
            "Train Epoch: 48 [5120/60000 (8%)]\tLoss: 0.005369\n",
            "Train Epoch: 48 [10240/60000 (17%)]\tLoss: 0.012209\n",
            "Train Epoch: 48 [15360/60000 (25%)]\tLoss: 0.001140\n",
            "Train Epoch: 48 [20480/60000 (34%)]\tLoss: 0.014547\n",
            "Train Epoch: 48 [25600/60000 (42%)]\tLoss: 0.001697\n",
            "Train Epoch: 48 [30720/60000 (51%)]\tLoss: 0.000481\n",
            "Train Epoch: 48 [35840/60000 (59%)]\tLoss: 0.011297\n",
            "Train Epoch: 48 [40960/60000 (68%)]\tLoss: 0.007041\n",
            "Train Epoch: 48 [46080/60000 (76%)]\tLoss: 0.011940\n",
            "Train Epoch: 48 [51200/60000 (85%)]\tLoss: 0.001764\n",
            "Train Epoch: 48 [56320/60000 (93%)]\tLoss: 0.000241\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.1208, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 49 [0/60000 (0%)]\tLoss: 0.000703\n",
            "Train Epoch: 49 [5120/60000 (8%)]\tLoss: 0.012523\n",
            "Train Epoch: 49 [10240/60000 (17%)]\tLoss: 0.002422\n",
            "Train Epoch: 49 [15360/60000 (25%)]\tLoss: 0.001740\n",
            "Train Epoch: 49 [20480/60000 (34%)]\tLoss: 0.000310\n",
            "Train Epoch: 49 [25600/60000 (42%)]\tLoss: 0.002701\n",
            "Train Epoch: 49 [30720/60000 (51%)]\tLoss: 0.001767\n",
            "Train Epoch: 49 [35840/60000 (59%)]\tLoss: 0.001321\n",
            "Train Epoch: 49 [40960/60000 (68%)]\tLoss: 0.001687\n",
            "Train Epoch: 49 [46080/60000 (76%)]\tLoss: 0.000080\n",
            "Train Epoch: 49 [51200/60000 (85%)]\tLoss: 0.003206\n",
            "Train Epoch: 49 [56320/60000 (93%)]\tLoss: 0.018324\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.1135, Accuracy: (98%)\n",
            "\n",
            "Train Epoch: 50 [0/60000 (0%)]\tLoss: 0.003636\n",
            "Train Epoch: 50 [5120/60000 (8%)]\tLoss: 0.000448\n",
            "Train Epoch: 50 [10240/60000 (17%)]\tLoss: 0.001114\n",
            "Train Epoch: 50 [15360/60000 (25%)]\tLoss: 0.005783\n",
            "Train Epoch: 50 [20480/60000 (34%)]\tLoss: 0.005845\n",
            "Train Epoch: 50 [25600/60000 (42%)]\tLoss: 0.002453\n",
            "Train Epoch: 50 [30720/60000 (51%)]\tLoss: 0.016868\n",
            "Train Epoch: 50 [35840/60000 (59%)]\tLoss: 0.000825\n",
            "Train Epoch: 50 [40960/60000 (68%)]\tLoss: 0.004151\n",
            "Train Epoch: 50 [46080/60000 (76%)]\tLoss: 0.000441\n",
            "Train Epoch: 50 [51200/60000 (85%)]\tLoss: 0.001783\n",
            "Train Epoch: 50 [56320/60000 (93%)]\tLoss: 0.013036\n",
            "Train Accuracy: (100%) \n",
            "\n",
            "Average loss: 0.1120, Accuracy: (98%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!pip install torch torchvision\n",
        "\n",
        "torch.save(model_a.state_dict(), f\"/content/drive/My Drive/mnist_mlp_{str(args_1.seed)}.pt\")\n",
        "\n",
        "# checkpoint = torch.load(f\"/content/drive/My Drive/{args_1.model}\")\n",
        "\n",
        "torch.save(model_b.state_dict(), f\"/content/drive/My Drive/mnist_mlp_{str(args_2.seed)}.pt\")\n",
        "\n",
        "# checkpoint = torch.load(f\"/content/drive/My Drive/{args_2.model}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUaoO_eDFABi",
        "outputId": "bbbefdc3-ca10-4772-f932-f73281236606"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "model_a_saved = MLP()\n",
        "model_b_saved = MLP()\n",
        "model_a_saved.load_state_dict(torch.load(\"/content/drive/My Drive/mnist_mlp_1.pt\"))\n",
        "model_b_saved.load_state_dict(torch.load(\"/content/drive/My Drive/mnist_mlp_2.pt\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-0yPMCFz61_",
        "outputId": "d61c3aef-9494-4e03-a1bb-d6d646b62077"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from utils.weight_matching import mlp_permutation_spec, weight_matching, apply_permutation\n",
        "# from utils.utils import flatten_params, lerp\n",
        "# from utils.plot import plot_interp_acc\n",
        "import argparse\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "# from utils.training import test\n",
        "from tqdm import tqdm\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# parser = argparse.ArgumentParser()\n",
        "# parser.add_argument(\"--model_a\", type=str, required=True)\n",
        "# parser.add_argument(\"--model_b\", type=str, required=True)\n",
        "# parser.add_argument(\"--seed\", type=int, default=0, help=\"Random seed\")\n",
        "# args = parser.parse_args()\n",
        "\n",
        "\n",
        "permutation_spec = mlp_permutation_spec(4)\n",
        "final_permutation = weight_matching(permutation_spec,\n",
        "                                    flatten_params(model_a_saved), flatten_params(model_b_saved))\n",
        "\n",
        "\n",
        "updated_params = apply_permutation(permutation_spec, final_permutation, flatten_params(model_b_saved))\n",
        "\n",
        "\n",
        "# test against mnist\n",
        "transform=transforms.Compose([\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize((0.1307,), (0.3081,))\n",
        "  ])\n",
        "test_kwargs = {'batch_size': 5000}\n",
        "train_kwargs = {'batch_size': 5000}\n",
        "dataset = datasets.MNIST('../data', train=False, download=True,\n",
        "                  transform=transform)\n",
        "dataset1 = datasets.MNIST('../data', train=True, download=True,\n",
        "                  transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(dataset, **test_kwargs)\n",
        "lambdas = torch.linspace(0, 1, steps=25)\n",
        "\n",
        "test_acc_interp_clever = []\n",
        "test_acc_interp_naive = []\n",
        "train_acc_interp_clever = []\n",
        "train_acc_interp_naive = []\n",
        "# naive\n",
        "model_b_saved.load_state_dict(torch.load(\"/content/drive/My Drive/mnist_mlp_2.pt\"))\n",
        "model_a_dict = copy.deepcopy(model_a_saved.state_dict())\n",
        "model_b_dict = copy.deepcopy(model_b_saved.state_dict())\n",
        "for lam in tqdm(lambdas):\n",
        "  naive_p = lerp(lam, model_a_dict, model_b_dict)\n",
        "  model_b_saved.load_state_dict(naive_p)\n",
        "  test_loss, acc = test(model_b_saved.cuda(), 'cuda', test_loader)\n",
        "  test_acc_interp_naive.append(acc)\n",
        "  train_loss, acc = test(model_b_saved.cuda(), 'cuda', train_loader)\n",
        "  train_acc_interp_naive.append(acc)\n",
        "\n",
        "# smart\n",
        "model_b_saved.load_state_dict(updated_params)\n",
        "model_b_saved.cuda()\n",
        "model_a_saved.cuda()\n",
        "model_a_dict = copy.deepcopy(model_a_saved.state_dict())\n",
        "model_b_dict = copy.deepcopy(model_b_saved.state_dict())\n",
        "for lam in tqdm(lambdas):\n",
        "  naive_p = lerp(lam, model_a_dict, model_b_dict)\n",
        "  model_b_saved.load_state_dict(naive_p)\n",
        "  test_loss, acc = test(model_b_saved.cuda(), 'cuda', test_loader)\n",
        "  test_acc_interp_clever.append(acc)\n",
        "  train_loss, acc = test(model_b_saved.cuda(), 'cuda', train_loader)\n",
        "  train_acc_interp_clever.append(acc)\n",
        "\n",
        "fig = plot_interp_acc(lambdas, train_acc_interp_naive, test_acc_interp_naive,\n",
        "                train_acc_interp_clever, test_acc_interp_clever)\n",
        "plt.savefig(f\"mnist_mlp_weight_matching_interp_accuracy_epoch.png\", dpi=300)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wdXH6Rzt0MXv",
        "outputId": "59b4cd48-fdf2-4f25-8476-2388ae670148"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0/P_0: 499.32867431640625\n",
            "0/P_2: 89.97660827636719\n",
            "0/P_3: 21.238574981689453\n",
            "0/P_1: 213.55636596679688\n",
            "1/P_3: 0.0\n",
            "1/P_1: 0.0\n",
            "1/P_2: 109.57341766357422\n",
            "1/P_0: 13.1912841796875\n",
            "2/P_1: 36.513885498046875\n",
            "2/P_2: 16.9544677734375\n",
            "2/P_0: 3.15313720703125\n",
            "2/P_3: 34.439029693603516\n",
            "3/P_3: 0.0\n",
            "3/P_0: 0.0\n",
            "3/P_1: 4.53521728515625\n",
            "3/P_2: 8.58795166015625\n",
            "4/P_2: 0.0\n",
            "4/P_0: 0.43841552734375\n",
            "4/P_3: 1.7426223754882812\n",
            "4/P_1: 1.507080078125\n",
            "5/P_1: 0.0\n",
            "5/P_2: 2.103424072265625\n",
            "5/P_3: 0.5877609252929688\n",
            "5/P_0: 0.36474609375\n",
            "6/P_2: 0.156402587890625\n",
            "6/P_1: 0.629150390625\n",
            "6/P_0: 0.096435546875\n",
            "6/P_3: 0.07738494873046875\n",
            "7/P_0: 0.0\n",
            "7/P_1: 0.2720947265625\n",
            "7/P_2: 0.602752685546875\n",
            "7/P_3: 0.42014312744140625\n",
            "8/P_2: 0.244964599609375\n",
            "8/P_1: 0.10687255859375\n",
            "8/P_0: 0.06011962890625\n",
            "8/P_3: 0.08878326416015625\n",
            "9/P_2: 0.240142822265625\n",
            "9/P_3: 0.018890380859375\n",
            "9/P_0: 0.0\n",
            "9/P_1: 0.037353515625\n",
            "10/P_1: 0.0\n",
            "10/P_0: 0.0\n",
            "10/P_2: 0.076385498046875\n",
            "10/P_3: 0.0220794677734375\n",
            "11/P_2: 0.030914306640625\n",
            "11/P_3: 0.0267791748046875\n",
            "11/P_0: 0.0\n",
            "11/P_1: 0.01629638671875\n",
            "12/P_0: 0.0\n",
            "12/P_1: 0.0\n",
            "12/P_3: 0.0\n",
            "12/P_2: 0.016754150390625\n",
            "13/P_2: 0.0\n",
            "13/P_0: 0.0\n",
            "13/P_1: 0.0140380859375\n",
            "13/P_3: 0.02276611328125\n",
            "14/P_3: 0.0\n",
            "14/P_2: 0.10614013671875\n",
            "14/P_0: 0.0\n",
            "14/P_1: 0.0\n",
            "15/P_2: 0.0\n",
            "15/P_1: 0.0\n",
            "15/P_3: 0.0378570556640625\n",
            "15/P_0: 0.0\n",
            "16/P_3: 0.0\n",
            "16/P_1: 0.0\n",
            "16/P_0: 0.0\n",
            "16/P_2: 0.007720947265625\n",
            "17/P_0: 0.0\n",
            "17/P_3: 0.00959014892578125\n",
            "17/P_1: 0.0\n",
            "17/P_2: 0.0635986328125\n",
            "18/P_2: 0.0\n",
            "18/P_3: 0.04219818115234375\n",
            "18/P_0: 0.0\n",
            "18/P_1: 0.01348876953125\n",
            "19/P_3: 0.0\n",
            "19/P_2: 0.0303955078125\n",
            "19/P_0: 0.00531005859375\n",
            "19/P_1: 0.00341796875\n",
            "20/P_3: 0.01194000244140625\n",
            "20/P_1: 0.0\n",
            "20/P_2: 0.00140380859375\n",
            "20/P_0: 0.0\n",
            "21/P_2: 0.0\n",
            "21/P_0: 0.0\n",
            "21/P_1: 0.0\n",
            "21/P_3: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/25 [00:00<?, ?it/s]<ipython-input-5-3775b565d8d0>:22: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return nn.functional.log_softmax(x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 0.1120, Accuracy: (98%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 1/25 [00:16<06:33, 16.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 0.0058, Accuracy: (100%)\n",
            "\n",
            "\n",
            "Average loss: 0.0880, Accuracy: (98%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 2/25 [00:32<06:18, 16.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 0.0060, Accuracy: (100%)\n",
            "\n",
            "\n",
            "Average loss: 0.0739, Accuracy: (98%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 3/25 [00:49<06:06, 16.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 0.0094, Accuracy: (100%)\n",
            "\n",
            "\n",
            "Average loss: 0.0743, Accuracy: (98%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 4/25 [01:07<06:00, 17.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 0.0218, Accuracy: (100%)\n",
            "\n",
            "\n",
            "Average loss: 0.1064, Accuracy: (98%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 5/25 [01:23<05:32, 16.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 0.0619, Accuracy: (100%)\n",
            "\n",
            "\n",
            "Average loss: 0.2146, Accuracy: (98%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 6/25 [01:38<05:08, 16.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 0.1758, Accuracy: (100%)\n",
            "\n",
            "\n",
            "Average loss: 0.4614, Accuracy: (98%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 7/25 [01:54<04:48, 16.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 0.4267, Accuracy: (99%)\n",
            "\n",
            "\n",
            "Average loss: 0.8499, Accuracy: (97%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 8/25 [02:10<04:30, 15.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 0.8202, Accuracy: (98%)\n",
            "\n",
            "\n",
            "Average loss: 1.2847, Accuracy: (94%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 9/25 [02:25<04:12, 15.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 1.2627, Accuracy: (96%)\n",
            "\n",
            "\n",
            "Average loss: 1.6556, Accuracy: (86%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 10/25 [02:41<03:56, 15.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 1.6420, Accuracy: (87%)\n",
            "\n",
            "\n",
            "Average loss: 1.9154, Accuracy: (57%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 11/25 [02:57<03:40, 15.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 1.9084, Accuracy: (59%)\n",
            "\n",
            "\n",
            "Average loss: 2.0671, Accuracy: (31%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 12/25 [03:12<03:24, 15.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 2.0641, Accuracy: (31%)\n",
            "\n",
            "\n",
            "Average loss: 2.1180, Accuracy: (22%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 13/25 [03:28<03:08, 15.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 2.1172, Accuracy: (23%)\n",
            "\n",
            "\n",
            "Average loss: 2.0609, Accuracy: (34%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 14/25 [03:45<02:57, 16.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 2.0611, Accuracy: (34%)\n",
            "\n",
            "\n",
            "Average loss: 1.8890, Accuracy: (57%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 15/25 [04:01<02:39, 15.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 1.8885, Accuracy: (57%)\n",
            "\n",
            "\n",
            "Average loss: 1.5971, Accuracy: (80%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 16/25 [04:16<02:23, 15.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 1.5949, Accuracy: (81%)\n",
            "\n",
            "\n",
            "Average loss: 1.1953, Accuracy: (91%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 17/25 [04:32<02:06, 15.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 1.1892, Accuracy: (93%)\n",
            "\n",
            "\n",
            "Average loss: 0.7514, Accuracy: (96%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 18/25 [04:47<01:49, 15.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 0.7375, Accuracy: (97%)\n",
            "\n",
            "\n",
            "Average loss: 0.3845, Accuracy: (97%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 19/25 [05:03<01:34, 15.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 0.3591, Accuracy: (99%)\n",
            "\n",
            "\n",
            "Average loss: 0.1735, Accuracy: (98%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 20/25 [05:20<01:20, 16.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 0.1371, Accuracy: (100%)\n",
            "\n",
            "\n",
            "Average loss: 0.0886, Accuracy: (98%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 21/25 [05:36<01:04, 16.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 0.0447, Accuracy: (100%)\n",
            "\n",
            "\n",
            "Average loss: 0.0642, Accuracy: (98%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 22/25 [05:52<00:47, 15.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 0.0140, Accuracy: (100%)\n",
            "\n",
            "\n",
            "Average loss: 0.0637, Accuracy: (98%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 23/25 [06:07<00:31, 15.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 0.0050, Accuracy: (100%)\n",
            "\n",
            "\n",
            "Average loss: 0.0745, Accuracy: (98%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 24/25 [06:23<00:15, 15.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 0.0026, Accuracy: (100%)\n",
            "\n",
            "\n",
            "Average loss: 0.0935, Accuracy: (99%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25/25 [06:40<00:00, 16.03s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 0.0022, Accuracy: (100%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 0.1120, Accuracy: (98%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 1/25 [00:15<06:14, 15.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 0.0058, Accuracy: (100%)\n",
            "\n",
            "\n",
            "Average loss: 0.1024, Accuracy: (98%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 2/25 [00:30<05:56, 15.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 0.0049, Accuracy: (100%)\n",
            "\n",
            "\n",
            "Average loss: 0.0941, Accuracy: (98%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 3/25 [00:46<05:42, 15.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 0.0045, Accuracy: (100%)\n",
            "\n",
            "\n",
            "Average loss: 0.0873, Accuracy: (98%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 4/25 [01:02<05:28, 15.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 0.0045, Accuracy: (100%)\n",
            "\n",
            "\n",
            "Average loss: 0.0819, Accuracy: (98%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 5/25 [01:18<05:14, 15.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 0.0049, Accuracy: (100%)\n",
            "\n",
            "\n",
            "Average loss: 0.0777, Accuracy: (98%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 6/25 [01:34<04:58, 15.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 0.0055, Accuracy: (100%)\n",
            "\n",
            "\n",
            "Average loss: 0.0742, Accuracy: (98%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 7/25 [01:50<04:44, 15.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 0.0064, Accuracy: (100%)\n",
            "\n",
            "\n",
            "Average loss: 0.0717, Accuracy: (98%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 8/25 [02:05<04:28, 15.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 0.0073, Accuracy: (100%)\n",
            "\n",
            "\n",
            "Average loss: 0.0699, Accuracy: (98%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 9/25 [02:21<04:14, 15.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 0.0083, Accuracy: (100%)\n",
            "\n",
            "\n",
            "Average loss: 0.0687, Accuracy: (98%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 10/25 [02:38<03:59, 16.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 0.0092, Accuracy: (100%)\n",
            "\n",
            "\n",
            "Average loss: 0.0678, Accuracy: (98%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 11/25 [02:56<03:55, 16.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 0.0099, Accuracy: (100%)\n",
            "\n",
            "\n",
            "Average loss: 0.0668, Accuracy: (98%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 12/25 [03:12<03:35, 16.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 0.0102, Accuracy: (100%)\n",
            "\n",
            "\n",
            "Average loss: 0.0660, Accuracy: (98%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 13/25 [03:28<03:15, 16.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 0.0102, Accuracy: (100%)\n",
            "\n",
            "\n",
            "Average loss: 0.0654, Accuracy: (98%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 14/25 [03:44<02:58, 16.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 0.0097, Accuracy: (100%)\n",
            "\n",
            "\n",
            "Average loss: 0.0650, Accuracy: (98%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 15/25 [04:00<02:41, 16.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 0.0088, Accuracy: (100%)\n",
            "\n",
            "\n",
            "Average loss: 0.0651, Accuracy: (98%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 16/25 [04:16<02:24, 16.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 0.0077, Accuracy: (100%)\n",
            "\n",
            "\n",
            "Average loss: 0.0656, Accuracy: (98%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 17/25 [04:32<02:08, 16.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 0.0064, Accuracy: (100%)\n",
            "\n",
            "\n",
            "Average loss: 0.0664, Accuracy: (98%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 18/25 [04:48<01:52, 16.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 0.0052, Accuracy: (100%)\n",
            "\n",
            "\n",
            "Average loss: 0.0678, Accuracy: (98%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 19/25 [05:04<01:36, 16.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 0.0041, Accuracy: (100%)\n",
            "\n",
            "\n",
            "Average loss: 0.0699, Accuracy: (98%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 20/25 [05:19<01:19, 15.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 0.0033, Accuracy: (100%)\n",
            "\n",
            "\n",
            "Average loss: 0.0730, Accuracy: (98%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 21/25 [05:35<01:02, 15.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 0.0027, Accuracy: (100%)\n",
            "\n",
            "\n",
            "Average loss: 0.0767, Accuracy: (98%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 22/25 [05:53<00:49, 16.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 0.0023, Accuracy: (100%)\n",
            "\n",
            "\n",
            "Average loss: 0.0812, Accuracy: (98%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 23/25 [06:08<00:32, 16.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 0.0022, Accuracy: (100%)\n",
            "\n",
            "\n",
            "Average loss: 0.0866, Accuracy: (99%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 24/25 [06:24<00:15, 15.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 0.0021, Accuracy: (100%)\n",
            "\n",
            "\n",
            "Average loss: 0.0936, Accuracy: (99%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25/25 [06:39<00:00, 15.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 0.0022, Accuracy: (100%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "class MLP_NON_SYMM(torch.nn.Module):\n",
        "    def __init__(self, C_matrices, input=28*28):\n",
        "        super().__init__()\n",
        "        self.input = input\n",
        "        self.layer0 = torch.nn.Linear(input, 512)\n",
        "        self.layer1 = torch.nn.Linear(512, 512)\n",
        "        self.layer2 = torch.nn.Linear(512, 512)\n",
        "        self.layer3 = torch.nn.Linear(512, 256)\n",
        "        self.layer4 = torch.nn.Linear(256, 10)\n",
        "\n",
        "        self.C0, self.C1, self.C2, self.C3 = C_matrices\n",
        "        for C in C_matrices:\n",
        "            C.requires_grad = False\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, self.input)\n",
        "        x = self.custom_gelu(self.layer0(x), self.C0)\n",
        "        x = self.custom_gelu(self.layer1(x), self.C1)\n",
        "        x = self.custom_gelu(self.layer2(x), self.C2)\n",
        "        x = self.custom_gelu(self.layer3(x), self.C3)\n",
        "        x = self.layer4(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "    def custom_gelu(self, x, C):\n",
        "        return torch.nn.functional.gelu(torch.mm(torch.nn.functional.gelu(x), C))\n",
        "\n",
        "C_matrices = [\n",
        "    torch.randn(512, 512).to(device),\n",
        "    torch.randn(512, 512).to(device),\n",
        "    torch.randn(512, 512).to(device),\n",
        "    torch.randn(256, 256).to(device)\n",
        "]\n",
        "\n",
        "# model_a = MLP_NON_SYMM(C_matrices=C_matrices).to(device)\n",
        "# model_b = MLP_NON_SYMM(C_matrices=C_matrices).to(device)"
      ],
      "metadata": {
        "id": "alT0IcJjcanx"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from tqdm import tqdm\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "torch.manual_seed(args_4.seed)\n",
        "\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "train_kwargs = {'batch_size': args_2.batch_size}\n",
        "test_kwargs = {'batch_size': args_2.batch_size}\n",
        "if use_cuda:\n",
        "    cuda_kwargs = {'num_workers': 1,\n",
        "                    'pin_memory': True,\n",
        "                    'shuffle': True}\n",
        "    train_kwargs.update(cuda_kwargs)\n",
        "    test_kwargs.update(cuda_kwargs)\n",
        "\n",
        "transform=transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "dataset1 = datasets.MNIST('../data', train=True, download=True,\n",
        "                    transform=transform)\n",
        "dataset2 = datasets.MNIST('../data', train=False,\n",
        "                    transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n",
        "\n",
        "model_b = MLP_NON_SYMM(C_matrices=C_matrices).to(device)\n",
        "optimizer = optim.Adam(model_b.parameters(), lr=args_2.lr)\n",
        "\n",
        "for epoch in range(1, args_2.epochs + 1):\n",
        "    train(args_2, model_b, device, train_loader, optimizer, epoch)\n",
        "    test(model_b, device, test_loader)\n",
        "\n",
        "# torch.save(model_b.state_dict(), f\"mnist_mlp_{str(args_2.seed)}.pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zug5GKnmfCPS",
        "outputId": "b5682c96-78d3-4e9c-a8bc-8fb0530cf931"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b12c9537eb0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 1034.189819\n",
            "Train Epoch: 1 [5120/60000 (8%)]\tLoss: 135.230804\n",
            "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 18.806852\n",
            "Train Epoch: 1 [15360/60000 (25%)]\tLoss: 11.745053\n",
            "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 6.606968\n",
            "Train Epoch: 1 [25600/60000 (42%)]\tLoss: 5.083372\n",
            "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 4.156847\n",
            "Train Epoch: 1 [35840/60000 (59%)]\tLoss: 2.906134\n",
            "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 2.778599\n",
            "Train Epoch: 1 [46080/60000 (76%)]\tLoss: 1.898797\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 1.671939\n",
            "Train Epoch: 1 [56320/60000 (93%)]\tLoss: 2.352234\n",
            "Train Accuracy: (75%) \n",
            "\n",
            "Average loss: 1.9795, Accuracy: (89%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 1.661496\n",
            "Train Epoch: 2 [5120/60000 (8%)]\tLoss: 1.539505\n",
            "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 1.171618\n",
            "Train Epoch: 2 [15360/60000 (25%)]\tLoss: 1.079061\n",
            "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 1.313533\n",
            "Train Epoch: 2 [25600/60000 (42%)]\tLoss: 1.907889\n",
            "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 1.414814\n",
            "Train Epoch: 2 [35840/60000 (59%)]\tLoss: 0.979808\n",
            "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 1.764309\n",
            "Train Epoch: 2 [46080/60000 (76%)]\tLoss: 1.408535\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 1.251254\n",
            "Train Epoch: 2 [56320/60000 (93%)]\tLoss: 1.172465\n",
            "Train Accuracy: (91%) \n",
            "\n",
            "Average loss: 1.0799, Accuracy: (92%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.824634\n",
            "Train Epoch: 3 [5120/60000 (8%)]\tLoss: 0.600185\n",
            "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.545900\n",
            "Train Epoch: 3 [15360/60000 (25%)]\tLoss: 0.947369\n",
            "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.644764\n",
            "Train Epoch: 3 [25600/60000 (42%)]\tLoss: 0.732529\n",
            "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.948939\n",
            "Train Epoch: 3 [35840/60000 (59%)]\tLoss: 0.525033\n",
            "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.918825\n",
            "Train Epoch: 3 [46080/60000 (76%)]\tLoss: 0.392767\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.736416\n",
            "Train Epoch: 3 [56320/60000 (93%)]\tLoss: 0.768165\n",
            "Train Accuracy: (93%) \n",
            "\n",
            "Average loss: 0.9739, Accuracy: (93%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.554056\n",
            "Train Epoch: 4 [5120/60000 (8%)]\tLoss: 0.563740\n",
            "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.312979\n",
            "Train Epoch: 4 [15360/60000 (25%)]\tLoss: 0.555462\n",
            "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.580322\n",
            "Train Epoch: 4 [25600/60000 (42%)]\tLoss: 0.552835\n",
            "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.261769\n",
            "Train Epoch: 4 [35840/60000 (59%)]\tLoss: 0.449827\n",
            "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.501579\n",
            "Train Epoch: 4 [46080/60000 (76%)]\tLoss: 0.345896\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.622981\n",
            "Train Epoch: 4 [56320/60000 (93%)]\tLoss: 0.546942\n",
            "Train Accuracy: (95%) \n",
            "\n",
            "Average loss: 0.7881, Accuracy: (93%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.334989\n",
            "Train Epoch: 5 [5120/60000 (8%)]\tLoss: 0.287357\n",
            "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.483875\n",
            "Train Epoch: 5 [15360/60000 (25%)]\tLoss: 0.286290\n",
            "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.279291\n",
            "Train Epoch: 5 [25600/60000 (42%)]\tLoss: 0.356896\n",
            "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.359100\n",
            "Train Epoch: 5 [35840/60000 (59%)]\tLoss: 0.362833\n",
            "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.381270\n",
            "Train Epoch: 5 [46080/60000 (76%)]\tLoss: 0.264981\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.225773\n",
            "Train Epoch: 5 [56320/60000 (93%)]\tLoss: 0.487368\n",
            "Train Accuracy: (96%) \n",
            "\n",
            "Average loss: 0.7652, Accuracy: (94%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.140077\n",
            "Train Epoch: 6 [5120/60000 (8%)]\tLoss: 0.303075\n",
            "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.218414\n",
            "Train Epoch: 6 [15360/60000 (25%)]\tLoss: 0.341114\n",
            "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 0.179350\n",
            "Train Epoch: 6 [25600/60000 (42%)]\tLoss: 0.353539\n",
            "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.265832\n",
            "Train Epoch: 6 [35840/60000 (59%)]\tLoss: 0.367611\n",
            "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.397092\n",
            "Train Epoch: 6 [46080/60000 (76%)]\tLoss: 0.299417\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.214987\n",
            "Train Epoch: 6 [56320/60000 (93%)]\tLoss: 0.392128\n",
            "Train Accuracy: (96%) \n",
            "\n",
            "Average loss: 0.6789, Accuracy: (94%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.167647\n",
            "Train Epoch: 7 [5120/60000 (8%)]\tLoss: 0.094534\n",
            "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.160959\n",
            "Train Epoch: 7 [15360/60000 (25%)]\tLoss: 0.103200\n",
            "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.197684\n",
            "Train Epoch: 7 [25600/60000 (42%)]\tLoss: 0.154176\n",
            "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.305973\n",
            "Train Epoch: 7 [35840/60000 (59%)]\tLoss: 0.093440\n",
            "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 0.215116\n",
            "Train Epoch: 7 [46080/60000 (76%)]\tLoss: 0.202187\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.300586\n",
            "Train Epoch: 7 [56320/60000 (93%)]\tLoss: 0.189009\n",
            "Train Accuracy: (97%) \n",
            "\n",
            "Average loss: 0.7037, Accuracy: (94%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.110058\n",
            "Train Epoch: 8 [5120/60000 (8%)]\tLoss: 0.259159\n",
            "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.094678\n",
            "Train Epoch: 8 [15360/60000 (25%)]\tLoss: 0.137293\n",
            "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 0.094878\n",
            "Train Epoch: 8 [25600/60000 (42%)]\tLoss: 0.106394\n",
            "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.022431\n",
            "Train Epoch: 8 [35840/60000 (59%)]\tLoss: 0.055022\n",
            "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 0.127369\n",
            "Train Epoch: 8 [46080/60000 (76%)]\tLoss: 0.058354\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.252823\n",
            "Train Epoch: 8 [56320/60000 (93%)]\tLoss: 0.189898\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.6540, Accuracy: (94%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.120132\n",
            "Train Epoch: 9 [5120/60000 (8%)]\tLoss: 0.162468\n",
            "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 0.203483\n",
            "Train Epoch: 9 [15360/60000 (25%)]\tLoss: 0.351954\n",
            "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 0.169654\n",
            "Train Epoch: 9 [25600/60000 (42%)]\tLoss: 0.175511\n",
            "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 0.183029\n",
            "Train Epoch: 9 [35840/60000 (59%)]\tLoss: 0.094271\n",
            "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 0.081480\n",
            "Train Epoch: 9 [46080/60000 (76%)]\tLoss: 0.091537\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.176724\n",
            "Train Epoch: 9 [56320/60000 (93%)]\tLoss: 0.272892\n",
            "Train Accuracy: (97%) \n",
            "\n",
            "Average loss: 0.6500, Accuracy: (95%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.059252\n",
            "Train Epoch: 10 [5120/60000 (8%)]\tLoss: 0.211346\n",
            "Train Epoch: 10 [10240/60000 (17%)]\tLoss: 0.148913\n",
            "Train Epoch: 10 [15360/60000 (25%)]\tLoss: 0.165739\n",
            "Train Epoch: 10 [20480/60000 (34%)]\tLoss: 0.091865\n",
            "Train Epoch: 10 [25600/60000 (42%)]\tLoss: 0.071598\n",
            "Train Epoch: 10 [30720/60000 (51%)]\tLoss: 0.126788\n",
            "Train Epoch: 10 [35840/60000 (59%)]\tLoss: 0.098283\n",
            "Train Epoch: 10 [40960/60000 (68%)]\tLoss: 0.108795\n",
            "Train Epoch: 10 [46080/60000 (76%)]\tLoss: 0.133304\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.161700\n",
            "Train Epoch: 10 [56320/60000 (93%)]\tLoss: 0.135243\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.6364, Accuracy: (95%)\n",
            "\n",
            "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.105827\n",
            "Train Epoch: 11 [5120/60000 (8%)]\tLoss: 0.121932\n",
            "Train Epoch: 11 [10240/60000 (17%)]\tLoss: 0.264025\n",
            "Train Epoch: 11 [15360/60000 (25%)]\tLoss: 0.176162\n",
            "Train Epoch: 11 [20480/60000 (34%)]\tLoss: 0.166920\n",
            "Train Epoch: 11 [25600/60000 (42%)]\tLoss: 0.355782\n",
            "Train Epoch: 11 [30720/60000 (51%)]\tLoss: 0.172434\n",
            "Train Epoch: 11 [35840/60000 (59%)]\tLoss: 0.172965\n",
            "Train Epoch: 11 [40960/60000 (68%)]\tLoss: 0.126841\n",
            "Train Epoch: 11 [46080/60000 (76%)]\tLoss: 0.088126\n",
            "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.052379\n",
            "Train Epoch: 11 [56320/60000 (93%)]\tLoss: 0.300834\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.6015, Accuracy: (95%)\n",
            "\n",
            "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.111683\n",
            "Train Epoch: 12 [5120/60000 (8%)]\tLoss: 0.389872\n",
            "Train Epoch: 12 [10240/60000 (17%)]\tLoss: 0.108694\n",
            "Train Epoch: 12 [15360/60000 (25%)]\tLoss: 0.035836\n",
            "Train Epoch: 12 [20480/60000 (34%)]\tLoss: 0.050850\n",
            "Train Epoch: 12 [25600/60000 (42%)]\tLoss: 0.119939\n",
            "Train Epoch: 12 [30720/60000 (51%)]\tLoss: 0.348289\n",
            "Train Epoch: 12 [35840/60000 (59%)]\tLoss: 0.150570\n",
            "Train Epoch: 12 [40960/60000 (68%)]\tLoss: 0.203382\n",
            "Train Epoch: 12 [46080/60000 (76%)]\tLoss: 0.149580\n",
            "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.152656\n",
            "Train Epoch: 12 [56320/60000 (93%)]\tLoss: 0.281208\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.7336, Accuracy: (95%)\n",
            "\n",
            "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.203269\n",
            "Train Epoch: 13 [5120/60000 (8%)]\tLoss: 0.354698\n",
            "Train Epoch: 13 [10240/60000 (17%)]\tLoss: 0.143210\n",
            "Train Epoch: 13 [15360/60000 (25%)]\tLoss: 0.251778\n",
            "Train Epoch: 13 [20480/60000 (34%)]\tLoss: 0.091248\n",
            "Train Epoch: 13 [25600/60000 (42%)]\tLoss: 0.233054\n",
            "Train Epoch: 13 [30720/60000 (51%)]\tLoss: 0.235875\n",
            "Train Epoch: 13 [35840/60000 (59%)]\tLoss: 0.062684\n",
            "Train Epoch: 13 [40960/60000 (68%)]\tLoss: 0.219112\n",
            "Train Epoch: 13 [46080/60000 (76%)]\tLoss: 0.253585\n",
            "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.174564\n",
            "Train Epoch: 13 [56320/60000 (93%)]\tLoss: 0.252769\n",
            "Train Accuracy: (97%) \n",
            "\n",
            "Average loss: 0.6256, Accuracy: (95%)\n",
            "\n",
            "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.024774\n",
            "Train Epoch: 14 [5120/60000 (8%)]\tLoss: 0.066713\n",
            "Train Epoch: 14 [10240/60000 (17%)]\tLoss: 0.102187\n",
            "Train Epoch: 14 [15360/60000 (25%)]\tLoss: 0.079351\n",
            "Train Epoch: 14 [20480/60000 (34%)]\tLoss: 0.103778\n",
            "Train Epoch: 14 [25600/60000 (42%)]\tLoss: 0.061816\n",
            "Train Epoch: 14 [30720/60000 (51%)]\tLoss: 0.133986\n",
            "Train Epoch: 14 [35840/60000 (59%)]\tLoss: 0.139772\n",
            "Train Epoch: 14 [40960/60000 (68%)]\tLoss: 0.294879\n",
            "Train Epoch: 14 [46080/60000 (76%)]\tLoss: 0.181978\n",
            "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.101879\n",
            "Train Epoch: 14 [56320/60000 (93%)]\tLoss: 0.232666\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.6368, Accuracy: (95%)\n",
            "\n",
            "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.050134\n",
            "Train Epoch: 15 [5120/60000 (8%)]\tLoss: 0.147320\n",
            "Train Epoch: 15 [10240/60000 (17%)]\tLoss: 0.332459\n",
            "Train Epoch: 15 [15360/60000 (25%)]\tLoss: 0.155960\n",
            "Train Epoch: 15 [20480/60000 (34%)]\tLoss: 0.180540\n",
            "Train Epoch: 15 [25600/60000 (42%)]\tLoss: 0.061732\n",
            "Train Epoch: 15 [30720/60000 (51%)]\tLoss: 0.193268\n",
            "Train Epoch: 15 [35840/60000 (59%)]\tLoss: 0.186358\n",
            "Train Epoch: 15 [40960/60000 (68%)]\tLoss: 0.116214\n",
            "Train Epoch: 15 [46080/60000 (76%)]\tLoss: 0.376548\n",
            "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.317377\n",
            "Train Epoch: 15 [56320/60000 (93%)]\tLoss: 0.286408\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.5860, Accuracy: (96%)\n",
            "\n",
            "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.166413\n",
            "Train Epoch: 16 [5120/60000 (8%)]\tLoss: 0.159838\n",
            "Train Epoch: 16 [10240/60000 (17%)]\tLoss: 0.358330\n",
            "Train Epoch: 16 [15360/60000 (25%)]\tLoss: 0.300036\n",
            "Train Epoch: 16 [20480/60000 (34%)]\tLoss: 0.347776\n",
            "Train Epoch: 16 [25600/60000 (42%)]\tLoss: 0.230353\n",
            "Train Epoch: 16 [30720/60000 (51%)]\tLoss: 0.188380\n",
            "Train Epoch: 16 [35840/60000 (59%)]\tLoss: 0.213680\n",
            "Train Epoch: 16 [40960/60000 (68%)]\tLoss: 0.158027\n",
            "Train Epoch: 16 [46080/60000 (76%)]\tLoss: 0.353564\n",
            "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 0.081970\n",
            "Train Epoch: 16 [56320/60000 (93%)]\tLoss: 0.255890\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.7744, Accuracy: (95%)\n",
            "\n",
            "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.198488\n",
            "Train Epoch: 17 [5120/60000 (8%)]\tLoss: 0.176233\n",
            "Train Epoch: 17 [10240/60000 (17%)]\tLoss: 0.064231\n",
            "Train Epoch: 17 [15360/60000 (25%)]\tLoss: 0.167372\n",
            "Train Epoch: 17 [20480/60000 (34%)]\tLoss: 0.153731\n",
            "Train Epoch: 17 [25600/60000 (42%)]\tLoss: 0.176983\n",
            "Train Epoch: 17 [30720/60000 (51%)]\tLoss: 0.230123\n",
            "Train Epoch: 17 [35840/60000 (59%)]\tLoss: 0.097704\n",
            "Train Epoch: 17 [40960/60000 (68%)]\tLoss: 0.182629\n",
            "Train Epoch: 17 [46080/60000 (76%)]\tLoss: 0.150724\n",
            "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 0.311739\n",
            "Train Epoch: 17 [56320/60000 (93%)]\tLoss: 0.168425\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.6560, Accuracy: (95%)\n",
            "\n",
            "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.202908\n",
            "Train Epoch: 18 [5120/60000 (8%)]\tLoss: 0.230625\n",
            "Train Epoch: 18 [10240/60000 (17%)]\tLoss: 0.259253\n",
            "Train Epoch: 18 [15360/60000 (25%)]\tLoss: 0.106653\n",
            "Train Epoch: 18 [20480/60000 (34%)]\tLoss: 0.421357\n",
            "Train Epoch: 18 [25600/60000 (42%)]\tLoss: 0.135866\n",
            "Train Epoch: 18 [30720/60000 (51%)]\tLoss: 0.075348\n",
            "Train Epoch: 18 [35840/60000 (59%)]\tLoss: 0.266650\n",
            "Train Epoch: 18 [40960/60000 (68%)]\tLoss: 0.222465\n",
            "Train Epoch: 18 [46080/60000 (76%)]\tLoss: 0.076135\n",
            "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 0.160831\n",
            "Train Epoch: 18 [56320/60000 (93%)]\tLoss: 0.099697\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.6703, Accuracy: (95%)\n",
            "\n",
            "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.281467\n",
            "Train Epoch: 19 [5120/60000 (8%)]\tLoss: 0.275847\n",
            "Train Epoch: 19 [10240/60000 (17%)]\tLoss: 0.176376\n",
            "Train Epoch: 19 [15360/60000 (25%)]\tLoss: 0.149454\n",
            "Train Epoch: 19 [20480/60000 (34%)]\tLoss: 0.088785\n",
            "Train Epoch: 19 [25600/60000 (42%)]\tLoss: 0.101317\n",
            "Train Epoch: 19 [30720/60000 (51%)]\tLoss: 0.322092\n",
            "Train Epoch: 19 [35840/60000 (59%)]\tLoss: 0.229430\n",
            "Train Epoch: 19 [40960/60000 (68%)]\tLoss: 0.195552\n",
            "Train Epoch: 19 [46080/60000 (76%)]\tLoss: 0.217023\n",
            "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 0.150920\n",
            "Train Epoch: 19 [56320/60000 (93%)]\tLoss: 0.239937\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.7836, Accuracy: (95%)\n",
            "\n",
            "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.315843\n",
            "Train Epoch: 20 [5120/60000 (8%)]\tLoss: 0.125869\n",
            "Train Epoch: 20 [10240/60000 (17%)]\tLoss: 0.225540\n",
            "Train Epoch: 20 [15360/60000 (25%)]\tLoss: 0.152110\n",
            "Train Epoch: 20 [20480/60000 (34%)]\tLoss: 0.288703\n",
            "Train Epoch: 20 [25600/60000 (42%)]\tLoss: 0.201263\n",
            "Train Epoch: 20 [30720/60000 (51%)]\tLoss: 0.170502\n",
            "Train Epoch: 20 [35840/60000 (59%)]\tLoss: 0.199729\n",
            "Train Epoch: 20 [40960/60000 (68%)]\tLoss: 0.087554\n",
            "Train Epoch: 20 [46080/60000 (76%)]\tLoss: 0.364761\n",
            "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 0.206991\n",
            "Train Epoch: 20 [56320/60000 (93%)]\tLoss: 0.123406\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.7351, Accuracy: (95%)\n",
            "\n",
            "Train Epoch: 21 [0/60000 (0%)]\tLoss: 0.134021\n",
            "Train Epoch: 21 [5120/60000 (8%)]\tLoss: 0.239461\n",
            "Train Epoch: 21 [10240/60000 (17%)]\tLoss: 0.259101\n",
            "Train Epoch: 21 [15360/60000 (25%)]\tLoss: 0.192830\n",
            "Train Epoch: 21 [20480/60000 (34%)]\tLoss: 0.170588\n",
            "Train Epoch: 21 [25600/60000 (42%)]\tLoss: 0.379880\n",
            "Train Epoch: 21 [30720/60000 (51%)]\tLoss: 0.283541\n",
            "Train Epoch: 21 [35840/60000 (59%)]\tLoss: 0.049641\n",
            "Train Epoch: 21 [40960/60000 (68%)]\tLoss: 0.337710\n",
            "Train Epoch: 21 [46080/60000 (76%)]\tLoss: 0.275612\n",
            "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 0.146514\n",
            "Train Epoch: 21 [56320/60000 (93%)]\tLoss: 0.128698\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.5902, Accuracy: (96%)\n",
            "\n",
            "Train Epoch: 22 [0/60000 (0%)]\tLoss: 0.215038\n",
            "Train Epoch: 22 [5120/60000 (8%)]\tLoss: 0.239809\n",
            "Train Epoch: 22 [10240/60000 (17%)]\tLoss: 0.112375\n",
            "Train Epoch: 22 [15360/60000 (25%)]\tLoss: 0.136505\n",
            "Train Epoch: 22 [20480/60000 (34%)]\tLoss: 0.337847\n",
            "Train Epoch: 22 [25600/60000 (42%)]\tLoss: 0.174682\n",
            "Train Epoch: 22 [30720/60000 (51%)]\tLoss: 0.268413\n",
            "Train Epoch: 22 [35840/60000 (59%)]\tLoss: 0.202272\n",
            "Train Epoch: 22 [40960/60000 (68%)]\tLoss: 0.195929\n",
            "Train Epoch: 22 [46080/60000 (76%)]\tLoss: 0.140288\n",
            "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 0.324159\n",
            "Train Epoch: 22 [56320/60000 (93%)]\tLoss: 0.341100\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.6251, Accuracy: (96%)\n",
            "\n",
            "Train Epoch: 23 [0/60000 (0%)]\tLoss: 0.161861\n",
            "Train Epoch: 23 [5120/60000 (8%)]\tLoss: 0.156444\n",
            "Train Epoch: 23 [10240/60000 (17%)]\tLoss: 0.198280\n",
            "Train Epoch: 23 [15360/60000 (25%)]\tLoss: 0.082848\n",
            "Train Epoch: 23 [20480/60000 (34%)]\tLoss: 0.288213\n",
            "Train Epoch: 23 [25600/60000 (42%)]\tLoss: 0.219430\n",
            "Train Epoch: 23 [30720/60000 (51%)]\tLoss: 0.216719\n",
            "Train Epoch: 23 [35840/60000 (59%)]\tLoss: 0.217502\n",
            "Train Epoch: 23 [40960/60000 (68%)]\tLoss: 0.064823\n",
            "Train Epoch: 23 [46080/60000 (76%)]\tLoss: 0.274879\n",
            "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 0.143198\n",
            "Train Epoch: 23 [56320/60000 (93%)]\tLoss: 0.301417\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.7525, Accuracy: (95%)\n",
            "\n",
            "Train Epoch: 24 [0/60000 (0%)]\tLoss: 0.192845\n",
            "Train Epoch: 24 [5120/60000 (8%)]\tLoss: 0.611957\n",
            "Train Epoch: 24 [10240/60000 (17%)]\tLoss: 0.301505\n",
            "Train Epoch: 24 [15360/60000 (25%)]\tLoss: 0.285952\n",
            "Train Epoch: 24 [20480/60000 (34%)]\tLoss: 0.226476\n",
            "Train Epoch: 24 [25600/60000 (42%)]\tLoss: 0.104708\n",
            "Train Epoch: 24 [30720/60000 (51%)]\tLoss: 0.283124\n",
            "Train Epoch: 24 [35840/60000 (59%)]\tLoss: 0.325021\n",
            "Train Epoch: 24 [40960/60000 (68%)]\tLoss: 0.335633\n",
            "Train Epoch: 24 [46080/60000 (76%)]\tLoss: 0.299442\n",
            "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 0.173156\n",
            "Train Epoch: 24 [56320/60000 (93%)]\tLoss: 0.278818\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.6517, Accuracy: (96%)\n",
            "\n",
            "Train Epoch: 25 [0/60000 (0%)]\tLoss: 0.185581\n",
            "Train Epoch: 25 [5120/60000 (8%)]\tLoss: 0.286085\n",
            "Train Epoch: 25 [10240/60000 (17%)]\tLoss: 0.206964\n",
            "Train Epoch: 25 [15360/60000 (25%)]\tLoss: 0.158348\n",
            "Train Epoch: 25 [20480/60000 (34%)]\tLoss: 0.174431\n",
            "Train Epoch: 25 [25600/60000 (42%)]\tLoss: 0.378730\n",
            "Train Epoch: 25 [30720/60000 (51%)]\tLoss: 0.045275\n",
            "Train Epoch: 25 [35840/60000 (59%)]\tLoss: 0.183062\n",
            "Train Epoch: 25 [40960/60000 (68%)]\tLoss: 0.249425\n",
            "Train Epoch: 25 [46080/60000 (76%)]\tLoss: 0.323478\n",
            "Train Epoch: 25 [51200/60000 (85%)]\tLoss: 0.193989\n",
            "Train Epoch: 25 [56320/60000 (93%)]\tLoss: 0.068048\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.6602, Accuracy: (96%)\n",
            "\n",
            "Train Epoch: 26 [0/60000 (0%)]\tLoss: 0.193398\n",
            "Train Epoch: 26 [5120/60000 (8%)]\tLoss: 0.378990\n",
            "Train Epoch: 26 [10240/60000 (17%)]\tLoss: 0.376489\n",
            "Train Epoch: 26 [15360/60000 (25%)]\tLoss: 0.363049\n",
            "Train Epoch: 26 [20480/60000 (34%)]\tLoss: 0.424459\n",
            "Train Epoch: 26 [25600/60000 (42%)]\tLoss: 0.295090\n",
            "Train Epoch: 26 [30720/60000 (51%)]\tLoss: 0.394029\n",
            "Train Epoch: 26 [35840/60000 (59%)]\tLoss: 0.556159\n",
            "Train Epoch: 26 [40960/60000 (68%)]\tLoss: 0.532763\n",
            "Train Epoch: 26 [46080/60000 (76%)]\tLoss: 0.361388\n",
            "Train Epoch: 26 [51200/60000 (85%)]\tLoss: 0.663701\n",
            "Train Epoch: 26 [56320/60000 (93%)]\tLoss: 0.509425\n",
            "Train Accuracy: (97%) \n",
            "\n",
            "Average loss: 1.0801, Accuracy: (94%)\n",
            "\n",
            "Train Epoch: 27 [0/60000 (0%)]\tLoss: 0.777291\n",
            "Train Epoch: 27 [5120/60000 (8%)]\tLoss: 0.414935\n",
            "Train Epoch: 27 [10240/60000 (17%)]\tLoss: 0.186454\n",
            "Train Epoch: 27 [15360/60000 (25%)]\tLoss: 0.285419\n",
            "Train Epoch: 27 [20480/60000 (34%)]\tLoss: 0.251968\n",
            "Train Epoch: 27 [25600/60000 (42%)]\tLoss: 0.500850\n",
            "Train Epoch: 27 [30720/60000 (51%)]\tLoss: 0.226115\n",
            "Train Epoch: 27 [35840/60000 (59%)]\tLoss: 0.234897\n",
            "Train Epoch: 27 [40960/60000 (68%)]\tLoss: 0.152505\n",
            "Train Epoch: 27 [46080/60000 (76%)]\tLoss: 0.087837\n",
            "Train Epoch: 27 [51200/60000 (85%)]\tLoss: 0.150971\n",
            "Train Epoch: 27 [56320/60000 (93%)]\tLoss: 0.194045\n",
            "Train Accuracy: (97%) \n",
            "\n",
            "Average loss: 0.5182, Accuracy: (96%)\n",
            "\n",
            "Train Epoch: 28 [0/60000 (0%)]\tLoss: 0.119516\n",
            "Train Epoch: 28 [5120/60000 (8%)]\tLoss: 0.261230\n",
            "Train Epoch: 28 [10240/60000 (17%)]\tLoss: 0.132532\n",
            "Train Epoch: 28 [15360/60000 (25%)]\tLoss: 0.129920\n",
            "Train Epoch: 28 [20480/60000 (34%)]\tLoss: 0.185997\n",
            "Train Epoch: 28 [25600/60000 (42%)]\tLoss: 0.225693\n",
            "Train Epoch: 28 [30720/60000 (51%)]\tLoss: 0.167124\n",
            "Train Epoch: 28 [35840/60000 (59%)]\tLoss: 0.307171\n",
            "Train Epoch: 28 [40960/60000 (68%)]\tLoss: 0.220874\n",
            "Train Epoch: 28 [46080/60000 (76%)]\tLoss: 0.095852\n",
            "Train Epoch: 28 [51200/60000 (85%)]\tLoss: 0.178359\n",
            "Train Epoch: 28 [56320/60000 (93%)]\tLoss: 0.186722\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.5751, Accuracy: (96%)\n",
            "\n",
            "Train Epoch: 29 [0/60000 (0%)]\tLoss: 0.138759\n",
            "Train Epoch: 29 [5120/60000 (8%)]\tLoss: 0.097785\n",
            "Train Epoch: 29 [10240/60000 (17%)]\tLoss: 0.125233\n",
            "Train Epoch: 29 [15360/60000 (25%)]\tLoss: 0.144626\n",
            "Train Epoch: 29 [20480/60000 (34%)]\tLoss: 0.110834\n",
            "Train Epoch: 29 [25600/60000 (42%)]\tLoss: 0.171558\n",
            "Train Epoch: 29 [30720/60000 (51%)]\tLoss: 0.221201\n",
            "Train Epoch: 29 [35840/60000 (59%)]\tLoss: 0.061855\n",
            "Train Epoch: 29 [40960/60000 (68%)]\tLoss: 0.132419\n",
            "Train Epoch: 29 [46080/60000 (76%)]\tLoss: 0.214634\n",
            "Train Epoch: 29 [51200/60000 (85%)]\tLoss: 0.080228\n",
            "Train Epoch: 29 [56320/60000 (93%)]\tLoss: 0.201813\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.5509, Accuracy: (97%)\n",
            "\n",
            "Train Epoch: 30 [0/60000 (0%)]\tLoss: 0.154283\n",
            "Train Epoch: 30 [5120/60000 (8%)]\tLoss: 0.083989\n",
            "Train Epoch: 30 [10240/60000 (17%)]\tLoss: 0.052207\n",
            "Train Epoch: 30 [15360/60000 (25%)]\tLoss: 0.159564\n",
            "Train Epoch: 30 [20480/60000 (34%)]\tLoss: 0.119786\n",
            "Train Epoch: 30 [25600/60000 (42%)]\tLoss: 0.174524\n",
            "Train Epoch: 30 [30720/60000 (51%)]\tLoss: 0.078488\n",
            "Train Epoch: 30 [35840/60000 (59%)]\tLoss: 0.048825\n",
            "Train Epoch: 30 [40960/60000 (68%)]\tLoss: 0.148012\n",
            "Train Epoch: 30 [46080/60000 (76%)]\tLoss: 0.121259\n",
            "Train Epoch: 30 [51200/60000 (85%)]\tLoss: 0.106249\n",
            "Train Epoch: 30 [56320/60000 (93%)]\tLoss: 0.149054\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.5471, Accuracy: (96%)\n",
            "\n",
            "Train Epoch: 31 [0/60000 (0%)]\tLoss: 0.100461\n",
            "Train Epoch: 31 [5120/60000 (8%)]\tLoss: 0.017238\n",
            "Train Epoch: 31 [10240/60000 (17%)]\tLoss: 0.206767\n",
            "Train Epoch: 31 [15360/60000 (25%)]\tLoss: 0.029314\n",
            "Train Epoch: 31 [20480/60000 (34%)]\tLoss: 0.128440\n",
            "Train Epoch: 31 [25600/60000 (42%)]\tLoss: 0.105649\n",
            "Train Epoch: 31 [30720/60000 (51%)]\tLoss: 0.133178\n",
            "Train Epoch: 31 [35840/60000 (59%)]\tLoss: 0.199275\n",
            "Train Epoch: 31 [40960/60000 (68%)]\tLoss: 0.223814\n",
            "Train Epoch: 31 [46080/60000 (76%)]\tLoss: 0.045438\n",
            "Train Epoch: 31 [51200/60000 (85%)]\tLoss: 0.044859\n",
            "Train Epoch: 31 [56320/60000 (93%)]\tLoss: 0.315041\n",
            "Train Accuracy: (99%) \n",
            "\n",
            "Average loss: 0.4820, Accuracy: (97%)\n",
            "\n",
            "Train Epoch: 32 [0/60000 (0%)]\tLoss: 0.044588\n",
            "Train Epoch: 32 [5120/60000 (8%)]\tLoss: 0.163521\n",
            "Train Epoch: 32 [10240/60000 (17%)]\tLoss: 0.153939\n",
            "Train Epoch: 32 [15360/60000 (25%)]\tLoss: 0.086659\n",
            "Train Epoch: 32 [20480/60000 (34%)]\tLoss: 0.178240\n",
            "Train Epoch: 32 [25600/60000 (42%)]\tLoss: 0.092028\n",
            "Train Epoch: 32 [30720/60000 (51%)]\tLoss: 0.277097\n",
            "Train Epoch: 32 [35840/60000 (59%)]\tLoss: 0.105348\n",
            "Train Epoch: 32 [40960/60000 (68%)]\tLoss: 0.244811\n",
            "Train Epoch: 32 [46080/60000 (76%)]\tLoss: 0.073075\n",
            "Train Epoch: 32 [51200/60000 (85%)]\tLoss: 0.094026\n",
            "Train Epoch: 32 [56320/60000 (93%)]\tLoss: 0.028937\n",
            "Train Accuracy: (99%) \n",
            "\n",
            "Average loss: 0.5518, Accuracy: (96%)\n",
            "\n",
            "Train Epoch: 33 [0/60000 (0%)]\tLoss: 0.139389\n",
            "Train Epoch: 33 [5120/60000 (8%)]\tLoss: 0.108015\n",
            "Train Epoch: 33 [10240/60000 (17%)]\tLoss: 0.032912\n",
            "Train Epoch: 33 [15360/60000 (25%)]\tLoss: 0.036289\n",
            "Train Epoch: 33 [20480/60000 (34%)]\tLoss: 0.090494\n",
            "Train Epoch: 33 [25600/60000 (42%)]\tLoss: 0.186666\n",
            "Train Epoch: 33 [30720/60000 (51%)]\tLoss: 0.304446\n",
            "Train Epoch: 33 [35840/60000 (59%)]\tLoss: 0.121634\n",
            "Train Epoch: 33 [40960/60000 (68%)]\tLoss: 0.235810\n",
            "Train Epoch: 33 [46080/60000 (76%)]\tLoss: 0.317924\n",
            "Train Epoch: 33 [51200/60000 (85%)]\tLoss: 0.101231\n",
            "Train Epoch: 33 [56320/60000 (93%)]\tLoss: 0.206262\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.6037, Accuracy: (96%)\n",
            "\n",
            "Train Epoch: 34 [0/60000 (0%)]\tLoss: 0.093204\n",
            "Train Epoch: 34 [5120/60000 (8%)]\tLoss: 0.108760\n",
            "Train Epoch: 34 [10240/60000 (17%)]\tLoss: 0.158308\n",
            "Train Epoch: 34 [15360/60000 (25%)]\tLoss: 0.100030\n",
            "Train Epoch: 34 [20480/60000 (34%)]\tLoss: 0.151025\n",
            "Train Epoch: 34 [25600/60000 (42%)]\tLoss: 0.148342\n",
            "Train Epoch: 34 [30720/60000 (51%)]\tLoss: 0.035966\n",
            "Train Epoch: 34 [35840/60000 (59%)]\tLoss: 0.035426\n",
            "Train Epoch: 34 [40960/60000 (68%)]\tLoss: 0.106281\n",
            "Train Epoch: 34 [46080/60000 (76%)]\tLoss: 0.126371\n",
            "Train Epoch: 34 [51200/60000 (85%)]\tLoss: 0.099410\n",
            "Train Epoch: 34 [56320/60000 (93%)]\tLoss: 0.061893\n",
            "Train Accuracy: (99%) \n",
            "\n",
            "Average loss: 0.5010, Accuracy: (97%)\n",
            "\n",
            "Train Epoch: 35 [0/60000 (0%)]\tLoss: 0.112260\n",
            "Train Epoch: 35 [5120/60000 (8%)]\tLoss: 0.180984\n",
            "Train Epoch: 35 [10240/60000 (17%)]\tLoss: 0.220008\n",
            "Train Epoch: 35 [15360/60000 (25%)]\tLoss: 0.033135\n",
            "Train Epoch: 35 [20480/60000 (34%)]\tLoss: 0.210553\n",
            "Train Epoch: 35 [25600/60000 (42%)]\tLoss: 0.201673\n",
            "Train Epoch: 35 [30720/60000 (51%)]\tLoss: 0.071250\n",
            "Train Epoch: 35 [35840/60000 (59%)]\tLoss: 0.242384\n",
            "Train Epoch: 35 [40960/60000 (68%)]\tLoss: 0.114134\n",
            "Train Epoch: 35 [46080/60000 (76%)]\tLoss: 0.132691\n",
            "Train Epoch: 35 [51200/60000 (85%)]\tLoss: 0.242022\n",
            "Train Epoch: 35 [56320/60000 (93%)]\tLoss: 0.125186\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.6508, Accuracy: (96%)\n",
            "\n",
            "Train Epoch: 36 [0/60000 (0%)]\tLoss: 0.036283\n",
            "Train Epoch: 36 [5120/60000 (8%)]\tLoss: 0.182993\n",
            "Train Epoch: 36 [10240/60000 (17%)]\tLoss: 0.168450\n",
            "Train Epoch: 36 [15360/60000 (25%)]\tLoss: 0.143137\n",
            "Train Epoch: 36 [20480/60000 (34%)]\tLoss: 0.106022\n",
            "Train Epoch: 36 [25600/60000 (42%)]\tLoss: 0.335592\n",
            "Train Epoch: 36 [30720/60000 (51%)]\tLoss: 0.166294\n",
            "Train Epoch: 36 [35840/60000 (59%)]\tLoss: 0.307827\n",
            "Train Epoch: 36 [40960/60000 (68%)]\tLoss: 0.478896\n",
            "Train Epoch: 36 [46080/60000 (76%)]\tLoss: 0.215155\n",
            "Train Epoch: 36 [51200/60000 (85%)]\tLoss: 0.265343\n",
            "Train Epoch: 36 [56320/60000 (93%)]\tLoss: 0.141057\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.5668, Accuracy: (96%)\n",
            "\n",
            "Train Epoch: 37 [0/60000 (0%)]\tLoss: 0.076846\n",
            "Train Epoch: 37 [5120/60000 (8%)]\tLoss: 0.147617\n",
            "Train Epoch: 37 [10240/60000 (17%)]\tLoss: 0.148464\n",
            "Train Epoch: 37 [15360/60000 (25%)]\tLoss: 0.069157\n",
            "Train Epoch: 37 [20480/60000 (34%)]\tLoss: 0.138401\n",
            "Train Epoch: 37 [25600/60000 (42%)]\tLoss: 0.150778\n",
            "Train Epoch: 37 [30720/60000 (51%)]\tLoss: 0.104683\n",
            "Train Epoch: 37 [35840/60000 (59%)]\tLoss: 0.170219\n",
            "Train Epoch: 37 [40960/60000 (68%)]\tLoss: 0.164693\n",
            "Train Epoch: 37 [46080/60000 (76%)]\tLoss: 0.278663\n",
            "Train Epoch: 37 [51200/60000 (85%)]\tLoss: 0.141260\n",
            "Train Epoch: 37 [56320/60000 (93%)]\tLoss: 0.256657\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.5533, Accuracy: (96%)\n",
            "\n",
            "Train Epoch: 38 [0/60000 (0%)]\tLoss: 0.129438\n",
            "Train Epoch: 38 [5120/60000 (8%)]\tLoss: 0.151052\n",
            "Train Epoch: 38 [10240/60000 (17%)]\tLoss: 0.131276\n",
            "Train Epoch: 38 [15360/60000 (25%)]\tLoss: 0.117421\n",
            "Train Epoch: 38 [20480/60000 (34%)]\tLoss: 0.196749\n",
            "Train Epoch: 38 [25600/60000 (42%)]\tLoss: 0.094423\n",
            "Train Epoch: 38 [30720/60000 (51%)]\tLoss: 0.261747\n",
            "Train Epoch: 38 [35840/60000 (59%)]\tLoss: 0.274316\n",
            "Train Epoch: 38 [40960/60000 (68%)]\tLoss: 0.106556\n",
            "Train Epoch: 38 [46080/60000 (76%)]\tLoss: 0.152776\n",
            "Train Epoch: 38 [51200/60000 (85%)]\tLoss: 0.170831\n",
            "Train Epoch: 38 [56320/60000 (93%)]\tLoss: 0.153555\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.5218, Accuracy: (96%)\n",
            "\n",
            "Train Epoch: 39 [0/60000 (0%)]\tLoss: 0.116327\n",
            "Train Epoch: 39 [5120/60000 (8%)]\tLoss: 0.104524\n",
            "Train Epoch: 39 [10240/60000 (17%)]\tLoss: 0.093092\n",
            "Train Epoch: 39 [15360/60000 (25%)]\tLoss: 0.243506\n",
            "Train Epoch: 39 [20480/60000 (34%)]\tLoss: 0.110818\n",
            "Train Epoch: 39 [25600/60000 (42%)]\tLoss: 0.076132\n",
            "Train Epoch: 39 [30720/60000 (51%)]\tLoss: 0.109496\n",
            "Train Epoch: 39 [35840/60000 (59%)]\tLoss: 0.149303\n",
            "Train Epoch: 39 [40960/60000 (68%)]\tLoss: 0.033332\n",
            "Train Epoch: 39 [46080/60000 (76%)]\tLoss: 0.111505\n",
            "Train Epoch: 39 [51200/60000 (85%)]\tLoss: 0.125213\n",
            "Train Epoch: 39 [56320/60000 (93%)]\tLoss: 0.128117\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.4499, Accuracy: (96%)\n",
            "\n",
            "Train Epoch: 40 [0/60000 (0%)]\tLoss: 0.144759\n",
            "Train Epoch: 40 [5120/60000 (8%)]\tLoss: 0.172032\n",
            "Train Epoch: 40 [10240/60000 (17%)]\tLoss: 0.020519\n",
            "Train Epoch: 40 [15360/60000 (25%)]\tLoss: 0.048947\n",
            "Train Epoch: 40 [20480/60000 (34%)]\tLoss: 0.044650\n",
            "Train Epoch: 40 [25600/60000 (42%)]\tLoss: 0.056695\n",
            "Train Epoch: 40 [30720/60000 (51%)]\tLoss: 0.133632\n",
            "Train Epoch: 40 [35840/60000 (59%)]\tLoss: 0.044860\n",
            "Train Epoch: 40 [40960/60000 (68%)]\tLoss: 0.045070\n",
            "Train Epoch: 40 [46080/60000 (76%)]\tLoss: 0.086121\n",
            "Train Epoch: 40 [51200/60000 (85%)]\tLoss: 0.148411\n",
            "Train Epoch: 40 [56320/60000 (93%)]\tLoss: 0.256987\n",
            "Train Accuracy: (99%) \n",
            "\n",
            "Average loss: 0.4511, Accuracy: (97%)\n",
            "\n",
            "Train Epoch: 41 [0/60000 (0%)]\tLoss: 0.104075\n",
            "Train Epoch: 41 [5120/60000 (8%)]\tLoss: 0.129321\n",
            "Train Epoch: 41 [10240/60000 (17%)]\tLoss: 0.158407\n",
            "Train Epoch: 41 [15360/60000 (25%)]\tLoss: 0.378999\n",
            "Train Epoch: 41 [20480/60000 (34%)]\tLoss: 0.102332\n",
            "Train Epoch: 41 [25600/60000 (42%)]\tLoss: 0.208057\n",
            "Train Epoch: 41 [30720/60000 (51%)]\tLoss: 0.090319\n",
            "Train Epoch: 41 [35840/60000 (59%)]\tLoss: 0.124490\n",
            "Train Epoch: 41 [40960/60000 (68%)]\tLoss: 0.042113\n",
            "Train Epoch: 41 [46080/60000 (76%)]\tLoss: 0.126417\n",
            "Train Epoch: 41 [51200/60000 (85%)]\tLoss: 0.106348\n",
            "Train Epoch: 41 [56320/60000 (93%)]\tLoss: 0.091968\n",
            "Train Accuracy: (99%) \n",
            "\n",
            "Average loss: 0.4816, Accuracy: (96%)\n",
            "\n",
            "Train Epoch: 42 [0/60000 (0%)]\tLoss: 0.053092\n",
            "Train Epoch: 42 [5120/60000 (8%)]\tLoss: 0.061710\n",
            "Train Epoch: 42 [10240/60000 (17%)]\tLoss: 0.087895\n",
            "Train Epoch: 42 [15360/60000 (25%)]\tLoss: 0.037073\n",
            "Train Epoch: 42 [20480/60000 (34%)]\tLoss: 0.022387\n",
            "Train Epoch: 42 [25600/60000 (42%)]\tLoss: 0.037143\n",
            "Train Epoch: 42 [30720/60000 (51%)]\tLoss: 0.008326\n",
            "Train Epoch: 42 [35840/60000 (59%)]\tLoss: 0.099089\n",
            "Train Epoch: 42 [40960/60000 (68%)]\tLoss: 0.120702\n",
            "Train Epoch: 42 [46080/60000 (76%)]\tLoss: 0.072213\n",
            "Train Epoch: 42 [51200/60000 (85%)]\tLoss: 0.166946\n",
            "Train Epoch: 42 [56320/60000 (93%)]\tLoss: 0.040215\n",
            "Train Accuracy: (99%) \n",
            "\n",
            "Average loss: 0.5507, Accuracy: (97%)\n",
            "\n",
            "Train Epoch: 43 [0/60000 (0%)]\tLoss: 0.063315\n",
            "Train Epoch: 43 [5120/60000 (8%)]\tLoss: 0.620067\n",
            "Train Epoch: 43 [10240/60000 (17%)]\tLoss: 0.126006\n",
            "Train Epoch: 43 [15360/60000 (25%)]\tLoss: 0.073506\n",
            "Train Epoch: 43 [20480/60000 (34%)]\tLoss: 0.240288\n",
            "Train Epoch: 43 [25600/60000 (42%)]\tLoss: 0.123044\n",
            "Train Epoch: 43 [30720/60000 (51%)]\tLoss: 0.106331\n",
            "Train Epoch: 43 [35840/60000 (59%)]\tLoss: 0.161885\n",
            "Train Epoch: 43 [40960/60000 (68%)]\tLoss: 0.051980\n",
            "Train Epoch: 43 [46080/60000 (76%)]\tLoss: 0.081068\n",
            "Train Epoch: 43 [51200/60000 (85%)]\tLoss: 0.142466\n",
            "Train Epoch: 43 [56320/60000 (93%)]\tLoss: 0.064605\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.5137, Accuracy: (96%)\n",
            "\n",
            "Train Epoch: 44 [0/60000 (0%)]\tLoss: 0.141344\n",
            "Train Epoch: 44 [5120/60000 (8%)]\tLoss: 0.072130\n",
            "Train Epoch: 44 [10240/60000 (17%)]\tLoss: 0.039960\n",
            "Train Epoch: 44 [15360/60000 (25%)]\tLoss: 0.068239\n",
            "Train Epoch: 44 [20480/60000 (34%)]\tLoss: 0.087241\n",
            "Train Epoch: 44 [25600/60000 (42%)]\tLoss: 0.041580\n",
            "Train Epoch: 44 [30720/60000 (51%)]\tLoss: 0.055981\n",
            "Train Epoch: 44 [35840/60000 (59%)]\tLoss: 0.108552\n",
            "Train Epoch: 44 [40960/60000 (68%)]\tLoss: 0.099079\n",
            "Train Epoch: 44 [46080/60000 (76%)]\tLoss: 0.031749\n",
            "Train Epoch: 44 [51200/60000 (85%)]\tLoss: 0.120002\n",
            "Train Epoch: 44 [56320/60000 (93%)]\tLoss: 0.063946\n",
            "Train Accuracy: (99%) \n",
            "\n",
            "Average loss: 0.4014, Accuracy: (97%)\n",
            "\n",
            "Train Epoch: 45 [0/60000 (0%)]\tLoss: 0.026041\n",
            "Train Epoch: 45 [5120/60000 (8%)]\tLoss: 0.045508\n",
            "Train Epoch: 45 [10240/60000 (17%)]\tLoss: 0.202434\n",
            "Train Epoch: 45 [15360/60000 (25%)]\tLoss: 0.070972\n",
            "Train Epoch: 45 [20480/60000 (34%)]\tLoss: 0.175667\n",
            "Train Epoch: 45 [25600/60000 (42%)]\tLoss: 0.112152\n",
            "Train Epoch: 45 [30720/60000 (51%)]\tLoss: 0.233586\n",
            "Train Epoch: 45 [35840/60000 (59%)]\tLoss: 0.142102\n",
            "Train Epoch: 45 [40960/60000 (68%)]\tLoss: 0.133628\n",
            "Train Epoch: 45 [46080/60000 (76%)]\tLoss: 0.185691\n",
            "Train Epoch: 45 [51200/60000 (85%)]\tLoss: 0.050503\n",
            "Train Epoch: 45 [56320/60000 (93%)]\tLoss: 0.134864\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.4061, Accuracy: (97%)\n",
            "\n",
            "Train Epoch: 46 [0/60000 (0%)]\tLoss: 0.062608\n",
            "Train Epoch: 46 [5120/60000 (8%)]\tLoss: 0.066009\n",
            "Train Epoch: 46 [10240/60000 (17%)]\tLoss: 0.066348\n",
            "Train Epoch: 46 [15360/60000 (25%)]\tLoss: 0.127507\n",
            "Train Epoch: 46 [20480/60000 (34%)]\tLoss: 0.031158\n",
            "Train Epoch: 46 [25600/60000 (42%)]\tLoss: 0.104759\n",
            "Train Epoch: 46 [30720/60000 (51%)]\tLoss: 0.114580\n",
            "Train Epoch: 46 [35840/60000 (59%)]\tLoss: 0.061616\n",
            "Train Epoch: 46 [40960/60000 (68%)]\tLoss: 0.040644\n",
            "Train Epoch: 46 [46080/60000 (76%)]\tLoss: 0.123623\n",
            "Train Epoch: 46 [51200/60000 (85%)]\tLoss: 0.164312\n",
            "Train Epoch: 46 [56320/60000 (93%)]\tLoss: 0.252950\n",
            "Train Accuracy: (99%) \n",
            "\n",
            "Average loss: 0.4302, Accuracy: (96%)\n",
            "\n",
            "Train Epoch: 47 [0/60000 (0%)]\tLoss: 0.045077\n",
            "Train Epoch: 47 [5120/60000 (8%)]\tLoss: 0.053914\n",
            "Train Epoch: 47 [10240/60000 (17%)]\tLoss: 0.274303\n",
            "Train Epoch: 47 [15360/60000 (25%)]\tLoss: 0.079768\n",
            "Train Epoch: 47 [20480/60000 (34%)]\tLoss: 0.449285\n",
            "Train Epoch: 47 [25600/60000 (42%)]\tLoss: 0.118382\n",
            "Train Epoch: 47 [30720/60000 (51%)]\tLoss: 0.065875\n",
            "Train Epoch: 47 [35840/60000 (59%)]\tLoss: 0.131534\n",
            "Train Epoch: 47 [40960/60000 (68%)]\tLoss: 0.035960\n",
            "Train Epoch: 47 [46080/60000 (76%)]\tLoss: 0.068792\n",
            "Train Epoch: 47 [51200/60000 (85%)]\tLoss: 0.018087\n",
            "Train Epoch: 47 [56320/60000 (93%)]\tLoss: 0.212994\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.3837, Accuracy: (96%)\n",
            "\n",
            "Train Epoch: 48 [0/60000 (0%)]\tLoss: 0.109978\n",
            "Train Epoch: 48 [5120/60000 (8%)]\tLoss: 0.082662\n",
            "Train Epoch: 48 [10240/60000 (17%)]\tLoss: 0.093258\n",
            "Train Epoch: 48 [15360/60000 (25%)]\tLoss: 0.068312\n",
            "Train Epoch: 48 [20480/60000 (34%)]\tLoss: 0.132036\n",
            "Train Epoch: 48 [25600/60000 (42%)]\tLoss: 0.055347\n",
            "Train Epoch: 48 [30720/60000 (51%)]\tLoss: 0.060809\n",
            "Train Epoch: 48 [35840/60000 (59%)]\tLoss: 0.094999\n",
            "Train Epoch: 48 [40960/60000 (68%)]\tLoss: 0.286209\n",
            "Train Epoch: 48 [46080/60000 (76%)]\tLoss: 0.063485\n",
            "Train Epoch: 48 [51200/60000 (85%)]\tLoss: 0.158661\n",
            "Train Epoch: 48 [56320/60000 (93%)]\tLoss: 0.038587\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.2996, Accuracy: (97%)\n",
            "\n",
            "Train Epoch: 49 [0/60000 (0%)]\tLoss: 0.058082\n",
            "Train Epoch: 49 [5120/60000 (8%)]\tLoss: 0.051637\n",
            "Train Epoch: 49 [10240/60000 (17%)]\tLoss: 0.107880\n",
            "Train Epoch: 49 [15360/60000 (25%)]\tLoss: 0.051675\n",
            "Train Epoch: 49 [20480/60000 (34%)]\tLoss: 0.056247\n",
            "Train Epoch: 49 [25600/60000 (42%)]\tLoss: 0.084425\n",
            "Train Epoch: 49 [30720/60000 (51%)]\tLoss: 0.092867\n",
            "Train Epoch: 49 [35840/60000 (59%)]\tLoss: 0.078750\n",
            "Train Epoch: 49 [40960/60000 (68%)]\tLoss: 0.083462\n",
            "Train Epoch: 49 [46080/60000 (76%)]\tLoss: 0.046106\n",
            "Train Epoch: 49 [51200/60000 (85%)]\tLoss: 0.193945\n",
            "Train Epoch: 49 [56320/60000 (93%)]\tLoss: 0.030056\n",
            "Train Accuracy: (99%) \n",
            "\n",
            "Average loss: 0.3375, Accuracy: (97%)\n",
            "\n",
            "Train Epoch: 50 [0/60000 (0%)]\tLoss: 0.071707\n",
            "Train Epoch: 50 [5120/60000 (8%)]\tLoss: 0.225423\n",
            "Train Epoch: 50 [10240/60000 (17%)]\tLoss: 0.035750\n",
            "Train Epoch: 50 [15360/60000 (25%)]\tLoss: 0.064663\n",
            "Train Epoch: 50 [20480/60000 (34%)]\tLoss: 0.057766\n",
            "Train Epoch: 50 [25600/60000 (42%)]\tLoss: 0.155946\n",
            "Train Epoch: 50 [30720/60000 (51%)]\tLoss: 0.112383\n",
            "Train Epoch: 50 [35840/60000 (59%)]\tLoss: 0.118111\n",
            "Train Epoch: 50 [40960/60000 (68%)]\tLoss: 0.093443\n",
            "Train Epoch: 50 [46080/60000 (76%)]\tLoss: 0.009833\n",
            "Train Epoch: 50 [51200/60000 (85%)]\tLoss: 0.077673\n",
            "Train Epoch: 50 [56320/60000 (93%)]\tLoss: 0.130872\n",
            "Train Accuracy: (99%) \n",
            "\n",
            "Average loss: 0.2972, Accuracy: (97%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "torch.manual_seed(args_3.seed)\n",
        "\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "train_kwargs = {'batch_size': args_1.batch_size}\n",
        "test_kwargs = {'batch_size': args_1.batch_size}\n",
        "if use_cuda:\n",
        "    cuda_kwargs = {'num_workers': 1,\n",
        "                    'pin_memory': True,\n",
        "                    'shuffle': True}\n",
        "    train_kwargs.update(cuda_kwargs)\n",
        "    test_kwargs.update(cuda_kwargs)\n",
        "\n",
        "transform=transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "dataset1 = datasets.MNIST('../data', train=True, download=True,\n",
        "                    transform=transform)\n",
        "dataset2 = datasets.MNIST('../data', train=False,\n",
        "                    transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n",
        "\n",
        "model_a = MLP_NON_SYMM(C_matrices=C_matrices).to(device)\n",
        "optimizer = optim.Adam(model_a.parameters(), lr=args_1.lr)\n",
        "\n",
        "for epoch in range(1, args_1.epochs + 1):\n",
        "    train(args_1, model_a, device, train_loader, optimizer, epoch)\n",
        "    test(model_a, device, test_loader)\n",
        "\n",
        "# torch.save(model_a.state_dict(), f\"mnist_mlp_{str(args_1.seed)}.pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YmhHEIEfM2C",
        "outputId": "9805c1b0-fae3-4f6e-e80d-b45deafbc3d1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 940.189331\n",
            "Train Epoch: 1 [5120/60000 (8%)]\tLoss: 120.411385\n",
            "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 19.198910\n",
            "Train Epoch: 1 [15360/60000 (25%)]\tLoss: 11.953046\n",
            "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 6.265797\n",
            "Train Epoch: 1 [25600/60000 (42%)]\tLoss: 4.327809\n",
            "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 3.593540\n",
            "Train Epoch: 1 [35840/60000 (59%)]\tLoss: 2.931265\n",
            "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 2.299785\n",
            "Train Epoch: 1 [46080/60000 (76%)]\tLoss: 1.953659\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 2.425818\n",
            "Train Epoch: 1 [56320/60000 (93%)]\tLoss: 2.747963\n",
            "Train Accuracy: (74%) \n",
            "\n",
            "Average loss: 2.3215, Accuracy: (87%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.229073\n",
            "Train Epoch: 2 [5120/60000 (8%)]\tLoss: 2.840946\n",
            "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 1.630698\n",
            "Train Epoch: 2 [15360/60000 (25%)]\tLoss: 1.918687\n",
            "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.940716\n",
            "Train Epoch: 2 [25600/60000 (42%)]\tLoss: 1.091477\n",
            "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 1.190230\n",
            "Train Epoch: 2 [35840/60000 (59%)]\tLoss: 1.351334\n",
            "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 1.220619\n",
            "Train Epoch: 2 [46080/60000 (76%)]\tLoss: 1.315863\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.753451\n",
            "Train Epoch: 2 [56320/60000 (93%)]\tLoss: 1.006296\n",
            "Train Accuracy: (91%) \n",
            "\n",
            "Average loss: 2.1078, Accuracy: (86%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.282898\n",
            "Train Epoch: 3 [5120/60000 (8%)]\tLoss: 0.778859\n",
            "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.965715\n",
            "Train Epoch: 3 [15360/60000 (25%)]\tLoss: 0.827690\n",
            "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.637120\n",
            "Train Epoch: 3 [25600/60000 (42%)]\tLoss: 0.489482\n",
            "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.796335\n",
            "Train Epoch: 3 [35840/60000 (59%)]\tLoss: 0.854008\n",
            "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.416603\n",
            "Train Epoch: 3 [46080/60000 (76%)]\tLoss: 0.738667\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.714564\n",
            "Train Epoch: 3 [56320/60000 (93%)]\tLoss: 0.365929\n",
            "Train Accuracy: (93%) \n",
            "\n",
            "Average loss: 0.9281, Accuracy: (93%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.630917\n",
            "Train Epoch: 4 [5120/60000 (8%)]\tLoss: 0.775228\n",
            "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.523241\n",
            "Train Epoch: 4 [15360/60000 (25%)]\tLoss: 0.363870\n",
            "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.458915\n",
            "Train Epoch: 4 [25600/60000 (42%)]\tLoss: 0.474293\n",
            "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.563007\n",
            "Train Epoch: 4 [35840/60000 (59%)]\tLoss: 0.630463\n",
            "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.353556\n",
            "Train Epoch: 4 [46080/60000 (76%)]\tLoss: 0.640902\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.560506\n",
            "Train Epoch: 4 [56320/60000 (93%)]\tLoss: 0.648306\n",
            "Train Accuracy: (95%) \n",
            "\n",
            "Average loss: 0.8689, Accuracy: (93%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.516766\n",
            "Train Epoch: 5 [5120/60000 (8%)]\tLoss: 0.509148\n",
            "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.341587\n",
            "Train Epoch: 5 [15360/60000 (25%)]\tLoss: 0.448693\n",
            "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.184317\n",
            "Train Epoch: 5 [25600/60000 (42%)]\tLoss: 0.202589\n",
            "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.196664\n",
            "Train Epoch: 5 [35840/60000 (59%)]\tLoss: 0.390155\n",
            "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.339341\n",
            "Train Epoch: 5 [46080/60000 (76%)]\tLoss: 0.480783\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.201178\n",
            "Train Epoch: 5 [56320/60000 (93%)]\tLoss: 0.236392\n",
            "Train Accuracy: (96%) \n",
            "\n",
            "Average loss: 0.7216, Accuracy: (94%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.177946\n",
            "Train Epoch: 6 [5120/60000 (8%)]\tLoss: 0.280277\n",
            "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.143020\n",
            "Train Epoch: 6 [15360/60000 (25%)]\tLoss: 0.153420\n",
            "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 0.364093\n",
            "Train Epoch: 6 [25600/60000 (42%)]\tLoss: 0.368778\n",
            "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.227996\n",
            "Train Epoch: 6 [35840/60000 (59%)]\tLoss: 0.263538\n",
            "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.252262\n",
            "Train Epoch: 6 [46080/60000 (76%)]\tLoss: 0.149110\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.264632\n",
            "Train Epoch: 6 [56320/60000 (93%)]\tLoss: 0.258307\n",
            "Train Accuracy: (97%) \n",
            "\n",
            "Average loss: 0.6530, Accuracy: (94%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.104326\n",
            "Train Epoch: 7 [5120/60000 (8%)]\tLoss: 0.188048\n",
            "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.269713\n",
            "Train Epoch: 7 [15360/60000 (25%)]\tLoss: 0.098658\n",
            "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.182582\n",
            "Train Epoch: 7 [25600/60000 (42%)]\tLoss: 0.177947\n",
            "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.244674\n",
            "Train Epoch: 7 [35840/60000 (59%)]\tLoss: 0.407392\n",
            "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 0.193687\n",
            "Train Epoch: 7 [46080/60000 (76%)]\tLoss: 0.200495\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.101534\n",
            "Train Epoch: 7 [56320/60000 (93%)]\tLoss: 0.145277\n",
            "Train Accuracy: (97%) \n",
            "\n",
            "Average loss: 0.5836, Accuracy: (95%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.115179\n",
            "Train Epoch: 8 [5120/60000 (8%)]\tLoss: 0.091662\n",
            "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.312901\n",
            "Train Epoch: 8 [15360/60000 (25%)]\tLoss: 0.239028\n",
            "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 0.106876\n",
            "Train Epoch: 8 [25600/60000 (42%)]\tLoss: 0.195230\n",
            "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.184889\n",
            "Train Epoch: 8 [35840/60000 (59%)]\tLoss: 0.193865\n",
            "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 0.170465\n",
            "Train Epoch: 8 [46080/60000 (76%)]\tLoss: 0.211241\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.144306\n",
            "Train Epoch: 8 [56320/60000 (93%)]\tLoss: 0.104740\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.6650, Accuracy: (94%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.277856\n",
            "Train Epoch: 9 [5120/60000 (8%)]\tLoss: 0.090569\n",
            "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 0.193408\n",
            "Train Epoch: 9 [15360/60000 (25%)]\tLoss: 0.035634\n",
            "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 0.143822\n",
            "Train Epoch: 9 [25600/60000 (42%)]\tLoss: 0.192422\n",
            "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 0.123775\n",
            "Train Epoch: 9 [35840/60000 (59%)]\tLoss: 0.064203\n",
            "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 0.114759\n",
            "Train Epoch: 9 [46080/60000 (76%)]\tLoss: 0.183618\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.256794\n",
            "Train Epoch: 9 [56320/60000 (93%)]\tLoss: 0.166417\n",
            "Train Accuracy: (97%) \n",
            "\n",
            "Average loss: 0.6488, Accuracy: (95%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.120512\n",
            "Train Epoch: 10 [5120/60000 (8%)]\tLoss: 0.140086\n",
            "Train Epoch: 10 [10240/60000 (17%)]\tLoss: 0.234050\n",
            "Train Epoch: 10 [15360/60000 (25%)]\tLoss: 0.156050\n",
            "Train Epoch: 10 [20480/60000 (34%)]\tLoss: 0.037100\n",
            "Train Epoch: 10 [25600/60000 (42%)]\tLoss: 0.306942\n",
            "Train Epoch: 10 [30720/60000 (51%)]\tLoss: 0.069026\n",
            "Train Epoch: 10 [35840/60000 (59%)]\tLoss: 0.240223\n",
            "Train Epoch: 10 [40960/60000 (68%)]\tLoss: 0.144155\n",
            "Train Epoch: 10 [46080/60000 (76%)]\tLoss: 0.113142\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.332151\n",
            "Train Epoch: 10 [56320/60000 (93%)]\tLoss: 0.128546\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.6620, Accuracy: (95%)\n",
            "\n",
            "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.140089\n",
            "Train Epoch: 11 [5120/60000 (8%)]\tLoss: 0.225303\n",
            "Train Epoch: 11 [10240/60000 (17%)]\tLoss: 0.267494\n",
            "Train Epoch: 11 [15360/60000 (25%)]\tLoss: 0.069388\n",
            "Train Epoch: 11 [20480/60000 (34%)]\tLoss: 0.076772\n",
            "Train Epoch: 11 [25600/60000 (42%)]\tLoss: 0.110748\n",
            "Train Epoch: 11 [30720/60000 (51%)]\tLoss: 0.176977\n",
            "Train Epoch: 11 [35840/60000 (59%)]\tLoss: 0.153883\n",
            "Train Epoch: 11 [40960/60000 (68%)]\tLoss: 0.125862\n",
            "Train Epoch: 11 [46080/60000 (76%)]\tLoss: 0.248103\n",
            "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.036598\n",
            "Train Epoch: 11 [56320/60000 (93%)]\tLoss: 0.157790\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.6287, Accuracy: (95%)\n",
            "\n",
            "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.090845\n",
            "Train Epoch: 12 [5120/60000 (8%)]\tLoss: 0.174149\n",
            "Train Epoch: 12 [10240/60000 (17%)]\tLoss: 0.215690\n",
            "Train Epoch: 12 [15360/60000 (25%)]\tLoss: 0.184220\n",
            "Train Epoch: 12 [20480/60000 (34%)]\tLoss: 0.110604\n",
            "Train Epoch: 12 [25600/60000 (42%)]\tLoss: 0.089181\n",
            "Train Epoch: 12 [30720/60000 (51%)]\tLoss: 0.184782\n",
            "Train Epoch: 12 [35840/60000 (59%)]\tLoss: 0.221555\n",
            "Train Epoch: 12 [40960/60000 (68%)]\tLoss: 0.214939\n",
            "Train Epoch: 12 [46080/60000 (76%)]\tLoss: 0.294928\n",
            "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.197282\n",
            "Train Epoch: 12 [56320/60000 (93%)]\tLoss: 0.182089\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.5804, Accuracy: (95%)\n",
            "\n",
            "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.035082\n",
            "Train Epoch: 13 [5120/60000 (8%)]\tLoss: 0.164248\n",
            "Train Epoch: 13 [10240/60000 (17%)]\tLoss: 0.172647\n",
            "Train Epoch: 13 [15360/60000 (25%)]\tLoss: 0.210590\n",
            "Train Epoch: 13 [20480/60000 (34%)]\tLoss: 0.266775\n",
            "Train Epoch: 13 [25600/60000 (42%)]\tLoss: 0.304737\n",
            "Train Epoch: 13 [30720/60000 (51%)]\tLoss: 0.134150\n",
            "Train Epoch: 13 [35840/60000 (59%)]\tLoss: 0.255043\n",
            "Train Epoch: 13 [40960/60000 (68%)]\tLoss: 0.204590\n",
            "Train Epoch: 13 [46080/60000 (76%)]\tLoss: 0.138348\n",
            "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.174442\n",
            "Train Epoch: 13 [56320/60000 (93%)]\tLoss: 0.400136\n",
            "Train Accuracy: (97%) \n",
            "\n",
            "Average loss: 0.8527, Accuracy: (95%)\n",
            "\n",
            "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.298502\n",
            "Train Epoch: 14 [5120/60000 (8%)]\tLoss: 0.253474\n",
            "Train Epoch: 14 [10240/60000 (17%)]\tLoss: 0.196606\n",
            "Train Epoch: 14 [15360/60000 (25%)]\tLoss: 0.226101\n",
            "Train Epoch: 14 [20480/60000 (34%)]\tLoss: 0.255214\n",
            "Train Epoch: 14 [25600/60000 (42%)]\tLoss: 0.052675\n",
            "Train Epoch: 14 [30720/60000 (51%)]\tLoss: 0.242387\n",
            "Train Epoch: 14 [35840/60000 (59%)]\tLoss: 0.134984\n",
            "Train Epoch: 14 [40960/60000 (68%)]\tLoss: 0.173735\n",
            "Train Epoch: 14 [46080/60000 (76%)]\tLoss: 0.401297\n",
            "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.212769\n",
            "Train Epoch: 14 [56320/60000 (93%)]\tLoss: 0.042844\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.7900, Accuracy: (94%)\n",
            "\n",
            "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.208044\n",
            "Train Epoch: 15 [5120/60000 (8%)]\tLoss: 0.187941\n",
            "Train Epoch: 15 [10240/60000 (17%)]\tLoss: 0.158885\n",
            "Train Epoch: 15 [15360/60000 (25%)]\tLoss: 0.092757\n",
            "Train Epoch: 15 [20480/60000 (34%)]\tLoss: 0.202073\n",
            "Train Epoch: 15 [25600/60000 (42%)]\tLoss: 0.016594\n",
            "Train Epoch: 15 [30720/60000 (51%)]\tLoss: 0.134590\n",
            "Train Epoch: 15 [35840/60000 (59%)]\tLoss: 0.087858\n",
            "Train Epoch: 15 [40960/60000 (68%)]\tLoss: 0.271136\n",
            "Train Epoch: 15 [46080/60000 (76%)]\tLoss: 0.205272\n",
            "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.105237\n",
            "Train Epoch: 15 [56320/60000 (93%)]\tLoss: 0.222053\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.5996, Accuracy: (96%)\n",
            "\n",
            "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.045648\n",
            "Train Epoch: 16 [5120/60000 (8%)]\tLoss: 0.139926\n",
            "Train Epoch: 16 [10240/60000 (17%)]\tLoss: 0.331266\n",
            "Train Epoch: 16 [15360/60000 (25%)]\tLoss: 0.195980\n",
            "Train Epoch: 16 [20480/60000 (34%)]\tLoss: 0.127869\n",
            "Train Epoch: 16 [25600/60000 (42%)]\tLoss: 0.123169\n",
            "Train Epoch: 16 [30720/60000 (51%)]\tLoss: 0.108186\n",
            "Train Epoch: 16 [35840/60000 (59%)]\tLoss: 0.128266\n",
            "Train Epoch: 16 [40960/60000 (68%)]\tLoss: 0.534035\n",
            "Train Epoch: 16 [46080/60000 (76%)]\tLoss: 0.142174\n",
            "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 0.329536\n",
            "Train Epoch: 16 [56320/60000 (93%)]\tLoss: 0.330331\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.7233, Accuracy: (95%)\n",
            "\n",
            "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.146481\n",
            "Train Epoch: 17 [5120/60000 (8%)]\tLoss: 0.286176\n",
            "Train Epoch: 17 [10240/60000 (17%)]\tLoss: 0.118479\n",
            "Train Epoch: 17 [15360/60000 (25%)]\tLoss: 0.072123\n",
            "Train Epoch: 17 [20480/60000 (34%)]\tLoss: 0.172359\n",
            "Train Epoch: 17 [25600/60000 (42%)]\tLoss: 0.189997\n",
            "Train Epoch: 17 [30720/60000 (51%)]\tLoss: 0.182454\n",
            "Train Epoch: 17 [35840/60000 (59%)]\tLoss: 0.131265\n",
            "Train Epoch: 17 [40960/60000 (68%)]\tLoss: 0.176551\n",
            "Train Epoch: 17 [46080/60000 (76%)]\tLoss: 0.084062\n",
            "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 0.099583\n",
            "Train Epoch: 17 [56320/60000 (93%)]\tLoss: 0.234772\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.6439, Accuracy: (95%)\n",
            "\n",
            "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.050751\n",
            "Train Epoch: 18 [5120/60000 (8%)]\tLoss: 0.079397\n",
            "Train Epoch: 18 [10240/60000 (17%)]\tLoss: 0.227155\n",
            "Train Epoch: 18 [15360/60000 (25%)]\tLoss: 0.140551\n",
            "Train Epoch: 18 [20480/60000 (34%)]\tLoss: 0.250276\n",
            "Train Epoch: 18 [25600/60000 (42%)]\tLoss: 0.211161\n",
            "Train Epoch: 18 [30720/60000 (51%)]\tLoss: 0.232366\n",
            "Train Epoch: 18 [35840/60000 (59%)]\tLoss: 0.161897\n",
            "Train Epoch: 18 [40960/60000 (68%)]\tLoss: 0.088485\n",
            "Train Epoch: 18 [46080/60000 (76%)]\tLoss: 0.149823\n",
            "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 0.235220\n",
            "Train Epoch: 18 [56320/60000 (93%)]\tLoss: 0.123000\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.6809, Accuracy: (95%)\n",
            "\n",
            "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.200159\n",
            "Train Epoch: 19 [5120/60000 (8%)]\tLoss: 0.158559\n",
            "Train Epoch: 19 [10240/60000 (17%)]\tLoss: 0.199276\n",
            "Train Epoch: 19 [15360/60000 (25%)]\tLoss: 0.158246\n",
            "Train Epoch: 19 [20480/60000 (34%)]\tLoss: 0.096121\n",
            "Train Epoch: 19 [25600/60000 (42%)]\tLoss: 0.191929\n",
            "Train Epoch: 19 [30720/60000 (51%)]\tLoss: 0.123740\n",
            "Train Epoch: 19 [35840/60000 (59%)]\tLoss: 0.219778\n",
            "Train Epoch: 19 [40960/60000 (68%)]\tLoss: 0.222744\n",
            "Train Epoch: 19 [46080/60000 (76%)]\tLoss: 0.209228\n",
            "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 0.220094\n",
            "Train Epoch: 19 [56320/60000 (93%)]\tLoss: 0.140224\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.6096, Accuracy: (96%)\n",
            "\n",
            "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.188008\n",
            "Train Epoch: 20 [5120/60000 (8%)]\tLoss: 0.295826\n",
            "Train Epoch: 20 [10240/60000 (17%)]\tLoss: 0.140054\n",
            "Train Epoch: 20 [15360/60000 (25%)]\tLoss: 0.211127\n",
            "Train Epoch: 20 [20480/60000 (34%)]\tLoss: 0.123686\n",
            "Train Epoch: 20 [25600/60000 (42%)]\tLoss: 0.319548\n",
            "Train Epoch: 20 [30720/60000 (51%)]\tLoss: 0.118813\n",
            "Train Epoch: 20 [35840/60000 (59%)]\tLoss: 0.177830\n",
            "Train Epoch: 20 [40960/60000 (68%)]\tLoss: 0.217950\n",
            "Train Epoch: 20 [46080/60000 (76%)]\tLoss: 0.422875\n",
            "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 0.236619\n",
            "Train Epoch: 20 [56320/60000 (93%)]\tLoss: 0.256008\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.6073, Accuracy: (96%)\n",
            "\n",
            "Train Epoch: 21 [0/60000 (0%)]\tLoss: 0.289442\n",
            "Train Epoch: 21 [5120/60000 (8%)]\tLoss: 0.121857\n",
            "Train Epoch: 21 [10240/60000 (17%)]\tLoss: 0.192048\n",
            "Train Epoch: 21 [15360/60000 (25%)]\tLoss: 0.043435\n",
            "Train Epoch: 21 [20480/60000 (34%)]\tLoss: 0.174817\n",
            "Train Epoch: 21 [25600/60000 (42%)]\tLoss: 0.058247\n",
            "Train Epoch: 21 [30720/60000 (51%)]\tLoss: 0.338638\n",
            "Train Epoch: 21 [35840/60000 (59%)]\tLoss: 0.151795\n",
            "Train Epoch: 21 [40960/60000 (68%)]\tLoss: 0.143683\n",
            "Train Epoch: 21 [46080/60000 (76%)]\tLoss: 0.344441\n",
            "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 0.303664\n",
            "Train Epoch: 21 [56320/60000 (93%)]\tLoss: 0.014628\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.5902, Accuracy: (96%)\n",
            "\n",
            "Train Epoch: 22 [0/60000 (0%)]\tLoss: 0.082890\n",
            "Train Epoch: 22 [5120/60000 (8%)]\tLoss: 0.100829\n",
            "Train Epoch: 22 [10240/60000 (17%)]\tLoss: 0.126361\n",
            "Train Epoch: 22 [15360/60000 (25%)]\tLoss: 0.056362\n",
            "Train Epoch: 22 [20480/60000 (34%)]\tLoss: 0.147776\n",
            "Train Epoch: 22 [25600/60000 (42%)]\tLoss: 0.191582\n",
            "Train Epoch: 22 [30720/60000 (51%)]\tLoss: 0.233063\n",
            "Train Epoch: 22 [35840/60000 (59%)]\tLoss: 0.118928\n",
            "Train Epoch: 22 [40960/60000 (68%)]\tLoss: 0.279081\n",
            "Train Epoch: 22 [46080/60000 (76%)]\tLoss: 0.106490\n",
            "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 0.152427\n",
            "Train Epoch: 22 [56320/60000 (93%)]\tLoss: 0.273507\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.6935, Accuracy: (95%)\n",
            "\n",
            "Train Epoch: 23 [0/60000 (0%)]\tLoss: 0.276224\n",
            "Train Epoch: 23 [5120/60000 (8%)]\tLoss: 0.062165\n",
            "Train Epoch: 23 [10240/60000 (17%)]\tLoss: 0.096833\n",
            "Train Epoch: 23 [15360/60000 (25%)]\tLoss: 0.179022\n",
            "Train Epoch: 23 [20480/60000 (34%)]\tLoss: 0.191430\n",
            "Train Epoch: 23 [25600/60000 (42%)]\tLoss: 0.249809\n",
            "Train Epoch: 23 [30720/60000 (51%)]\tLoss: 0.084645\n",
            "Train Epoch: 23 [35840/60000 (59%)]\tLoss: 0.231913\n",
            "Train Epoch: 23 [40960/60000 (68%)]\tLoss: 0.318168\n",
            "Train Epoch: 23 [46080/60000 (76%)]\tLoss: 0.223504\n",
            "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 0.300315\n",
            "Train Epoch: 23 [56320/60000 (93%)]\tLoss: 0.337412\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.7322, Accuracy: (95%)\n",
            "\n",
            "Train Epoch: 24 [0/60000 (0%)]\tLoss: 0.254464\n",
            "Train Epoch: 24 [5120/60000 (8%)]\tLoss: 0.673101\n",
            "Train Epoch: 24 [10240/60000 (17%)]\tLoss: 0.489572\n",
            "Train Epoch: 24 [15360/60000 (25%)]\tLoss: 0.402642\n",
            "Train Epoch: 24 [20480/60000 (34%)]\tLoss: 0.437240\n",
            "Train Epoch: 24 [25600/60000 (42%)]\tLoss: 0.340257\n",
            "Train Epoch: 24 [30720/60000 (51%)]\tLoss: 0.336712\n",
            "Train Epoch: 24 [35840/60000 (59%)]\tLoss: 0.185002\n",
            "Train Epoch: 24 [40960/60000 (68%)]\tLoss: 0.234414\n",
            "Train Epoch: 24 [46080/60000 (76%)]\tLoss: 0.437578\n",
            "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 0.326955\n",
            "Train Epoch: 24 [56320/60000 (93%)]\tLoss: 0.124707\n",
            "Train Accuracy: (97%) \n",
            "\n",
            "Average loss: 0.6132, Accuracy: (95%)\n",
            "\n",
            "Train Epoch: 25 [0/60000 (0%)]\tLoss: 0.391966\n",
            "Train Epoch: 25 [5120/60000 (8%)]\tLoss: 0.456529\n",
            "Train Epoch: 25 [10240/60000 (17%)]\tLoss: 0.151946\n",
            "Train Epoch: 25 [15360/60000 (25%)]\tLoss: 0.081158\n",
            "Train Epoch: 25 [20480/60000 (34%)]\tLoss: 0.149420\n",
            "Train Epoch: 25 [25600/60000 (42%)]\tLoss: 0.125291\n",
            "Train Epoch: 25 [30720/60000 (51%)]\tLoss: 0.223964\n",
            "Train Epoch: 25 [35840/60000 (59%)]\tLoss: 0.105098\n",
            "Train Epoch: 25 [40960/60000 (68%)]\tLoss: 0.186964\n",
            "Train Epoch: 25 [46080/60000 (76%)]\tLoss: 0.235702\n",
            "Train Epoch: 25 [51200/60000 (85%)]\tLoss: 0.135558\n",
            "Train Epoch: 25 [56320/60000 (93%)]\tLoss: 0.162741\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.5686, Accuracy: (96%)\n",
            "\n",
            "Train Epoch: 26 [0/60000 (0%)]\tLoss: 0.127062\n",
            "Train Epoch: 26 [5120/60000 (8%)]\tLoss: 0.385014\n",
            "Train Epoch: 26 [10240/60000 (17%)]\tLoss: 0.167925\n",
            "Train Epoch: 26 [15360/60000 (25%)]\tLoss: 0.087371\n",
            "Train Epoch: 26 [20480/60000 (34%)]\tLoss: 0.269381\n",
            "Train Epoch: 26 [25600/60000 (42%)]\tLoss: 0.089055\n",
            "Train Epoch: 26 [30720/60000 (51%)]\tLoss: 0.159711\n",
            "Train Epoch: 26 [35840/60000 (59%)]\tLoss: 0.322925\n",
            "Train Epoch: 26 [40960/60000 (68%)]\tLoss: 0.216899\n",
            "Train Epoch: 26 [46080/60000 (76%)]\tLoss: 0.388985\n",
            "Train Epoch: 26 [51200/60000 (85%)]\tLoss: 0.154991\n",
            "Train Epoch: 26 [56320/60000 (93%)]\tLoss: 0.327820\n",
            "Train Accuracy: (97%) \n",
            "\n",
            "Average loss: 0.6348, Accuracy: (96%)\n",
            "\n",
            "Train Epoch: 27 [0/60000 (0%)]\tLoss: 0.249187\n",
            "Train Epoch: 27 [5120/60000 (8%)]\tLoss: 0.333166\n",
            "Train Epoch: 27 [10240/60000 (17%)]\tLoss: 0.159760\n",
            "Train Epoch: 27 [15360/60000 (25%)]\tLoss: 0.030172\n",
            "Train Epoch: 27 [20480/60000 (34%)]\tLoss: 0.082810\n",
            "Train Epoch: 27 [25600/60000 (42%)]\tLoss: 0.155975\n",
            "Train Epoch: 27 [30720/60000 (51%)]\tLoss: 0.305823\n",
            "Train Epoch: 27 [35840/60000 (59%)]\tLoss: 0.251729\n",
            "Train Epoch: 27 [40960/60000 (68%)]\tLoss: 0.204817\n",
            "Train Epoch: 27 [46080/60000 (76%)]\tLoss: 0.077348\n",
            "Train Epoch: 27 [51200/60000 (85%)]\tLoss: 0.173562\n",
            "Train Epoch: 27 [56320/60000 (93%)]\tLoss: 0.452644\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.5978, Accuracy: (96%)\n",
            "\n",
            "Train Epoch: 28 [0/60000 (0%)]\tLoss: 0.118288\n",
            "Train Epoch: 28 [5120/60000 (8%)]\tLoss: 0.324310\n",
            "Train Epoch: 28 [10240/60000 (17%)]\tLoss: 0.180171\n",
            "Train Epoch: 28 [15360/60000 (25%)]\tLoss: 0.119970\n",
            "Train Epoch: 28 [20480/60000 (34%)]\tLoss: 0.270707\n",
            "Train Epoch: 28 [25600/60000 (42%)]\tLoss: 0.302408\n",
            "Train Epoch: 28 [30720/60000 (51%)]\tLoss: 0.180121\n",
            "Train Epoch: 28 [35840/60000 (59%)]\tLoss: 0.209265\n",
            "Train Epoch: 28 [40960/60000 (68%)]\tLoss: 0.281243\n",
            "Train Epoch: 28 [46080/60000 (76%)]\tLoss: 0.268932\n",
            "Train Epoch: 28 [51200/60000 (85%)]\tLoss: 0.089442\n",
            "Train Epoch: 28 [56320/60000 (93%)]\tLoss: 0.177922\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.5352, Accuracy: (96%)\n",
            "\n",
            "Train Epoch: 29 [0/60000 (0%)]\tLoss: 0.067317\n",
            "Train Epoch: 29 [5120/60000 (8%)]\tLoss: 0.181019\n",
            "Train Epoch: 29 [10240/60000 (17%)]\tLoss: 0.326679\n",
            "Train Epoch: 29 [15360/60000 (25%)]\tLoss: 0.247044\n",
            "Train Epoch: 29 [20480/60000 (34%)]\tLoss: 0.159765\n",
            "Train Epoch: 29 [25600/60000 (42%)]\tLoss: 0.208536\n",
            "Train Epoch: 29 [30720/60000 (51%)]\tLoss: 0.078326\n",
            "Train Epoch: 29 [35840/60000 (59%)]\tLoss: 0.032652\n",
            "Train Epoch: 29 [40960/60000 (68%)]\tLoss: 0.136562\n",
            "Train Epoch: 29 [46080/60000 (76%)]\tLoss: 0.115140\n",
            "Train Epoch: 29 [51200/60000 (85%)]\tLoss: 0.104371\n",
            "Train Epoch: 29 [56320/60000 (93%)]\tLoss: 0.128095\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.4941, Accuracy: (96%)\n",
            "\n",
            "Train Epoch: 30 [0/60000 (0%)]\tLoss: 0.111892\n",
            "Train Epoch: 30 [5120/60000 (8%)]\tLoss: 0.171620\n",
            "Train Epoch: 30 [10240/60000 (17%)]\tLoss: 0.017360\n",
            "Train Epoch: 30 [15360/60000 (25%)]\tLoss: 0.209070\n",
            "Train Epoch: 30 [20480/60000 (34%)]\tLoss: 0.231704\n",
            "Train Epoch: 30 [25600/60000 (42%)]\tLoss: 0.053946\n",
            "Train Epoch: 30 [30720/60000 (51%)]\tLoss: 0.054262\n",
            "Train Epoch: 30 [35840/60000 (59%)]\tLoss: 0.133908\n",
            "Train Epoch: 30 [40960/60000 (68%)]\tLoss: 0.162925\n",
            "Train Epoch: 30 [46080/60000 (76%)]\tLoss: 0.270758\n",
            "Train Epoch: 30 [51200/60000 (85%)]\tLoss: 0.355034\n",
            "Train Epoch: 30 [56320/60000 (93%)]\tLoss: 0.237439\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.5032, Accuracy: (96%)\n",
            "\n",
            "Train Epoch: 31 [0/60000 (0%)]\tLoss: 0.137834\n",
            "Train Epoch: 31 [5120/60000 (8%)]\tLoss: 0.237037\n",
            "Train Epoch: 31 [10240/60000 (17%)]\tLoss: 0.118650\n",
            "Train Epoch: 31 [15360/60000 (25%)]\tLoss: 0.121915\n",
            "Train Epoch: 31 [20480/60000 (34%)]\tLoss: 0.064177\n",
            "Train Epoch: 31 [25600/60000 (42%)]\tLoss: 0.165983\n",
            "Train Epoch: 31 [30720/60000 (51%)]\tLoss: 0.143775\n",
            "Train Epoch: 31 [35840/60000 (59%)]\tLoss: 0.001943\n",
            "Train Epoch: 31 [40960/60000 (68%)]\tLoss: 0.098178\n",
            "Train Epoch: 31 [46080/60000 (76%)]\tLoss: 0.074030\n",
            "Train Epoch: 31 [51200/60000 (85%)]\tLoss: 0.098593\n",
            "Train Epoch: 31 [56320/60000 (93%)]\tLoss: 0.160440\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.4834, Accuracy: (97%)\n",
            "\n",
            "Train Epoch: 32 [0/60000 (0%)]\tLoss: 0.106530\n",
            "Train Epoch: 32 [5120/60000 (8%)]\tLoss: 0.335084\n",
            "Train Epoch: 32 [10240/60000 (17%)]\tLoss: 0.103570\n",
            "Train Epoch: 32 [15360/60000 (25%)]\tLoss: 0.183483\n",
            "Train Epoch: 32 [20480/60000 (34%)]\tLoss: 0.284877\n",
            "Train Epoch: 32 [25600/60000 (42%)]\tLoss: 0.143440\n",
            "Train Epoch: 32 [30720/60000 (51%)]\tLoss: 0.107667\n",
            "Train Epoch: 32 [35840/60000 (59%)]\tLoss: 0.157378\n",
            "Train Epoch: 32 [40960/60000 (68%)]\tLoss: 0.249873\n",
            "Train Epoch: 32 [46080/60000 (76%)]\tLoss: 0.141606\n",
            "Train Epoch: 32 [51200/60000 (85%)]\tLoss: 0.100664\n",
            "Train Epoch: 32 [56320/60000 (93%)]\tLoss: 0.297091\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.5810, Accuracy: (96%)\n",
            "\n",
            "Train Epoch: 33 [0/60000 (0%)]\tLoss: 0.146952\n",
            "Train Epoch: 33 [5120/60000 (8%)]\tLoss: 0.155557\n",
            "Train Epoch: 33 [10240/60000 (17%)]\tLoss: 0.088816\n",
            "Train Epoch: 33 [15360/60000 (25%)]\tLoss: 0.256316\n",
            "Train Epoch: 33 [20480/60000 (34%)]\tLoss: 0.279471\n",
            "Train Epoch: 33 [25600/60000 (42%)]\tLoss: 0.138294\n",
            "Train Epoch: 33 [30720/60000 (51%)]\tLoss: 0.209136\n",
            "Train Epoch: 33 [35840/60000 (59%)]\tLoss: 0.347165\n",
            "Train Epoch: 33 [40960/60000 (68%)]\tLoss: 0.163551\n",
            "Train Epoch: 33 [46080/60000 (76%)]\tLoss: 0.149537\n",
            "Train Epoch: 33 [51200/60000 (85%)]\tLoss: 0.241472\n",
            "Train Epoch: 33 [56320/60000 (93%)]\tLoss: 0.232140\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.6256, Accuracy: (96%)\n",
            "\n",
            "Train Epoch: 34 [0/60000 (0%)]\tLoss: 0.098075\n",
            "Train Epoch: 34 [5120/60000 (8%)]\tLoss: 0.127907\n",
            "Train Epoch: 34 [10240/60000 (17%)]\tLoss: 0.014971\n",
            "Train Epoch: 34 [15360/60000 (25%)]\tLoss: 0.039324\n",
            "Train Epoch: 34 [20480/60000 (34%)]\tLoss: 0.300707\n",
            "Train Epoch: 34 [25600/60000 (42%)]\tLoss: 0.191037\n",
            "Train Epoch: 34 [30720/60000 (51%)]\tLoss: 0.157459\n",
            "Train Epoch: 34 [35840/60000 (59%)]\tLoss: 0.126566\n",
            "Train Epoch: 34 [40960/60000 (68%)]\tLoss: 0.135664\n",
            "Train Epoch: 34 [46080/60000 (76%)]\tLoss: 0.299229\n",
            "Train Epoch: 34 [51200/60000 (85%)]\tLoss: 0.198003\n",
            "Train Epoch: 34 [56320/60000 (93%)]\tLoss: 0.193659\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.4437, Accuracy: (97%)\n",
            "\n",
            "Train Epoch: 35 [0/60000 (0%)]\tLoss: 0.150016\n",
            "Train Epoch: 35 [5120/60000 (8%)]\tLoss: 0.096004\n",
            "Train Epoch: 35 [10240/60000 (17%)]\tLoss: 0.066886\n",
            "Train Epoch: 35 [15360/60000 (25%)]\tLoss: 0.034513\n",
            "Train Epoch: 35 [20480/60000 (34%)]\tLoss: 0.137033\n",
            "Train Epoch: 35 [25600/60000 (42%)]\tLoss: 0.165014\n",
            "Train Epoch: 35 [30720/60000 (51%)]\tLoss: 0.163865\n",
            "Train Epoch: 35 [35840/60000 (59%)]\tLoss: 0.044529\n",
            "Train Epoch: 35 [40960/60000 (68%)]\tLoss: 0.069471\n",
            "Train Epoch: 35 [46080/60000 (76%)]\tLoss: 0.205129\n",
            "Train Epoch: 35 [51200/60000 (85%)]\tLoss: 0.065282\n",
            "Train Epoch: 35 [56320/60000 (93%)]\tLoss: 0.200410\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.5791, Accuracy: (96%)\n",
            "\n",
            "Train Epoch: 36 [0/60000 (0%)]\tLoss: 0.076600\n",
            "Train Epoch: 36 [5120/60000 (8%)]\tLoss: 0.145024\n",
            "Train Epoch: 36 [10240/60000 (17%)]\tLoss: 0.150724\n",
            "Train Epoch: 36 [15360/60000 (25%)]\tLoss: 0.081997\n",
            "Train Epoch: 36 [20480/60000 (34%)]\tLoss: 0.048770\n",
            "Train Epoch: 36 [25600/60000 (42%)]\tLoss: 0.066969\n",
            "Train Epoch: 36 [30720/60000 (51%)]\tLoss: 0.112963\n",
            "Train Epoch: 36 [35840/60000 (59%)]\tLoss: 0.110274\n",
            "Train Epoch: 36 [40960/60000 (68%)]\tLoss: 0.085583\n",
            "Train Epoch: 36 [46080/60000 (76%)]\tLoss: 0.029866\n",
            "Train Epoch: 36 [51200/60000 (85%)]\tLoss: 0.139295\n",
            "Train Epoch: 36 [56320/60000 (93%)]\tLoss: 0.068676\n",
            "Train Accuracy: (99%) \n",
            "\n",
            "Average loss: 0.4845, Accuracy: (97%)\n",
            "\n",
            "Train Epoch: 37 [0/60000 (0%)]\tLoss: 0.116511\n",
            "Train Epoch: 37 [5120/60000 (8%)]\tLoss: 0.173381\n",
            "Train Epoch: 37 [10240/60000 (17%)]\tLoss: 0.139326\n",
            "Train Epoch: 37 [15360/60000 (25%)]\tLoss: 0.137451\n",
            "Train Epoch: 37 [20480/60000 (34%)]\tLoss: 0.112853\n",
            "Train Epoch: 37 [25600/60000 (42%)]\tLoss: 0.165337\n",
            "Train Epoch: 37 [30720/60000 (51%)]\tLoss: 0.115831\n",
            "Train Epoch: 37 [35840/60000 (59%)]\tLoss: 0.096035\n",
            "Train Epoch: 37 [40960/60000 (68%)]\tLoss: 0.046718\n",
            "Train Epoch: 37 [46080/60000 (76%)]\tLoss: 0.091963\n",
            "Train Epoch: 37 [51200/60000 (85%)]\tLoss: 0.056463\n",
            "Train Epoch: 37 [56320/60000 (93%)]\tLoss: 0.182673\n",
            "Train Accuracy: (99%) \n",
            "\n",
            "Average loss: 0.5386, Accuracy: (96%)\n",
            "\n",
            "Train Epoch: 38 [0/60000 (0%)]\tLoss: 0.117115\n",
            "Train Epoch: 38 [5120/60000 (8%)]\tLoss: 0.082653\n",
            "Train Epoch: 38 [10240/60000 (17%)]\tLoss: 0.134968\n",
            "Train Epoch: 38 [15360/60000 (25%)]\tLoss: 0.052883\n",
            "Train Epoch: 38 [20480/60000 (34%)]\tLoss: 0.035341\n",
            "Train Epoch: 38 [25600/60000 (42%)]\tLoss: 0.020693\n",
            "Train Epoch: 38 [30720/60000 (51%)]\tLoss: 0.011023\n",
            "Train Epoch: 38 [35840/60000 (59%)]\tLoss: 0.051588\n",
            "Train Epoch: 38 [40960/60000 (68%)]\tLoss: 0.063541\n",
            "Train Epoch: 38 [46080/60000 (76%)]\tLoss: 0.158361\n",
            "Train Epoch: 38 [51200/60000 (85%)]\tLoss: 0.049207\n",
            "Train Epoch: 38 [56320/60000 (93%)]\tLoss: 0.189710\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.5436, Accuracy: (97%)\n",
            "\n",
            "Train Epoch: 39 [0/60000 (0%)]\tLoss: 0.260839\n",
            "Train Epoch: 39 [5120/60000 (8%)]\tLoss: 0.043698\n",
            "Train Epoch: 39 [10240/60000 (17%)]\tLoss: 0.195179\n",
            "Train Epoch: 39 [15360/60000 (25%)]\tLoss: 0.080297\n",
            "Train Epoch: 39 [20480/60000 (34%)]\tLoss: 0.083578\n",
            "Train Epoch: 39 [25600/60000 (42%)]\tLoss: 0.053661\n",
            "Train Epoch: 39 [30720/60000 (51%)]\tLoss: 0.064975\n",
            "Train Epoch: 39 [35840/60000 (59%)]\tLoss: 0.088410\n",
            "Train Epoch: 39 [40960/60000 (68%)]\tLoss: 0.062715\n",
            "Train Epoch: 39 [46080/60000 (76%)]\tLoss: 0.225342\n",
            "Train Epoch: 39 [51200/60000 (85%)]\tLoss: 0.052976\n",
            "Train Epoch: 39 [56320/60000 (93%)]\tLoss: 0.056997\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.5605, Accuracy: (96%)\n",
            "\n",
            "Train Epoch: 40 [0/60000 (0%)]\tLoss: 0.070672\n",
            "Train Epoch: 40 [5120/60000 (8%)]\tLoss: 0.226163\n",
            "Train Epoch: 40 [10240/60000 (17%)]\tLoss: 0.318039\n",
            "Train Epoch: 40 [15360/60000 (25%)]\tLoss: 0.158225\n",
            "Train Epoch: 40 [20480/60000 (34%)]\tLoss: 0.397966\n",
            "Train Epoch: 40 [25600/60000 (42%)]\tLoss: 0.207461\n",
            "Train Epoch: 40 [30720/60000 (51%)]\tLoss: 0.220606\n",
            "Train Epoch: 40 [35840/60000 (59%)]\tLoss: 0.113002\n",
            "Train Epoch: 40 [40960/60000 (68%)]\tLoss: 0.111833\n",
            "Train Epoch: 40 [46080/60000 (76%)]\tLoss: 0.359454\n",
            "Train Epoch: 40 [51200/60000 (85%)]\tLoss: 0.288328\n",
            "Train Epoch: 40 [56320/60000 (93%)]\tLoss: 0.145213\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.4628, Accuracy: (96%)\n",
            "\n",
            "Train Epoch: 41 [0/60000 (0%)]\tLoss: 0.089450\n",
            "Train Epoch: 41 [5120/60000 (8%)]\tLoss: 0.111317\n",
            "Train Epoch: 41 [10240/60000 (17%)]\tLoss: 0.061821\n",
            "Train Epoch: 41 [15360/60000 (25%)]\tLoss: 0.155466\n",
            "Train Epoch: 41 [20480/60000 (34%)]\tLoss: 0.206663\n",
            "Train Epoch: 41 [25600/60000 (42%)]\tLoss: 0.212563\n",
            "Train Epoch: 41 [30720/60000 (51%)]\tLoss: 0.096574\n",
            "Train Epoch: 41 [35840/60000 (59%)]\tLoss: 0.172215\n",
            "Train Epoch: 41 [40960/60000 (68%)]\tLoss: 0.093224\n",
            "Train Epoch: 41 [46080/60000 (76%)]\tLoss: 0.109444\n",
            "Train Epoch: 41 [51200/60000 (85%)]\tLoss: 0.125697\n",
            "Train Epoch: 41 [56320/60000 (93%)]\tLoss: 0.185128\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.3714, Accuracy: (97%)\n",
            "\n",
            "Train Epoch: 42 [0/60000 (0%)]\tLoss: 0.116107\n",
            "Train Epoch: 42 [5120/60000 (8%)]\tLoss: 0.124209\n",
            "Train Epoch: 42 [10240/60000 (17%)]\tLoss: 0.056934\n",
            "Train Epoch: 42 [15360/60000 (25%)]\tLoss: 0.082209\n",
            "Train Epoch: 42 [20480/60000 (34%)]\tLoss: 0.143967\n",
            "Train Epoch: 42 [25600/60000 (42%)]\tLoss: 0.084676\n",
            "Train Epoch: 42 [30720/60000 (51%)]\tLoss: 0.088630\n",
            "Train Epoch: 42 [35840/60000 (59%)]\tLoss: 0.047434\n",
            "Train Epoch: 42 [40960/60000 (68%)]\tLoss: 0.064201\n",
            "Train Epoch: 42 [46080/60000 (76%)]\tLoss: 0.002406\n",
            "Train Epoch: 42 [51200/60000 (85%)]\tLoss: 0.151893\n",
            "Train Epoch: 42 [56320/60000 (93%)]\tLoss: 0.193840\n",
            "Train Accuracy: (99%) \n",
            "\n",
            "Average loss: 0.3874, Accuracy: (97%)\n",
            "\n",
            "Train Epoch: 43 [0/60000 (0%)]\tLoss: 0.135969\n",
            "Train Epoch: 43 [5120/60000 (8%)]\tLoss: 0.038495\n",
            "Train Epoch: 43 [10240/60000 (17%)]\tLoss: 0.191567\n",
            "Train Epoch: 43 [15360/60000 (25%)]\tLoss: 0.079065\n",
            "Train Epoch: 43 [20480/60000 (34%)]\tLoss: 0.115088\n",
            "Train Epoch: 43 [25600/60000 (42%)]\tLoss: 0.216435\n",
            "Train Epoch: 43 [30720/60000 (51%)]\tLoss: 0.042448\n",
            "Train Epoch: 43 [35840/60000 (59%)]\tLoss: 0.364435\n",
            "Train Epoch: 43 [40960/60000 (68%)]\tLoss: 0.047609\n",
            "Train Epoch: 43 [46080/60000 (76%)]\tLoss: 0.085410\n",
            "Train Epoch: 43 [51200/60000 (85%)]\tLoss: 0.103080\n",
            "Train Epoch: 43 [56320/60000 (93%)]\tLoss: 0.132927\n",
            "Train Accuracy: (99%) \n",
            "\n",
            "Average loss: 0.4771, Accuracy: (96%)\n",
            "\n",
            "Train Epoch: 44 [0/60000 (0%)]\tLoss: 0.039642\n",
            "Train Epoch: 44 [5120/60000 (8%)]\tLoss: 0.093678\n",
            "Train Epoch: 44 [10240/60000 (17%)]\tLoss: 0.022943\n",
            "Train Epoch: 44 [15360/60000 (25%)]\tLoss: 0.049452\n",
            "Train Epoch: 44 [20480/60000 (34%)]\tLoss: 0.035594\n",
            "Train Epoch: 44 [25600/60000 (42%)]\tLoss: 0.063744\n",
            "Train Epoch: 44 [30720/60000 (51%)]\tLoss: 0.118389\n",
            "Train Epoch: 44 [35840/60000 (59%)]\tLoss: 0.070949\n",
            "Train Epoch: 44 [40960/60000 (68%)]\tLoss: 0.038330\n",
            "Train Epoch: 44 [46080/60000 (76%)]\tLoss: 0.125806\n",
            "Train Epoch: 44 [51200/60000 (85%)]\tLoss: 0.140657\n",
            "Train Epoch: 44 [56320/60000 (93%)]\tLoss: 0.137416\n",
            "Train Accuracy: (99%) \n",
            "\n",
            "Average loss: 0.5596, Accuracy: (96%)\n",
            "\n",
            "Train Epoch: 45 [0/60000 (0%)]\tLoss: 0.267550\n",
            "Train Epoch: 45 [5120/60000 (8%)]\tLoss: 0.050214\n",
            "Train Epoch: 45 [10240/60000 (17%)]\tLoss: 0.088839\n",
            "Train Epoch: 45 [15360/60000 (25%)]\tLoss: 0.173171\n",
            "Train Epoch: 45 [20480/60000 (34%)]\tLoss: 0.137919\n",
            "Train Epoch: 45 [25600/60000 (42%)]\tLoss: 0.033559\n",
            "Train Epoch: 45 [30720/60000 (51%)]\tLoss: 0.293866\n",
            "Train Epoch: 45 [35840/60000 (59%)]\tLoss: 0.076267\n",
            "Train Epoch: 45 [40960/60000 (68%)]\tLoss: 0.067055\n",
            "Train Epoch: 45 [46080/60000 (76%)]\tLoss: 0.156673\n",
            "Train Epoch: 45 [51200/60000 (85%)]\tLoss: 0.099982\n",
            "Train Epoch: 45 [56320/60000 (93%)]\tLoss: 0.352414\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.4139, Accuracy: (96%)\n",
            "\n",
            "Train Epoch: 46 [0/60000 (0%)]\tLoss: 0.191782\n",
            "Train Epoch: 46 [5120/60000 (8%)]\tLoss: 0.103807\n",
            "Train Epoch: 46 [10240/60000 (17%)]\tLoss: 0.081573\n",
            "Train Epoch: 46 [15360/60000 (25%)]\tLoss: 0.053120\n",
            "Train Epoch: 46 [20480/60000 (34%)]\tLoss: 0.221661\n",
            "Train Epoch: 46 [25600/60000 (42%)]\tLoss: 0.060997\n",
            "Train Epoch: 46 [30720/60000 (51%)]\tLoss: 0.071792\n",
            "Train Epoch: 46 [35840/60000 (59%)]\tLoss: 0.123752\n",
            "Train Epoch: 46 [40960/60000 (68%)]\tLoss: 0.117338\n",
            "Train Epoch: 46 [46080/60000 (76%)]\tLoss: 0.074752\n",
            "Train Epoch: 46 [51200/60000 (85%)]\tLoss: 0.090268\n",
            "Train Epoch: 46 [56320/60000 (93%)]\tLoss: 0.071439\n",
            "Train Accuracy: (98%) \n",
            "\n",
            "Average loss: 0.3073, Accuracy: (97%)\n",
            "\n",
            "Train Epoch: 47 [0/60000 (0%)]\tLoss: 0.091462\n",
            "Train Epoch: 47 [5120/60000 (8%)]\tLoss: 0.080582\n",
            "Train Epoch: 47 [10240/60000 (17%)]\tLoss: 0.062880\n",
            "Train Epoch: 47 [15360/60000 (25%)]\tLoss: 0.066368\n",
            "Train Epoch: 47 [20480/60000 (34%)]\tLoss: 0.059715\n",
            "Train Epoch: 47 [25600/60000 (42%)]\tLoss: 0.006250\n",
            "Train Epoch: 47 [30720/60000 (51%)]\tLoss: 0.062452\n",
            "Train Epoch: 47 [35840/60000 (59%)]\tLoss: 0.027874\n",
            "Train Epoch: 47 [40960/60000 (68%)]\tLoss: 0.093380\n",
            "Train Epoch: 47 [46080/60000 (76%)]\tLoss: 0.056330\n",
            "Train Epoch: 47 [51200/60000 (85%)]\tLoss: 0.077093\n",
            "Train Epoch: 47 [56320/60000 (93%)]\tLoss: 0.112183\n",
            "Train Accuracy: (99%) \n",
            "\n",
            "Average loss: 0.3273, Accuracy: (97%)\n",
            "\n",
            "Train Epoch: 48 [0/60000 (0%)]\tLoss: 0.079225\n",
            "Train Epoch: 48 [5120/60000 (8%)]\tLoss: 0.008038\n",
            "Train Epoch: 48 [10240/60000 (17%)]\tLoss: 0.055829\n",
            "Train Epoch: 48 [15360/60000 (25%)]\tLoss: 0.063371\n",
            "Train Epoch: 48 [20480/60000 (34%)]\tLoss: 0.152184\n",
            "Train Epoch: 48 [25600/60000 (42%)]\tLoss: 0.047947\n",
            "Train Epoch: 48 [30720/60000 (51%)]\tLoss: 0.047488\n",
            "Train Epoch: 48 [35840/60000 (59%)]\tLoss: 0.013102\n",
            "Train Epoch: 48 [40960/60000 (68%)]\tLoss: 0.153728\n",
            "Train Epoch: 48 [46080/60000 (76%)]\tLoss: 0.094190\n",
            "Train Epoch: 48 [51200/60000 (85%)]\tLoss: 0.087075\n",
            "Train Epoch: 48 [56320/60000 (93%)]\tLoss: 0.047334\n",
            "Train Accuracy: (99%) \n",
            "\n",
            "Average loss: 0.3296, Accuracy: (97%)\n",
            "\n",
            "Train Epoch: 49 [0/60000 (0%)]\tLoss: 0.148208\n",
            "Train Epoch: 49 [5120/60000 (8%)]\tLoss: 0.010190\n",
            "Train Epoch: 49 [10240/60000 (17%)]\tLoss: 0.059449\n",
            "Train Epoch: 49 [15360/60000 (25%)]\tLoss: 0.029288\n",
            "Train Epoch: 49 [20480/60000 (34%)]\tLoss: 0.086145\n",
            "Train Epoch: 49 [25600/60000 (42%)]\tLoss: 0.092442\n",
            "Train Epoch: 49 [30720/60000 (51%)]\tLoss: 0.030760\n",
            "Train Epoch: 49 [35840/60000 (59%)]\tLoss: 0.067048\n",
            "Train Epoch: 49 [40960/60000 (68%)]\tLoss: 0.125466\n",
            "Train Epoch: 49 [46080/60000 (76%)]\tLoss: 0.073183\n",
            "Train Epoch: 49 [51200/60000 (85%)]\tLoss: 0.046328\n",
            "Train Epoch: 49 [56320/60000 (93%)]\tLoss: 0.038092\n",
            "Train Accuracy: (99%) \n",
            "\n",
            "Average loss: 0.2572, Accuracy: (97%)\n",
            "\n",
            "Train Epoch: 50 [0/60000 (0%)]\tLoss: 0.007216\n",
            "Train Epoch: 50 [5120/60000 (8%)]\tLoss: 0.004901\n",
            "Train Epoch: 50 [10240/60000 (17%)]\tLoss: 0.031594\n",
            "Train Epoch: 50 [15360/60000 (25%)]\tLoss: 0.055174\n",
            "Train Epoch: 50 [20480/60000 (34%)]\tLoss: 0.014921\n",
            "Train Epoch: 50 [25600/60000 (42%)]\tLoss: 0.040881\n",
            "Train Epoch: 50 [30720/60000 (51%)]\tLoss: 0.149095\n",
            "Train Epoch: 50 [35840/60000 (59%)]\tLoss: 0.072512\n",
            "Train Epoch: 50 [40960/60000 (68%)]\tLoss: 0.018810\n",
            "Train Epoch: 50 [46080/60000 (76%)]\tLoss: 0.047620\n",
            "Train Epoch: 50 [51200/60000 (85%)]\tLoss: 0.096106\n",
            "Train Epoch: 50 [56320/60000 (93%)]\tLoss: 0.039377\n",
            "Train Accuracy: (99%) \n",
            "\n",
            "Average loss: 0.3095, Accuracy: (97%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from tqdm import tqdm\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'test' function and 'lerp' function are defined elsewhere\n",
        "\n",
        "# Load your models\n",
        "model_a_saved = model_a\n",
        "model_b_saved = model_b\n",
        "\n",
        "# MNIST data loaders\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "test_kwargs = {'batch_size': 5000}\n",
        "train_kwargs = {'batch_size': 5000}\n",
        "dataset = datasets.MNIST('../data', train=False, download=True, transform=transform)\n",
        "dataset1 = datasets.MNIST('../data', train=True, download=True, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset1, **train_kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(dataset, **test_kwargs)\n",
        "\n",
        "# Interpolation\n",
        "lambdas = torch.linspace(0, 1, steps=25)\n",
        "test_acc_interp_naive = []\n",
        "train_acc_interp_naive = []\n",
        "\n",
        "# Naive interpolation\n",
        "model_a_dict = copy.deepcopy(model_a_saved.state_dict())\n",
        "model_b_dict = copy.deepcopy(model_b_saved.state_dict())\n",
        "for lam in tqdm(lambdas):\n",
        "    naive_p = lerp(lam, model_a_dict, model_b_dict)\n",
        "    model_b_saved.load_state_dict(naive_p)\n",
        "    test_loss, acc = test(model_b_saved.cuda(), 'cuda', test_loader)\n",
        "    test_acc_interp_naive.append(acc)\n",
        "    train_loss, acc = test(model_b_saved.cuda(), 'cuda', train_loader)\n",
        "    train_acc_interp_naive.append(acc)\n",
        "\n",
        "# Plotting\n",
        "fig = plt.figure()\n",
        "plt.plot(lambdas, train_acc_interp_naive, label='Train Accuracy (Naive)')\n",
        "plt.plot(lambdas, test_acc_interp_naive, label='Test Accuracy (Naive)')\n",
        "plt.xlabel('Lambda')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Naive Interpolation Accuracy')\n",
        "plt.legend()\n",
        "plt.savefig(f\"mnist_mlp_weight_matching_interp_accuracy_epoch_naive.png\", dpi=300)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qgxgHatuv8Sg",
        "outputId": "b1bd9664-da7c-4bd3-8788-180c1004cebd"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 0.3095, Accuracy: (97%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 1/25 [00:14<05:55, 14.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 0.0300, Accuracy: (99%)\n",
            "\n",
            "\n",
            "Average loss: 0.2407, Accuracy: (97%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 2/25 [00:32<06:15, 16.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 0.0397, Accuracy: (99%)\n",
            "\n",
            "\n",
            "Average loss: 0.2575, Accuracy: (95%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 3/25 [00:46<05:40, 15.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 0.1063, Accuracy: (97%)\n",
            "\n",
            "\n",
            "Average loss: 0.4352, Accuracy: (89%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 4/25 [01:03<05:32, 15.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 0.3351, Accuracy: (91%)\n",
            "\n",
            "\n",
            "Average loss: 1.0549, Accuracy: (72%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 5/25 [01:18<05:15, 15.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 0.9921, Accuracy: (74%)\n",
            "\n",
            "\n",
            "Average loss: 2.0150, Accuracy: (53%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 6/25 [01:33<04:55, 15.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 1.9757, Accuracy: (54%)\n",
            "\n",
            "\n",
            "Average loss: 2.6793, Accuracy: (40%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 7/25 [01:48<04:34, 15.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 2.6641, Accuracy: (41%)\n",
            "\n",
            "\n",
            "Average loss: 2.9910, Accuracy: (27%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 8/25 [02:03<04:16, 15.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 2.9898, Accuracy: (27%)\n",
            "\n",
            "\n",
            "Average loss: 3.0315, Accuracy: (17%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 9/25 [02:18<04:02, 15.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 3.0386, Accuracy: (17%)\n",
            "\n",
            "\n",
            "Average loss: 2.9595, Accuracy: (13%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 10/25 [02:34<03:51, 15.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 2.9693, Accuracy: (13%)\n",
            "\n",
            "\n",
            "Average loss: 2.9024, Accuracy: (11%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 11/25 [02:49<03:33, 15.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 2.9107, Accuracy: (11%)\n",
            "\n",
            "\n",
            "Average loss: 2.8938, Accuracy: (11%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 12/25 [03:04<03:16, 15.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 2.8894, Accuracy: (11%)\n",
            "\n",
            "\n",
            "Average loss: 2.8705, Accuracy: (11%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 13/25 [03:18<02:59, 14.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 2.8621, Accuracy: (11%)\n",
            "\n",
            "\n",
            "Average loss: 2.8198, Accuracy: (11%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 14/25 [03:33<02:44, 14.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 2.8105, Accuracy: (11%)\n",
            "\n",
            "\n",
            "Average loss: 2.7484, Accuracy: (12%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 15/25 [03:48<02:28, 14.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 2.7384, Accuracy: (11%)\n",
            "\n",
            "\n",
            "Average loss: 2.6609, Accuracy: (12%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 16/25 [04:03<02:13, 14.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 2.6572, Accuracy: (12%)\n",
            "\n",
            "\n",
            "Average loss: 2.5785, Accuracy: (13%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 17/25 [04:18<01:59, 14.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 2.5819, Accuracy: (14%)\n",
            "\n",
            "\n",
            "Average loss: 2.4278, Accuracy: (20%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 18/25 [04:33<01:45, 15.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 2.4189, Accuracy: (20%)\n",
            "\n",
            "\n",
            "Average loss: 2.0598, Accuracy: (31%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 19/25 [04:48<01:29, 14.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 2.0250, Accuracy: (32%)\n",
            "\n",
            "\n",
            "Average loss: 1.5163, Accuracy: (49%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 20/25 [05:04<01:16, 15.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 1.4655, Accuracy: (50%)\n",
            "\n",
            "\n",
            "Average loss: 0.8762, Accuracy: (72%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 21/25 [05:19<01:00, 15.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 0.8204, Accuracy: (73%)\n",
            "\n",
            "\n",
            "Average loss: 0.4565, Accuracy: (87%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 22/25 [05:33<00:44, 14.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 0.3782, Accuracy: (88%)\n",
            "\n",
            "\n",
            "Average loss: 0.2822, Accuracy: (94%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 23/25 [05:48<00:29, 14.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 0.1611, Accuracy: (95%)\n",
            "\n",
            "\n",
            "Average loss: 0.2504, Accuracy: (96%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 24/25 [06:03<00:15, 15.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 0.0727, Accuracy: (98%)\n",
            "\n",
            "\n",
            "Average loss: 0.2972, Accuracy: (97%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25/25 [06:18<00:00, 15.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average loss: 0.0474, Accuracy: (99%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAHHCAYAAABZbpmkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACD70lEQVR4nO3dd1iV9f/H8ed9zmFPEVmKgrj33nuWI/foa6ktG1qWlWVppWWalZW2h6MiV6k/S9PMHLkXuHACigsU2Xuc+/fHwZMIKChwH+D9uK5zyfmc+9zndW6B8+a+P0NRVVVFCCGEEKKc0mkdQAghhBCiJEmxI4QQQohyTYodIYQQQpRrUuwIIYQQolyTYkcIIYQQ5ZoUO0IIIYQo16TYEUIIIUS5JsWOEEIIIco1KXaEEEIIUa5JsSNEKejWrRvdunXTOka5dv78eRRFYcmSJcW6Xz8/P8aPH1+s+xRClC4pdoTIsWTJEhRFwdbWlsuXL+d5vFu3bjRq1EiDZPfufjLv3r2bd955h7i4uOINZYEs/b1++eWXKIpC27ZttY4iRJkkxY4Qt0lPT2fu3LnFus+//vqLv/76q1j3WdJ2797NzJkzLbYAKE53eq+nT5/mu+++K/1QtwgMDMTPz4/9+/dz7tw5TbMIURZJsSPEbZo1a8Z3333HlStXim2f1tbWWFtbF9v+yrKUlBStIxSJjY0NVlZWmr1+eHg4u3fvZv78+VSpUoXAwEDNstxNcnKy1hGEyJcUO0Lc5o033iA7O7tQZ3cWL15Mjx498PDwwMbGhgYNGvDVV1/l2e7WPjtRUVEYDAZmzpyZZ7vTp0+jKAqff/65uS0uLo4XX3wRX19fbGxsqFWrFh988AFGo/Ge3p+iKEyaNIm1a9fSqFEjbGxsaNiwIRs3bjRv88477/Dqq68C4O/vj6IoKIrC+fPnzdv8/PPPtGzZEjs7O9zc3Bg9ejQXL17M874bNWrEoUOH6NKlC/b29rzxxhuAqS/MgAED+Ouvv2jWrBm2trY0aNCA1atX58kcFhbGiBEjcHNzw97ennbt2rF+/fq7vtejR48yfvx4atasia2tLV5eXjz++OPcuHGj0O81vz47hcmzbds2FEVh5cqVzJ49m2rVqmFra0vPnj2LdHYmMDCQSpUq0b9/f4YPH15gsRMXF8dLL72En58fNjY2VKtWjbFjxxIdHW3eJi0tjXfeeYc6depga2uLt7c3Q4cOJTQ0NFfmbdu25dp3fv2hxo8fj6OjI6GhofTr1w8nJyfGjBkDwL///suIESOoXr06NjY2+Pr68tJLL5Gampon96lTpxg5ciRVqlTBzs6OunXr8uabbwKwdetWFEVhzZo1eZ73yy+/oCgKe/bsKfSxFBWXQesAQlgaf39/xo4dy3fffcfrr7+Oj49Pgdt+9dVXNGzYkIceegiDwcDvv//Oc889h9FoZOLEifk+x9PTk65du7Jy5UrefvvtXI+tWLECvV7PiBEjANNZkK5du3L58mWefvppqlevzu7du5k2bRpXr17l008/vaf3uHPnTlavXs1zzz2Hk5MTCxYsYNiwYURERFC5cmWGDh3KmTNnWLZsGZ988gnu7u4AVKlSBYDZs2czY8YMRo4cyZNPPsn169dZuHAhXbp0ISgoCFdXV/Nr3bhxgwcffJDRo0fzyCOP4OnpaX7s7NmzjBo1imeeeYZx48axePFiRowYwcaNG+nduzdgKg47dOhASkoKL7zwApUrV2bp0qU89NBD/PrrrwwZMqTA97l582bCwsJ47LHH8PLy4sSJE3z77becOHGCvXv3oijKXd/r7YqaZ+7cueh0Ol555RXi4+OZN28eY8aMYd++fYX6vwoMDGTo0KFYW1vz8MMP89VXX3HgwAFat25t3iYpKYnOnTtz8uRJHn/8cVq0aEF0dDTr1q3j0qVLuLu7k52dzYABA9iyZQujR49m8uTJJCYmsnnzZo4fP05AQECh8twqKyuLvn370qlTJz766CPs7e0BWLVqFSkpKTz77LNUrlyZ/fv3s3DhQi5dusSqVavMzz969CidO3fGysqKCRMm4OfnR2hoKL///juzZ8+mW7du+Pr6EhgYmOe4BgYGEhAQQPv27YucW1RAqhBCVVVVXbx4sQqoBw4cUENDQ1WDwaC+8MIL5se7du2qNmzYMNdzUlJS8uynb9++as2aNXO1de3aVe3atav5/jfffKMC6rFjx3Jt16BBA7VHjx7m+++++67q4OCgnjlzJtd2r7/+uqrX69WIiIg7vqf8MgOqtbW1eu7cOXPbkSNHVEBduHChue3DDz9UATU8PDzX88+fP6/q9Xp19uzZudqPHTumGgyGXO1du3ZVAfXrr7/Ok61GjRoqoP7222/mtvj4eNXb21tt3ry5ue3FF19UAfXff/81tyUmJqr+/v6qn5+fmp2draqqqoaHh6uAunjxYvN2+f3/LFu2TAXUHTt23PW93sw5bty4IufZunWrCqj169dX09PTzdt+9tln+f7f5+fgwYMqoG7evFlVVVU1Go1qtWrV1MmTJ+fa7q233lIBdfXq1Xn2YTQaVVVV1UWLFqmAOn/+/AK3uZl569atuR7P79iOGzdOBdTXX389z/7yO+5z5sxRFUVRL1y4YG7r0qWL6uTklKvt1jyqqqrTpk1TbWxs1Li4OHPbtWvXVIPBoL799tt5XkeI/MhlLCHyUbNmTR599FG+/fZbrl69WuB2dnZ25q/j4+OJjo6ma9euhIWFER8fX+Dzhg4disFgYMWKFea248ePExISwqhRo8xtq1atonPnzlSqVIno6GjzrVevXmRnZ7Njx457en+9evXK9Zd8kyZNcHZ2Jiws7K7PXb16NUajkZEjR+bK5OXlRe3atdm6dWuu7W1sbHjsscfy3ZePj0+uv9idnZ0ZO3YsQUFBREZGArBhwwbatGlDp06dzNs5OjoyYcIEzp8/T0hISIFZb/3/SUtLIzo6mnbt2gFw+PDhu77X/BQ1z2OPPZarv1bnzp0BCnWsAwMD8fT0pHv37oDpEuSoUaNYvnw52dnZ5u1+++03mjZtmu9ZLkVRzNu4u7vz/PPPF7jNvXj22WfztN163JOTk4mOjqZDhw6oqkpQUBAA169fZ8eOHTz++ONUr169wDxjx44lPT2dX3/91dy2YsUKsrKyeOSRR+45t6hYpNgRogDTp08nKyvrjn13du3aRa9evXBwcMDV1ZUqVaqY+6Tcqdhxd3enZ8+erFy50ty2YsUKDAYDQ4cONbedPXuWjRs3UqVKlVy3Xr16AXDt2rV7em+3f7gAVKpUidjY2Ls+9+zZs6iqSu3atfPkOnnyZJ5MVatWLbBzdq1atfJ80NapUwfA3GfmwoUL1K1bN89z69evb368IDExMUyePBlPT0/s7OyoUqUK/v7+wJ3/f+6kqHluP9aVKlUCuOuxzs7OZvny5XTv3p3w8HDOnTvHuXPnaNu2LVFRUWzZssW8bWho6F2nGAgNDaVu3boYDMXXe8FgMFCtWrU87REREYwfPx43NzccHR2pUqUKXbt2Bf477jeLvbvlrlevHq1bt87VVykwMJB27dpRq1at4noropyTPjtCFKBmzZo88sgjfPvtt7z++ut5Hg8NDaVnz57Uq1eP+fPn4+vri7W1NRs2bOCTTz65awfi0aNH89hjjxEcHEyzZs1YuXIlPXv2NPcZATAajfTu3ZupU6fmu4+bhUFR6fX6fNtVVb3rc41GI4qi8Oeff+a7H0dHx1z3b/0rv7SNHDmS3bt38+qrr9KsWTMcHR0xGo088MAD99zBu6ju9Vj/888/XL16leXLl7N8+fI8jwcGBtKnT59iyXhTQWd4bj2LdCsbGxt0Ol2ebXv37k1MTAyvvfYa9erVw8HBgcuXLzN+/Ph7Ou5jx45l8uTJXLp0ifT0dPbu3ZurE78QdyPFjhB3MH36dH7++Wc++OCDPI/9/vvvpKens27dulx/vd9+GacggwcP5umnnzZfyjpz5gzTpk3LtU1AQABJSUnmMzmlqaAPvoCAAFRVxd/f/56LrZvOnTuHqqq5XuvMmTOAaRQUQI0aNTh9+nSe5546dcr8eH5iY2PZsmULM2fO5K233jK3nz17Ns+2RbmMc695iiowMBAPDw+++OKLPI+tXr2aNWvW8PXXX2NnZ0dAQADHjx+/4/4CAgLYt28fmZmZBQ6lv3nW6fb5hu509ux2x44d48yZMyxdupSxY8ea2zdv3pxru5o1awLcNTeY/jCYMmUKy5YtIzU1FSsrq1yXe4W4G7mMJcQdBAQE8Mgjj/DNN9+Y+5DcdPMv9lv/Qo+Pj2fx4sWF2rerqyt9+/Zl5cqVLF++HGtrawYPHpxrm5EjR7Jnzx42bdqU5/lxcXFkZWUV8R0VnoODg/l1bjV06FD0ej0zZ87Mc3ZCVdVcw7rv5sqVK7mGFSckJPDjjz/SrFkzvLy8AOjXrx/79+/PNcQ4OTmZb7/9Fj8/Pxo0aJDvvvP7/wHyHcFW0HvNz73mKYrU1FRWr17NgAEDGD58eJ7bpEmTSExMZN26dQAMGzaMI0eO5DtE++b7HzZsGNHR0fmeEbm5TY0aNdDr9Xn6gn355ZeFzp7fcVdVlc8++yzXdlWqVKFLly4sWrSIiIiIfPPc5O7uzoMPPsjPP/9MYGAgDzzwQK4zoELcjZzZEeIu3nzzTX766SdOnz5Nw4YNze19+vTB2tqagQMH8vTTT5OUlMR3332Hh4fHHTs132rUqFE88sgjfPnll/Tt2zfXkG2AV199lXXr1jFgwADGjx9Py5YtSU5O5tixY/z666+cP3++xH7pt2zZEjC9/9GjR2NlZcXAgQMJCAjgvffeY9q0aZw/f57Bgwfj5OREeHg4a9asYcKECbzyyiuFeo06derwxBNPcODAATw9PVm0aBFRUVG5CsbXX3+dZcuW8eCDD/LCCy/g5ubG0qVLCQ8P57fffstzGeUmZ2dnunTpwrx588jMzKRq1ar89ddfhIeHF/q93iyCbnWveYpi3bp1JCYm8tBDD+X7eLt27cwTDI4aNYpXX32VX3/9lREjRvD444/TsmVLYmJiWLduHV9//TVNmzZl7Nix/Pjjj0yZMoX9+/fTuXNnkpOT+fvvv3nuuecYNGgQLi4ujBgxgoULF6IoCgEBAfzxxx9F6htWr149AgICeOWVV7h8+TLOzs789ttv+fZRWrBgAZ06daJFixZMmDABf39/zp8/z/r16wkODs617dixYxk+fDgA7777buEPphAgQ8+FuOnWoee3uznM9vZh3OvWrVObNGmi2traqn5+fuoHH3xgHuJ76zDm24ee35SQkKDa2dmpgPrzzz/nmysxMVGdNm2aWqtWLdXa2lp1d3dXO3TooH700UdqRkbGHd9TQUPPJ06cmGfb24dYq6pp6HvVqlVVnU6X5z399ttvaqdOnVQHBwfVwcFBrVevnjpx4kT19OnTd3z9W1+vf//+6qZNm9QmTZqoNjY2ar169dRVq1bl2TY0NFQdPny46urqqtra2qpt2rRR//jjj1zb5Dc8+tKlS+qQIUNUV1dX1cXFRR0xYoR65coVFcgzbLmg95rfcSlMnpvDuG9/P/nlvN3AgQNVW1tbNTk5ucBtxo8fr1pZWanR0dGqqqrqjRs31EmTJqlVq1ZVra2t1WrVqqnjxo0zP66qpiHhb775purv769aWVmpXl5e6vDhw9XQ0FDzNtevX1eHDRum2tvbq5UqVVKffvpp9fjx4/kOPXdwcMg3W0hIiNqrVy/V0dFRdXd3V5966inz9Aa3v+/jx4+b/49sbW3VunXrqjNmzMizz/T0dLVSpUqqi4uLmpqaWuBxESI/iqoWokeiEEIUMz8/Pxo1asQff/yhdRRRBmRlZeHj48PAgQP54YcftI4jyhjpsyOEEMLirV27luvXr+fq9CxEYUmfHSGEEBZr3759HD16lHfffZfmzZub5+sRoijkzI4QQgiL9dVXX/Hss8/i4eHBjz/+qHUcUUZJnx0hhBBClGtyZkcIIYQQ5ZoUO0IIIYQo16SDMqa1fq5cuYKTk9N9rf4rhBBCiNKjqiqJiYn4+PjccUJPKXYwTVnv6+urdQwhhBBC3IOLFy9SrVq1Ah+XYgdwcnICTAfL2dlZ4zRCCCGEKIyEhAR8fX3Nn+MFkWKH/1Y8dnZ2lmJHCCGEKGPu1gVFOigLIYQQolyTYkcIIYQQ5ZoUO0IIIYQo16TPjhDFyGg0kpGRoXUMISyelZUVer1e6xiigpBiR4hikpGRQXh4OEajUesoQpQJrq6ueHl5yfxmosRJsSNEMVBVlatXr6LX6/H19b3j5FZCVHSqqpKSksK1a9cA8Pb21jiRKO+k2BGiGGRlZZGSkoKPjw/29vZaxxHC4tnZ2QFw7do1PDw85JKWKFGa/vm5Y8cOBg4ciI+PD4qisHbt2lyPq6rKW2+9hbe3N3Z2dvTq1YuzZ8/m2iYmJoYxY8bg7OyMq6srTzzxBElJSaX4LoSA7OxsAKytrTVOIkTZcfMPg8zMTI2TiPJO02InOTmZpk2b8sUXX+T7+Lx581iwYAFff/01+/btw8HBgb59+5KWlmbeZsyYMZw4cYLNmzfzxx9/sGPHDiZMmFBab0GIXKTvgRCFJz8vorRoehnrwQcf5MEHH8z3MVVV+fTTT5k+fTqDBg0C4Mcff8TT05O1a9cyevRoTp48ycaNGzlw4ACtWrUCYOHChfTr14+PPvoIHx+fUnsvQgghhLBMFtuLMjw8nMjISHr16mVuc3FxoW3btuzZsweAPXv24Orqai50AHr16oVOp2Pfvn0F7js9PZ2EhIRcNyFE8fDz8+PTTz/VOka5s2XLFurXr2++ZFqc3nnnHZo1a1as+2zXrh2//fZbse5TiHtlscVOZGQkAJ6enrnaPT09zY9FRkbi4eGR63GDwYCbm5t5m/zMmTMHFxcX801WPBcVkaIod7y9884797TfAwcOFNul5GXLlqHX65k4cWKx7K8smzp1KtOnTzd35F2yZAmKovDAAw/k2i4uLg5FUdi2bVuh9/3KK6+wZcuW4ozL9OnTef3112UqBmERLLbYKUnTpk0jPj7efLt48WKJvE7EjRSiEtLIyJIfdmF5rl69ar59+umnODs752p75ZVXzNuqqkpWVlah9lulSpViG5H2ww8/MHXqVJYtW5arr54WtJwscufOnYSGhjJs2LBc7QaDgb///putW7fe1/4dHR2pXLnyfe3jdg8++CCJiYn8+eefxbpfIe6FxRY7Xl5eAERFReVqj4qKMj/m5eVlnqfhpqysLGJiYszb5MfGxsa8wnlJrnQ+4aeDtH1/C3Wm/0njdzbR9cOtDPlyF08uPcDUX48w58+TfLsjlF8PXWLrqWsEX4zjYkwKyelZqKpaIpmEuMnLy8t8c3FxQVEU8/1Tp07h5OTEn3/+ScuWLbGxsTF/4A4aNAhPT08cHR1p3bo1f//9d6793n4ZS1EUvv/+e4YMGYK9vT21a9dm3bp1d80XHh7O7t27ef3116lTpw6rV6/Os82iRYto2LAhNjY2eHt7M2nSJPNjcXFxPP3003h6emJra0ujRo34448/gPwv23z66af4+fmZ748fP57Bgwcze/ZsfHx8qFu3LgA//fQTrVq1wsnJCS8vL/73v//l+T104sQJBgwYgLOzM05OTnTu3JnQ0FB27NiBlZVVnjPPL774Ip07dy7wWCxfvpzevXtja2ubq93BwYHHH3+c119/veADCbz22mvUqVMHe3t7atasyYwZM3KNgLr1ePz111/Y2toSFxeXax+TJ0+mR48e5vs7d+6kc+fO2NnZ4evrywsvvEBycrL5cb1eT79+/Vi+fPkdswlRGix2nh1/f3+8vLzYsmWL+YcwISGBffv28eyzzwLQvn174uLiOHToEC1btgTgn3/+wWg00rZtW62i56LXKWQbVRLTskhMy+LCjZRCPc/GoMPNwTrXrZ6XM0NbVMXT2fbuOxCaUlWV1Mzi71tRGHZW+mIb5fL666/z0UcfUbNmTSpVqsTFixfp168fs2fPxsbGhh9//JGBAwdy+vRpqlevXuB+Zs6cybx58/jwww9ZuHAhY8aM4cKFC7i5uRX4nMWLF9O/f39cXFx45JFH+OGHH/jf//5nfvyrr75iypQpzJ07lwcffJD4+Hh27doFmJbtuHlm4eeffyYgIICQkJAiz+WyZcsWnJ2d2bx5s7ktMzOTd999l7p163Lt2jWmTJnC+PHj2bBhAwCXL1+mS5cudOvWjX/++QdnZ2d27dpFVlYWXbp0oWbNmvz000+8+uqr5v0FBgYyb968AnP8+++/ud77rd555x1q1arFr7/+yvDhw/PdxsnJiSVLluDj48OxY8d46qmncHJyYurUqXm27dmzJ66urvz222888cQTgGlqhRUrVjB79mwAQkNDeeCBB3jvvfdYtGgR169fZ9KkSUyaNInFixeb99WmTRvmzp17p0MsyhlVVYlKSOfstUTORiVx9loS564lcu5aEjumdsfJ1kqTXJoWO0lJSZw7d858Pzw8nODgYNzc3KhevTovvvgi7733HrVr18bf358ZM2bg4+PD4MGDAahfvz4PPPAATz31FF9//TWZmZlMmjSJ0aNHW8RIrI0vdsFoVElIy+RGcgYxt91uJGUQm5KR81g6MUmmr9OzjKRnGbkan8bV+P9O3f8fV/jor9N0r1uFUa2r071uFQx6iz05V6GlZmbT4K1Nmrx2yKy+2FsXz4/2rFmz6N27t/m+m5sbTZs2Nd9/9913WbNmDevWrct1VuV248eP5+GHHwbg/fffZ8GCBezfvz9Pf5ObjEYjS5YsYeHChQCMHj2al19+mfDwcPz9/QF47733ePnll5k8ebL5ea1btwbg77//Zv/+/Zw8eZI6deoAULNmzSK/fwcHB77//vtc8yc9/vjj5q9r1qzJggULaN26NUlJSTg6OvLFF1/g4uLC8uXLsbIy/WK/mQHgiSeeYPHixeZi5/fffyctLY2RI0cWmOPChQsF/k7z8fFh8uTJvPnmm+bfjbebPn26+Ws/Pz9eeeUVli9fnm+xo9frGT16NL/88ou52NmyZQtxcXHmy2hz5sxhzJgxvPjiiwDUrl2bBQsW0LVrV7766ivzGSgfHx8uXryI0WiUWcXLGVVVuRKfxtkoUyFjKmwSOXsticS0/C95h15Pppmva+kGzaFpsXPw4EG6d+9uvj9lyhQAxo0bx5IlS5g6dSrJyclMmDCBuLg4OnXqxMaNG3Odyg0MDGTSpEn07NkTnU7HsGHDWLBgQam/l4LodAqu9ta42lsTUKVwz0nJyMpdCCVlcD0pnS0nozhwPpa/T17j75PX8HCyYXjLaoxs5Yufu0PJvhFRId060hFMf6C88847rF+/nqtXr5KVlUVqaioRERF33E+TJk3MXzs4OODs7Jzn0s+tNm/eTHJyMv369QPA3d2d3r17s2jRIt59912uXbvGlStX6NmzZ77PDw4Oplq1armKjHvRuHHjPBNFHjp0iHfeeYcjR44QGxtr7oAbERFBgwYNCA4OpnPnzuZC53bjx49n+vTp7N27l3bt2rFkyRJGjhyJg0PBP8Opqal5LmHd6rXXXuObb75h0aJF+RZNK1asYMGCBYSGhpKUlERWVtYdL9+PGTOGdu3aceXKFXx8fAgMDKR///64uroCcOTIEY4ePUpgYKD5OaqqYjQaCQ8Pp379+oBplmSj0Uh6erp5xmRRthiNKpfjUjkTZSpkzkb9d6YmOSP/s9d6nUKNyvbU9nCkjqcTtTwcqe3hRICHdp9TmhY73bp1u2PfFEVRmDVrFrNmzSpwGzc3N3755ZeSiKcZe2sD9m4GfN1yd/J8pmsA564lsergRX49dIlriel8uS2UL7eF0q6mG6NbV+eBRl7YWsm061qzs9ITMquvZq9dXG7/AH7llVfYvHkzH330EbVq1cLOzo7hw4fftfPu7R/8iqLccZTODz/8QExMTK4PSKPRyNGjR5k5c+ZdPzjv9rhOp8vzuye/WXxvf//Jycn07duXvn37EhgYSJUqVYiIiKBv377mY3C31/bw8GDgwIEsXrwYf39//vzzz7uOnHJ3dyc2NrbAx11dXZk2bRozZ85kwIABuR7bs2cPY8aMYebMmfTt29d81unjjz8ucH+tW7cmICCA5cuX8+yzz7JmzRqWLFlifjwpKYmnn36aF154Ic9zb72cGRMTg4ODgxQ6ZUx6VjY/7r7A/x25zLlrSaRl5v+zaqVX8Hd3oLZHTkHjaSpq/NztsTFY1ueQxfbZEfmr5eHItH71eblPXf45FcXyAxfZfuY6e8Ni2BsWg/P/GRjSvCqjWlengU/JdLwWd6coSrFdSrIku3btYvz48QwZMgQwfeidP3++WF/jxo0b/N///R/Lly+nYcOG5vbs7Gw6derEX3/9xQMPPICfnx9btmzJdXb4piZNmnDp0iXOnDmT79mdKlWqEBkZiaqq5v5NwcHBd8126tQpbty4wdy5c81TVhw8eDDPay9dupTMzMwCz+48+eSTPPzww1SrVo2AgAA6dux4x9dt3rw5ISEhd9zm+eefZ8GCBXz22We52nfv3k2NGjV48803zW0XLly4477AdHYnMDCQatWqodPp6N+/v/mxFi1aEBISQq1ate64j+PHj9O8efO7vpawDKqq8sfRq3yw8RSXYlPN7dYGHQFVHKntkXPzdKSWhxM1KttjVUa6UpS/38YVhLVBxwONvHmgkTdX4lJZdfASKw9e5HJcKkv3XGDpngs0qebCqNa+PNTUR7NOYaJ8qV27NqtXr2bgwIEoisKMGTOKfR6Vn376icqVKzNy5Mg8Ha379evHDz/8wAMPPMA777zDM888g4eHh7kz8q5du3j++efp2rUrXbp0YdiwYcyfP59atWpx6tQp87w03bp14/r168ybN4/hw4ezceNG/vzzz7uOzKxevTrW1tYsXLiQZ555huPHj/Puu+/m2mbSpEksXLiQ0aNHM23aNFxcXNi7dy9t2rQxj+jq27cvzs7OvPfee3c8c31T3759Wbp06R23sbW1ZebMmXnmJKpduzYREREsX76c1q1bs379etasWXPX1xwzZgzvvPMOs2fPZvjw4djY2Jgfe+2112jXrh2TJk3iySefxMHBgZCQEDZv3sznn39u3u7ff/+lT58+d30tob1DF2J5b30IQRFxAHg62zC5Zx3aB1Smups9el3ZXtqjbJRk4o58XO2Y3Ks2/07tzk9PtKF/E2+s9ApHL8Xz5prjtJm9hVdWHeHg+RgZ0i7uy/z586lUqRIdOnRg4MCB9O3blxYtWhTrayxatIghQ4bkO6Js2LBhrFu3jujoaMaNG8enn37Kl19+ScOGDRkwYECuhYJ/++03WrduzcMPP0yDBg2YOnWqefbh+vXr8+WXX/LFF1/QtGlT9u/fn2teoYJUqVKFJUuWsGrVKho0aMDcuXP56KOPcm1TuXJl/vnnH5KSkujatSstW7bku+++y3WWR6fTMX78eLKzsxk7duxdX/fmGoCnT5++43bjxo3L0xH7oYce4qWXXmLSpEk0a9aM3bt3M2PGjLu+Zq1atWjTpg1Hjx5lzJgxuR5r0qQJ27dv58yZM3Tu3JnmzZvz1ltv5epEffnyZXbv3s1jjz1219cS2om4kcLEwMMM+2o3QRFx2FvrmdK7Dltf6cb/2lbH392hzBc6AIoqn34kJCTg4uJCfHx88c65E7YdstLBYA16a9Db5HxtA3orMNjc9rU1FNOQ4RtJ6awJusyKAxc5e+2/VeBrVnFgdGtfRrWujoudnO0pLmlpaeaRQnfqSCrETU888QTXr18v1JxDAK+++ioJCQl88803JZyseLz22mvExsby7bffFriN/NxoJz4lk8+3nmXp7gtkZBvRKTCylS9TetfBowxNb1LYz2+5jFWSNrwC0WeK9hzdLYWPIacQ0tuYvnbzh8YjoHZfsLrzN2NlRxue7FyTJzr5czgijpUHLvL70SuEXU/m/Q2nWHnwEmue6yCXt4QoZfHx8Rw7doxffvml0IUOwJtvvsmXX35ZZoZxe3h4mEfYCsuRkWXk570XWPDPWeJSTJ3yO9d2541+9anvXYx/7KsqpMVBwhXTLf4SNBtj+oNfA3JmhxI8s7NyLMRegOwM0y0rA7LTTWd7sjNNXxsLNwV/LjYu0HAQNBkF1TtAIX/xJaVn8ceRK8zffIZrien0aeDJ14+0RFcOTlFqTf5CFYXVrVs39u/fz9NPP80nn3yidRxNyc9N6VFVlU0novhg4ynCo00zXdfxdOSNfvXpVtfjLs/OszNIjf2vkEm4lLuoufl1ZnLu570QbPqjvRjJmR1LMPLHu29jNOYUQ+n/FUO3FkbZmabiKCsVwv+FY6sg4TIc/tF0c64GTUZA45Hg2eCOL+VoY2B0m+rU83Zm5Dd7+Cskis+3nuOFnrWL6Q0LIe6mKAt0ClEcjl6K4731J9kfHgOAu6M1U3rXZWSragVPTJueCBf2mAqZ+Mt5i5rMwq0GgJ0bOFcFl6qgardOpJzZoQTP7JQEoxEidsPRFXDi/yA9/r/HPBtDk5HQeDg433kG6ZUHLzL116MoCnw/thU963vecXtxZ/IXqhBFJz83JetyXCofbjzF2uArgGkZoqc61+SZbgE42hRwriM1FvZ9A3u/Ml2GuhP7yqbPGudqOf/6gMvNr6ua/rUq2TmWCvv5LcUOZazYuVVmGpzdBEdXwplNYLw5KZoC/l1Ml7nqDwTb/N/TW/93nB/3XMDJxsDaSR0JqOJYetnLGfmlLUTRyc9NyUhMy+SrbaH8sDOc9CzT2ZShLaryat+6eLsUUHwk34C9X8D+7yA9wdTmWh08GprOytxe1JRCIVMYUuwUQZktdm6VEgMha02FT8Se/9oNtlC3n6nwqdXT1OE5R0aWkTHf7+XA+VgCqjiwdmJH6bB8j+SXthBFJz83xctoVPllfwSfbD7DjWTTjN7taroxvX8DGlV1yf9JiVGwZyEcWPRfHxuPhtDlFWgwCHSWNRPy7aTYKYJyUezcKvaCqW/P0RW5R4PZuUGjoabCp1prUBSuJ6YzcOFOIhPS6N3Ak2+kw/I9kV/aQhSd/NwUr9nrQ/ju33AAaro7MK1ffXrV98h3ziriL8Ouz+DwUsjKWXDauyl0mWr6A7kMjPgDKXaKpNwVOzepKlw9Yjrbc2wVJN+y8GKdB2HUT6C3IvhiHCO/2UNGlpGXetVhci/psFxU8ktbiKKTn5vis+tcNGO+3wfAm/3qM76jX/5LOcRegJ2fQHCgaTAMmP747TIVavcutrneSkthP7/LRukm7o2igE8zeOB9mHISHlkNTUab5u058yesnwKqSjNfV94b3AiAT/4+w5aTUdrmFkIIUWjxKZm8suoIAP9rW52nutTMW+jcCIW1E2FhCzi02FTo1OgEY/8PntgMdfqUuUKnKKTYqSj0BlOfnaHfwIglgGIaur7TNM/HyFa+jG1fA4AXlwcTej2p4H0JIUrMjBkzmDBhQonsu1u3brz44ovFtr/o6Gg8PDy4dOlSse1TFN1b645zNT4Nv8r2vNmvfu4Hr52C356Ez1tB8M+mud1qdofxG+Cx9VCzW7kucm6SYqciqtcPHvzA9PWWmXDsVwCm929Aa79KJKZnMeHHgySmZd5hJ6KsUxTljrd33nnnvva9du3aQm//9NNPo9frWbVq1T2/ZnkQGRnJZ599lmuF8vHjx6MoCnPnzs217dq1a/Pvi3EHq1evzrNw6f1wd3dn7NixvP3228W2T1E0645c4f+Cr6DXKXwyqhkON4eURx4zTWz7ZTtTNwbVaJp9/4m/Yexa8Ouoae7SJsVORdX2aWj3nOnrtc/ChT1YG3R8OaYlXs62hF5PZsrKIxiNFb5LV7l19epV8+3TTz/F2dk5V1thFsYsDikpKSxfvpypU6eyaNGiUnnNO8nIyNDstb///ns6dOhAjRo1crXb2trywQcfEBsbe1/7d3Nzw8nJ6b72cbvHHnuMwMBAYmJiinW/4u6uxqcyfc0xACZ2r0Xz6pXg8mFY9jB83QlC/g9Qod4AmLAdxqwE39bahtaIFDsVWZ/3TD8E2Rmw/GG4EUoVJxu+frQl1gYdm0OiWPjPOa1TihLi5eVlvrm4uKAoSq625cuXU79+fWxtbalXrx5ffvml+bkZGRlMmjQJb29vbG1tqVGjBnPmzAHAz88PwLxy+c37Bbm5gvjrr7/Ojh07uHjxYq7H09PTee211/D19cXGxoZatWrxww8/mB8/ceIEAwYMwNnZGScnJzp37kxoaCiQ/2WbwYMHM378ePN9Pz8/3n33XcaOHYuzs7P5EtJrr71GnTp1sLe3p2bNmsyYMYPMzNxnO3///Xdat26Nra0t7u7uDBkyBIBZs2bRqFGjPO+1WbNmd1xxfPny5QwcODBPe69evfDy8jIf4/zcuHGDhx9+mKpVq2Jvb0/jxo1ZtmxZrm1uPR5vvPEGbdu2zbOfpk2bMmvWLPP977//vsDvA4CGDRvi4+PDmjVrCswmip/RqPLKqiMkpGXRtJoLz/eoBQe+h++6w+kNgAINh8Kzu2F0oKn/ZgUmxU5FptPD0O/Ap4Vp1syfh0FydJ4Oy3+HSIflIlNVyEjW5lYMAywDAwN56623mD17NidPnuT9999nxowZLF26FIAFCxawbt06Vq5cyenTpwkMDDQXNQcOHABg8eLFXL161Xy/ID/88AOPPPIILi4uPPjggyxZsiTX42PHjmXZsmUsWLCAkydP8s033+DoaJoA8/Lly3Tp0gUbGxv++ecfDh06xOOPP05WVtHWnPvoo49o2rQpQUFB5mLEycmJJUuWEBISwmeffcZ3332Xay2r9evXM2TIEPr160dQUBBbtmyhTZs2ADz++OOcPHky13sPCgri6NGjPPbYY/lmiImJISQkhFatWuV5TK/X8/7777Nw4cIC+8ekpaXRsmVL1q9fz/Hjx5kwYQKPPvoo+/fvz3f7MWPGsH//fnNhCKbC8ejRo/zvf/8D7v59cFObNm34999/830dUTKW7D7PrnM3sLXSMX9UM6yuh8DGaaYHGw6FifthxGLwbKhtUAsha2NVdNb28L8V8H1PiA03nf4ct46RrXw5fjmeH/dc4KUVwTLDclFlpsD7d16yo8S8cQWsHe5rF2+//TYff/wxQ4cOBcDf35+QkBC++eYbxo0bR0REBLVr16ZTp04oipLrskuVKlUAcHV1xcvL646vc/bsWfbu3cvq1asBeOSRR5gyZQrTp09HURTOnDnDypUr2bx5M7169QKgZs2a5ud/8cUXuLi4sHz5cqysTBNi1qlTp8jvt0ePHrz88su52qZPn27+2s/Pj1deecV8uQ1g9uzZjB49mpkzZ5q3a9q0KQDVqlWjb9++LF68mNatTZcNFi9eTNeuXXPlv1VERASqquLjk//3zZAhQ2jWrBlvv/12rjNbN1WtWjXXpcfnn3+eTZs2sXLlSnMRdquGDRvStGlTfvnlF3OBFxgYSNu2balVqxZw9++Dm3x8fAgKCso3tyh+Z6MSmbvxFABv9m9AgKsevn3CdJa+zgMwfFGF6HRcFHJmR4CjB4z5FWxd4NJ+WPMMGI3SYbmCSk5OJjQ0lCeeeAJHR0fz7b333jOfBRg/fjzBwcHUrVuXF154gb/++uueXmvRokX07dsXd3d3APr160d8fDz//PMPAMHBwej1erp27Zrv84ODg+ncubO50LlX+Z1NWbFiBR07dsTLywtHR0emT59ORERErtfu2bNngft86qmnWLZsGWlpaWRkZPDLL7/w+OOPF7h9amoqwB3nm/nggw9YunQpJ0+ezPNYdnY27777Lo0bN8bNzQ1HR0c2bdqUK/PtxowZwy+//AKYVsVetmwZY8aMAQr3fXCTnZ0dKSmFXBhS3JeMLCOTlweTkWWkW90qPNK2Ovw1A66fAgcPeOhzKXTyIWd2hEmVujAqEH4aYlp2YksNrHvP4ssxLRm4cKe5w7LMsFxIVvamMyxavfZ9SEoyTTvw3Xff5enTodebpo5v0aIF4eHh/Pnnn/z999+MHDmSXr168euvvxb6dbKzs1m6dCmRkZEYDIZc7YsWLaJnz57Y2d157Z27Pa7T6bh93tTb+90AODjkPhO2Z88exowZw8yZM+nbt6/57NHHH39c6NceOHAgNjY2rFmzBmtrazIzMxk+fHiB298s+GJjY81nx27XpUsX+vbty7Rp03L1OwL48MMP+eyzz/j0009p3LgxDg4OvPjii3fscP3www/z2muvcfjwYVJTU7l48SKjRo0CCvd9cFNMTEyBmUXx+vTvM4RcTaCSvRXzhjVBObMJDnxnenDIV+Ao/w/5kWJH/Me/Mwz6AtZMME0j7lqDKq2f4OtHWzLymz3mDssyw3IhKMp9X0rSiqenJz4+PoSFhZn/ys+Ps7Mzo0aNYtSoUQwfPpwHHniAmJgY3NzcsLKyIjs7+46vs2HDBhITEwkKCsr14Xn8+HEee+wx4uLiaNy4MUajke3bt5svY92qSZMmLF26lMzMzHzP7lSpUoWrV6+a72dnZ3P8+HG6d+9+x2y7d++mRo0auYaAX7hwIc9rb9mypcA+OAaDgXHjxrF48WKsra0ZPXr0HQukgIAAnJ2dCQkJueOluLlz59KsWTPq1q2bq33Xrl0MGjSIRx55BACj0ciZM2do0KBBgfuqVq0aXbt2JTAwkNTUVHr37o2HhwdQ+O8DMP2fdevW7Y7biPt34HwMX283nVWbM7QxHko8/F/OqNp2z0GtvD8jwkSKHZFb01EQdwG2zoYNr4CLL83q9OG9wY2Y+utRPvn7DA19nOnVwFPrpKIEzZw5kxdeeAEXFxceeOAB0tPTOXjwILGxsUyZMoX58+fj7e1N8+bN0el0rFq1Ci8vL1xdXQFTH5ctW7bQsWNHbGxsqFSpUp7X+OGHH+jfv7+5n8tNDRo04KWXXiIwMJCJEycybtw4Hn/8cRYsWEDTpk25cOEC165dY+TIkUyaNImFCxcyevRopk2bhouLC3v37qVNmzbUrVuXHj16MGXKFNavX09AQADz588nLi7uru+/du3aREREsHz5clq3bs369evzjDZ6++236dmzJwEBAYwePZqsrCw2bNjAa6+9Zt7mySefpH590yRvu3btuuNr6nQ6evXqxc6dOxk8eHCB2zVu3JgxY8awYMGCPJl//fVXdu/eTaVKlZg/fz5RUVF3LHbAdCnr7bffJiMjI1cHbLj79wGYpg44dOgQ77///h1fR9yfxLRMXloRjFGF4S2r8UADTwgcDik3wLMR9JS5ju5IFWp8fLwKqPHx8VpHsQxGo6queVZV33ZW1fe8VfVKsKqqqjpj7TG1xmt/qI3e2qieu5aocUjLkpqaqoaEhKipqalaR7knixcvVl1cXHK1BQYGqs2aNVOtra3VSpUqqV26dFFXr16tqqqqfvvtt2qzZs1UBwcH1dnZWe3Zs6d6+PBh83PXrVun1qpVSzUYDGqNGjXyvF5kZKRqMBjUlStX5pvn2WefVZs3b66qqunYvvTSS6q3t7dqbW2t1qpVS120aJF52yNHjqh9+vRR7e3tVScnJ7Vz585qaGioqqqqmpGRoT777LOqm5ub6uHhoc6ZM0cdNGiQOm7cOPPza9SooX7yySd5Mrz66qtq5cqVVUdHR3XUqFHqJ598kucY/fbbb+Zj5O7urg4dOjTPfjp37qw2bNgw3/d5uw0bNqhVq1ZVs7OzzW3jxo1TBw0alGu78PBw1draWr31V/iNGzfUQYMGqY6OjqqHh4c6ffp0dezYsbme27VrV3Xy5Mm59hUbG6va2Nio9vb2amJi3p/rO30fqKqq/vLLL2rdunUL9f5uV9Z/bkrTKyuD1Rqv/aF2nLtFTUjNUNXdX5h+R7/roapRJ7WOp5nCfn7LQqCU44VA70dWhumvhvDt4OQNT/5NhoMPY77fy4HzsQRUcWDtxI442d5fx9DyQhY0FPlRVZXatWvz3HPPmc+E3G37tm3b8tJLL/Hwww+XQsL7165dO1544QXzcPWikJ+bwtl4PJJnfj6EosCKCe1pY3cZvuthGn3V7yNo85TWETUjC4GK+2OwhpE/QpX6kHgVAkdinZUkMywLUUjXr1/n888/JzIyssB+PbdTFIVvv/22yPMEaSU6OpqhQ4eWmcKsLLqWmMYbObMkP90lgDbV7ExrXWVnQJ0HofWTGicsG6TYEQWzczVNL+7oCddOwKpxVLHXyQzLQhSCh4cHs2bN4ttvv823z1JBmjVrxqOPPlqCyYqPu7s7U6dOLfIaXaJwVFXltV+PEpOcQX1vZ6b0rgN/TTcNM3f0hEEyzLywpNgRd+Za3TTpoJU9hP4D66fQrJpLrhmWt52+pnFIISyPqqpcv379ni7vCAEQuC+CraevY23Q8dnoZliHbjItCQEw+CtwcNc2YBkixY64O5/mOTNy6uDwj7BzPiNb+fJwm+oALN51Xtt8QghRzoRdT2L2etPkka89UI869snwfxNND7abCLUKntBS5CXFjiicug/Cg/NMX2+ZBcd+5bGOfgDsDbtBasad51SpKKS/vxCFJz8v+cvMNvLSyiOkZmbTsVZlHmtfHdY+mzPMvDH0kmHmRSXFjii8Nk9B+0mmr9c+S+3Uo/i42JKeZWRv2A1ts2ns5qR4d5qtVgiR280lJu53uY/y5out5zhyMQ5nWwMfjWiKbv/Xpm4EBlsY9j0YbLSOWObIpIKiaHq/a5p08OTvKCvGMMz/CxYGw7bT1+hez0PrdJoxGAzY29tz/fp1rKys0Onk7wghCqKqKikpKVy7dg1XV9c8y09UZEERseaBH+8OboR3yln4+x3Tg31ng0c97cKVYVLsiKLR6WDIt5AwEC4f5NmLrxHIm2w9fZ13VLXCjspQFAVvb2/Cw8PzLCsghMifq6srXl5eWsewGCkZWUxZeYRso8pDTX0Y1KASfDvENMy8bj9o9YTWEcssKXZE0Vnbw8PL4fue2Mdd4GWrX3kz5nHCo5OpWcVR63Sasba2pnbt2nIpS4hCsLKykjM6t3l/w0nCo5PxdrHl3UGN4K/XIPq0aZj5QwtlmPl9kGJH3BvHKtD/YwgczoPWwbyZqbLt9PUKXeyAaX0jmQlWCFFUW09d4+e9EQB8NKIpLhGb4eAPpgeHfC3DzO+TdCwQ986vM1jZ45YdTQPlAltlvh0hhCiymOQMXv31KACPd/Sno2cWrMsZDNJ+EgT00DBd+SDFjrh3Vrbg3xWA7rpg9oXHkJJRNqa5F0IIS6CqKtNWHyU6KZ3aHo5M7Vsb1jxjGmbu1Rh6vqV1xHJBih1xf+r0AeAB6yNkZBnZE1qxh6ALIURR7Dp3g00norDSK3w6uhm2B7+BsK1gsINhP8gw82IixY64P7VNxU5D9QyVSGDb6esaBxJCiLJj/bErAIxo5UtD5QJsmWl6oO9sqFJXw2TlixQ74v64VAPPRuhQ6aI7ytbT12RWVCGEKIRso8pfJ6IA6F/P5b/VzOv2h1aPa5yufJFiR9y/2r0B6GUI5lJsKqHXkzUOJIQQlu/QhVhuJGfgbGug3blPcoaZe8kw8xIgxY64f7X7AtDdcAw92bIKuhBCFMKmE5EATK52Dv2hRabGIV+BQ2UNU5VPUuyI+1etNdi64mhMpLlyVvrtCCHEXaiqysbjkbiRwKPXPjQ1yjDzEiPFjrh/egPU6gVAD30w+8NjSE6XIehCCFGQE1cSuByXygjrXVhnxIJHAxlmXoKk2BHFo47pUlYfq6NkZBvZLUPQhRCiQDcvYY2wDzI1tBwvw8xLkBQ7ongE9AQUaqnn8eaG9NsRQog72HQikirEEpB2wtRQf6C2gco5KXZE8XCobOq7A3TXB7Pt9HUZgi6EEPkIu57Emagk+hkOoqCafnc6+2gdq1yTYkcUn5zZlHvqg7kcl8q5a0kaBxJCCMuzKWdunZEOOZew6j+kYZqKQYodUXxyhqB30p/AhgwZlSWEEPnYdMI0Cqt+xjFTQwMpdkqaFDui+Hg1BicfbNQ02ulOyiroQghxm8j4NIIvxtFHfwidmg1eTaCSn9axyj0pdkTxURTzbMrddMEcOB9DkgxBF0IIs79CTKOwzJewGgzSME3FIcWOKF45C4P2sQomM9vI7nPRGgcSQgjLsfF4JM4k0zQz2NQgxU6pkGJHFK+a3UBvTVU1igDlClul344QQgAQm5zBvvAYeuoOo1ezoEp9cK+tdawKQYodUbxsHKFGRwC664LZLqugCyEEAFtOXSPbqDLCfAlLOiaXFil2RPHLmU25lz6YK/FpnImSIehCCLHxeCQOpNIm67CpQYaclxopdkTxy+m300p3CkdSZDZlIUSFl5yexb9nr9NdF4xBzQC3muDZUOtYFYYUO6L4VQ4AtwAMZNNJd1zm2xFCVHjbz1wnPcvIMLtDpoYGg0wjWEWpkGJHlIycS1k9dEEcOB9DYlqmxoGEEEI7m05EYkMGHVWZNVkLUuyIkpFzKauX1RGyjdnsOieroAshKqaMLCP/nLxGV90RrI2p4FIdfJprHatCkWJHlIwaHcHaETc1jkbKeem3I4SosHaHRpOYnsVgm5xLWPUHyiWsUibFjigZBmvTnDuYLmXJKuhCiIpq04korMiiu5IzCkuGnJc6KXZEybnZb8cQTGRCGqejEjUOJIQQpSvbqLI5JJKOuuPYGZPA0QuqtdE6VoUjxY4oObVM62Q1VsKoTDxbT8moLCFExXI4IpbopAwesj5gaqg/AHTy0Vva5IiLkuPsDV5N0KHSTXdE+u0IISqcjccj0ZNNH/3NS1iyFpYWpNgRJSvnUlZ3fRAHL8SSIEPQhRAVhKqqbDoRSVvdSRyz48G+MlTvoHWsCsmii53s7GxmzJiBv78/dnZ2BAQE8O677+bq6KqqKm+99Rbe3t7Y2dnRq1cvzp49q2FqkUttU7HTTX8MxZjJrrOyCroQomI4cSWBS7GpDDDkXMKq1x/0Bm1DVVAWXex88MEHfPXVV3z++eecPHmSDz74gHnz5rFw4ULzNvPmzWPBggV8/fXX7Nu3DwcHB/r27UtaWpqGyYVZ1RZgXxlHUmipnJXZlIUQFcZfJyJRMNLf6uaQc7mEpRWLLnZ2797NoEGD6N+/P35+fgwfPpw+ffqwf/9+wHRW59NPP2X69OkMGjSIJk2a8OOPP3LlyhXWrl2rbXhhotNDrV6A6VLWtjOyCroQomLYdCKKlsoZXLJjwMYF/LtoHanCsuhip0OHDmzZsoUzZ84AcOTIEXbu3MmDDz4IQHh4OJGRkfTq1cv8HBcXF9q2bcuePXsK3G96ejoJCQm5bqIE3ZxNWR9MVEI6J6/KEHQhRPkWHp3M6ahE+htMf5xT90HT/GNCExZ98fD1118nISGBevXqodfryc7OZvbs2YwZMwaAyMhIADw9PXM9z9PT0/xYfubMmcPMmTNLLrjIrVZPUPTU4hLVlOtsPX2NBj7OWqcSQogSs+lEJKAy0PoQZCOjsDRm0Wd2Vq5cSWBgIL/88guHDx9m6dKlfPTRRyxduvS+9jtt2jTi4+PNt4sXLxZTYpEvu0rg2xaA7rogtku/HSFEObfxeCRNlVDcs6+DtSME9NA6UoVm0cXOq6++yuuvv87o0aNp3Lgxjz76KC+99BJz5swBwMvLC4CoqKhcz4uKijI/lh8bGxucnZ1z3UQJq2O6lNVDF8ShiFjiU2UIuhCifIqMTyP4YhwP6nNGYdXuA1a22oaq4Cy62ElJSUF320yTer0eo9EIgL+/P15eXmzZssX8eEJCAvv27aN9+/almlXcRc4Q9A76k1gZ09gpQ9CFEOXUXyGmS1iDbA6aGmQtLM1ZdJ+dgQMHMnv2bKpXr07Dhg0JCgpi/vz5PP744wAoisKLL77Ie++9R+3atfH392fGjBn4+PgwePBgbcOL3Dzqg3M1bBIu0V4XwrbTAfRv4q11KiGEKHabTkRSX4nAO/sqGGzNS+cI7Vh0sbNw4UJmzJjBc889x7Vr1/Dx8eHpp5/mrbfeMm8zdepUkpOTmTBhAnFxcXTq1ImNGzdiayunDC2KopguZR1cRA9dEAvOtMNoVNHpFK2TCSFEsYlLyWBvWAwv6HNGYdXqBTaO2oYSKKpMekJCQgIuLi7Ex8dL/52SdHojLBvFFdWdDumf8cfznWlU1UXrVEIIUWx+PXSJV1YdYbv9a9QwXoQh30LTUVrHKrcK+/lt0X12RDnj3wUMtvgo0dRRLrH9jIzKEkKUL5tORBKgXDYVOjorqPuA1pEEUuyI0mRtD36dAdOorK2nZBV0IUT5kZKRxY4z13lQl3MJK6A72MrZa0sgxY4oXTmzKXfXB3M4Ipb4FBmCLoQoH7afvk56lpGHrHNGYdWXUViWQoodUbpy5ttppTuDo5rEjrNyKUsIUT5sOhGJrxJFHTUcFL1plXNhEaTYEaWrkh+410WPkS66Y7IKuhCiXMjIMrLl1LX/LmH5dQJ7N21DCTMpdkTpq3PzUlYQ289cx2is8AMChRBl3J6wGySmZf13CUsmErQoUuyI0pczm3J33RFiklI5cUVWnRdClG0bj0fizQ0aqWcBBeoN1DqSuIUUO6L0VW8HNs64KYk0UcLYdlpGZQkhyq5so8rmkCgeuDmRYPX24OSpbSiRixQ7ovTprUxDMjFdytoqxY4Qogw7HBFLdFI6A6zkEpalkmJHaCPnUlYPXRDBF+OIS8nQOJAQQtybTccjqUIczTllaqgvl7AsjRQ7Qhu1TQvjNdadp7Iayw5ZBV0IUQapqsqmkEj66A+iQ4WqLcGlmtaxxG2k2BHacPQAnxaAaYLBbTKbshCiDAq5msDFmFT6GQ6YGmQiQYskxY7QTp2bl7KCZQi6EKJM2nQiClcSaaecMDVIfx2LJMWO0E7OpazOumMkJKdw7HK8xoGEEKJoNh2PpLf+EHqM4NUY3GpqHUnkQ4odoR3v5uDggYOSRmvdKZlNWQhRpoRHJ3M6KpF+N4ec1x+kbSBRICl2hHZ0OvPZnR66ILadkX47QoiyY9OJSJxIobPuuKlBLmFZLCl2hLZuroKuCyb4YhwxyTIEXQhRNmw6EUkP3WEMZIF7XahSV+tIogBS7AhtBXQHnYEA3VWqE8m/sgq6EKIMiEpIIygijgf1OaOw5KyORZNiR2jL1sU0tTqmszt7Qm9oHEgIIe7urxOR2JNGd/0RU4MMObdoUuwI7eVcyuqhC2JPmBQ7QgjLt+lEFN10wdiQAZX8TSOxhMWSYkdoL2e+nba6k1y/EcOVuFSNAwkhRMES0jLZE3aDB2+OwmrwECiKtqHEHUmxI7TnXgdca2CjZNFRd5y9cnZHCGHBgiPiMBjT6akPNjXIkHOLJ8WO0J6iQK1eAHTQnZB+O0IIi3Y4IpbOumPYkwbO1aBqC60jibuQYkdYBv8ugKnY2RsuxY4QwnIdjoj77xJW/YFyCasMkGJHWAa/zgDU1V0iNSaSS7EpGgcSQoi8jEaV4xHX6aU7ZGqQIedlghQ7wjI4VAZP02iGdroQ9obFaBxICCHyCotOolp6KC5KCqpdJfBtq3UkUQhS7AjLcculLOm3I4SwRIcj4mimOweAUrUV6PQaJxKFIcWOsBw5xU573Qn2ht1AVVWNAwkhRG5BEbE0zyl2qNZa2zCi0KTYEZajRntURYe/Lgo17iKXYmW+HSGEZTl8IY7mys1ip5W2YUShSbEjLIetC4pPcwDa60LkUpYQwqIkpmVy/dpl/HRRpoaqLbUNJApNih1hWW5eytKHyNIRQgiLcuRiPE2VUNMd9zpg56ppHlF4UuwIy3Jrv53QaOm3I4SwGKb+OmdNd6S/TpkixY6wLL7tUHVWVFVuYJ14gQs3ZL4dIYRlOBwRS7ObZ3bkElaZIsWOsCzW9ii+bYCcIehyKUsIYQFUVSU4IsY87FzO7JQtUuwIy5Mzm3KHnCHoQgihtfDoZCqnXcBZSUW1sgePBlpHEkUgxY6wPDn9dtrpQthzTvrtCCG0dzgizjy/juLTHPQGjROJopBiR1ieaq1QDXZUURJwSQ4jPDpZ60RCiAouKCJW5tcpw6TYEZbHYINSvR0g/XaEEJbh1jM70l+n7JFiR1gmWSdLCGEhktKzuBh5jTrKRVNDVTmzU9ZIsSMsk39XwNRvZ3/odem3I4TQzNFLcTRSwtArKjhXA2dvrSOJIpJiR1gm76ao1o64KCl4pJwh9HqS1omEEBVUUISsh1XWSbEjLJPegOLXCZBLWUIIbR2+IDMnl3VS7AjLZV46IoS9YTEahxFCVESqqhIUEUszXc7MyXJmp0ySYkdYrpxip43uFAdDo6TfjhCi1F24kYJdyhU8lDhUnQG8m2odSdwDKXaE5fJoiGrnhoOSTtXUU5yJkn47QojSFXQx9r/JBL0ag5WdxonEvZBiR1gunS5Xvx1ZOkIIUdoOX4j7bz0sGXJeZkmxIyybzLcjhNDQ4YhYmUywHJBiR1i2nPl2WurOEhR2FaNR+u0IIUpHSkYWoZGxNFLOmxqkc3KZJcWOsGzutVEdvbBRMqmZHsLpqEStEwkhKoijl+Kpo57HRskEOzdwq6l1JHGPpNgRlk1RUMxD0OVSlhCi9ATlWg+rFSiKtoHEPZNiR1g+c7+dEOmkLIQoNab+OjKZYHkgxY6wfP6dAWiqhHIs7LL02xFClDjzZIJKzmSCVVtqG0jcFyl2hOWr5IfqWh0rJZu6GccJuZqgdSIhRDl3KTYVY1I0frooU4MUO2WaFDuiTLjZb6edXMoSQpSCwxGx/82v414X7Fw1zSPujxQ7omzIGYIukwsKIUrD4Qu3FDsy5LzMk2JHlA1+pn47jZTznAyPIFv67QghSlDQxTiaK1LslBdS7Iiywdkb1b0OOkWlYcYxQq5Ivx0hRMlIy8zm1JW4W1Y6l5FYZZ0UO6LMUHLO7rTXhbAnLFrjNEKI8urY5XhqqJdxUlJRreyhSn2tI4n7JMWOKDtknSwhRCm4tb+O4tMC9AaNE4n7VeRix8/Pj1mzZhEREVESeYQoWM6Znbq6S4SdDycr26hxICFEeXQ4Ipbmys3JBKW/TnlQ5GLnxRdfZPXq1dSsWZPevXuzfPly0tPTSyKbELk5VEb1bARA48xjHJd+O0KIYqaqKodvXyZClHn3VOwEBwezf/9+6tevz/PPP4+3tzeTJk3i8OHDJZFRCDNFhqALIUrQ5bhUUhLjqKNcMjVUlWKnPLjnPjstWrRgwYIFXLlyhbfffpvvv/+e1q1b06xZMxYtWoSqytBgUQJkUVAhRAkKioijiS4MvaKCiy84e2sdSRSDey52MjMzWblyJQ899BAvv/wyrVq14vvvv2fYsGG88cYbjBkzpjhzCmFSoz2qosNfF8Wl82fIlH47QohiZOqvI5ewypsidzE/fPgwixcvZtmyZeh0OsaOHcsnn3xCvXr1zNsMGTKE1q1lXgJRAmxdwLs5XDlEs6xjHLscT4vqlbROJYQoJw5HxDHxZn8duYRVbhT5zE7r1q05e/YsX331FZcvX+ajjz7KVegA+Pv7M3r06GIJePnyZR555BEqV66MnZ0djRs35uDBg+bHVVXlrbfewtvbGzs7O3r16sXZs2eL5bWFZVJq5lzK0ofIpSwhRLFJy8wm5MqtnZPlj/byosjFTlhYGBs3bmTEiBFYWVnlu42DgwOLFy++73CxsbF07NgRKysr/vzzT0JCQvj444+pVOm/v+TnzZvHggUL+Prrr9m3bx8ODg707duXtLS0+359YaFu6bezN1QmFxRCFI8TV+LxNF6nihKPqrMC7yZaRxLFpMiXsa5du0ZkZCRt27bN1b5v3z70ej2tWhXfab8PPvgAX1/fXIWTv7+/+WtVVfn000+ZPn06gwYNAuDHH3/E09OTtWvXFtvZJWFhfNuh6qyoarzBtQunyMhqg7VB5scUQtyfoIg4muX011G8GoGVncaJRHEp8ifExIkTuXjxYp72y5cvM3HixGIJddO6deto1aoVI0aMwMPDg+bNm/Pdd9+ZHw8PDycyMpJevXqZ21xcXGjbti179uwpcL/p6ekkJCTkuokyxNrefHq5hfEoRy/FaZtHCFEuHI6IlUtY5VSRi52QkBBatGiRp7158+aEhIQUS6ibwsLC+Oqrr6hduzabNm3i2Wef5YUXXmDp0qUAREZGAuDp6ZnreZ6enubH8jNnzhxcXFzMN19f32LNLUqeIktHCCGK2eELcTTX3Zw5WYqd8qTIxY6NjQ1RUVF52q9evYrBULzrhxiNRlq0aMH7779P8+bNmTBhAk899RRff/31fe132rRpxMfHm2/5nakSFi6n2GmnC2GvLAoqhLhPV+NTiUlIpKFywdRQtaW2gUSxKnKx06dPH3OxcFNcXBxvvPEGvXv3LtZw3t7eNGjQIFdb/fr1zetyeXl5AeQpvqKiosyP5cfGxgZnZ+dcN1HGVGuF0WBLFSWBuAvHSM/K1jqREKIMO3whjvrKBWyUTLBzA7eaWkcSxajIxc5HH33ExYsXqVGjBt27d6d79+74+/sTGRnJxx9/XKzhOnbsyOnTp3O1nTlzhho1agCmzspeXl5s2bLF/HhCQgL79u2jffv2xZpFWBiDDUp10/9xK/U4Ry7G3+UJQghRsDz9dRRF20CiWBW52KlatSpHjx5l3rx5NGjQgJYtW/LZZ59x7NixYu/78tJLL7F3717ef/99zp07xy+//MK3335r7gitKAovvvgi7733HuvWrePYsWOMHTsWHx8fBg8eXKxZhOWRfjtCiOISlKvYkckEy5t76mTj4ODAhAkTijtLHq1bt2bNmjVMmzaNWbNm4e/vz6effpprKYqpU6eSnJzMhAkTiIuLo1OnTmzcuBFbW9sSzyc0dku/nSWhUUzuVVvjQEKIsig9K5vjlxNoppdip7y65x7FISEhREREkJGRkav9oYceuu9QtxowYAADBgwo8HFFUZg1axazZs0q1tcVZYB3M4xWjrhkJpF28Qhpme2xtdJrnUoIUcaEXEnAKTuWGlbXUFFQpHNyuVPkYicsLIwhQ4Zw7NgxFEUxr26u5FzfzM6WjqKilOgNKP4d4cwmWqnHCYqIo31AZa1TCSHKmMMRcTTLuYSluNcxrcEnypUi99mZPHky/v7+XLt2DXt7e06cOMGOHTto1aoV27ZtK4GIQhRM8e8K5PTbCZN+O0KIojscEUszXajpjsyvUy4VudjZs2cPs2bNwt3dHZ1Oh06no1OnTsyZM4cXXnihJDIKUbCcfjttdKc4EJp3/ichhLib4Ig4mis3JxOU/jrlUZGLnezsbJycnABwd3fnypUrANSoUSPPMHEhSpxHQ7JtK+GgpGO8dIi0TLmMKoQovKiENK7GJdNUF2ZqkGKnXCpysdOoUSOOHDkCQNu2bZk3bx67du1i1qxZ1KwpkzCJUqbTofPvDEBr9TiHLsRqHEgIUZYERcQSoFzBSUkFKweoUl/rSKIEFLnYmT59OkajEYBZs2YRHh5O586d2bBhAwsWLCj2gELcza3z7eyVfjtCiCI4HHHLelhVW4C+eJc9EpahyP+rffv2NX9dq1YtTp06RUxMDJUqVTKPyBKiVOV0Um6pO8vCc1ehT12NAwkhyorDF2IZpuTMryNDzsutIp3ZyczMxGAwcPz48Vztbm5uUugI7bjXJsvBExslE/2VA6RkZGmdSAhRBmRkGTl2Od487FxGYpVfRSp2rKysqF69usylIyyLoqCvaTq70wbptyOEKJyTVxMwZCVTV3fJ1CCdk8utIvfZefPNN3njjTeIiYkpiTxC3JP/+u2EyDpZQohCCYqIpYkuDB0quFQHJy+tI4kSUuQ+O59//jnnzp3Dx8eHGjVq4ODgkOvxw4cPF1s4IQotZ0RWUyWU+ecuAfW0zSOEsHiHI+JofrO/TjXpr1OeFbnYkdXEhUWq5EeWsy9WCRexvbqf5PRuONjIqAohRMEOR8QyUPrrVAhF/jR4++23SyKHEPfNENAVgn6mjXKCA+dj6FbXQ+tIQggLdS0xjUuxKTS3uTlzshQ75VmR++wIYbFuWSdrb5j0KRNCFCwoIo5qynXclQTQWYFXE60jiRJU5GJHp9Oh1+sLvAmhGT9Tv51GynmOnjuvbRYhhEU7HBH7X38dr8ZgZattIFGiinwZa82aNbnuZ2ZmEhQUxNKlS5k5c2axBROiyJy9yaxUG6vYszhH7iMxrSdOtlZapxJCWKCgiDgekP46FUaRi51BgwblaRs+fDgNGzZkxYoVPPHEE8USTIh7YRXQBQ6epa1ygk0nohjesprWkYQQFiYz28jRS3FMMxc7Mr9OeVdsfXbatWvHli1bimt3QtybnPl22utCWHXwosZhhBCW6HRkIsbMdBrqzpsapNgp94ql2ElNTWXBggVUrVq1OHYnxL3L6bdTT3eRsPBQzkcnaxxICGFpDkfE0kC5gDVZYF8ZKvlrHUmUsCJfxrp9wU9VVUlMTMTe3p6ff/65WMMJUWQOlU2L+V0+xEP63fx6qDWv9JWFQYUQ/zl8IfaWlc5bgaztWO4Vudj55JNPchU7Op2OKlWq0LZtWypVqlSs4YS4J83+B5cPMUq/jbEHh/JS7zrodfLLTAhhEnQxjim6UNMd6ZxcIRS52Bk/fnwJxBCiGDUajrrpTepkXcY76Tg7zzWla50qWqcSQliA6KR0LtxIobn1zckEpb9ORVDkPjuLFy9m1apVedpXrVrF0qVLiyWUEPfFzhWlgWnU4Ej9NlZKR2UhRI7giDgqE0913XVAgaottI4kSkGRi505c+bg7u6ep93Dw4P333+/WEIJcd+aPwrAQP0edp64QFxKhsaBhBCW4HBELM1uDjmvUhdsXbQNJEpFkYudiIgI/P3z9lyvUaMGERERxRJKiPvm1wkq+eOopNGbPfxf8BWtEwkhLMDhiFiay/w6FU6Rix0PDw+OHj2ap/3IkSNUrly5WEIJcd8UBZo/AsilLCGESVa2kaOX4v9bJqKqFDsVRZGLnYcffpgXXniBrVu3kp2dTXZ2Nv/88w+TJ09m9OjRJZFRiHvT7H+oio42utOkXj3FiSvxWicSQmjodFQiaRmZNNWFmRpkJFaFUeRi591336Vt27b07NkTOzs77Ozs6NOnDz169JA+O8KyOPug1OoFwEj9dlYdvKRxICGEloIi4qilXMZRSQUrB/Cor3UkUUqKXOxYW1uzYsUKTp8+TWBgIKtXryY0NJRFixZhbW1dEhmFuHc5HZWH6XfwR9AF0rOyNQ4khNBKrv46VVuATq9tIFFqijzPzk21a9emdu3axZlFiOJX5wFUe3eqpETTLP0gf4c0p38Tb61TCSE0cPhCLM8oMr9ORVTkMzvDhg3jgw8+yNM+b948RowYUSyhhCg2BmuUpqa+ZKP00lFZiIrqUmwK52+k0FxmTq6Qilzs7Nixg379+uVpf/DBB9mxY0exhBKiWOVcyuquC+LU2TNcjU/VOJAQorTtPncDR1KorcvpuycjsSqUIhc7SUlJ+fbNsbKyIiEhoVhCCVGsPOpBtdYYFCNDdP+y+vBlrRMJIUrZv+eiaaILQ4cKLtXByVPrSKIUFbnYady4MStWrMjTvnz5cho0aFAsoYQodjlnd0bot7PqQASqqmocSAhRWoxGld3nommmyGSCFVWROyjPmDGDoUOHEhoaSo8ePQDYsmULv/zyC7/++muxBxSiWDQairpxGgGZV3GPDeLA+Wa08XfTOpUQohScikzkRnIGrWykv05FVeQzOwMHDmTt2rWcO3eO5557jpdffpnLly/zzz//UKtWrZLIKMT9s3FCaTgEkI7KQlQ0O89dR4eRNvozpgYpdiqcIhc7AP3792fXrl0kJycTFhbGyJEjeeWVV2jatGlx5xOi+LQwXcrqr9/HtqOhJKVnaRxICFEadp67QRMlDEdjIti4gE9zrSOJUnZPxQ6YRmWNGzcOHx8fPv74Y3r06MHevXuLM5sQxcu3LWrl2tgr6fQy7mLD0ataJxJClLD0rGz2h9+gq+6IqaFmV9Df8xRzoowqUrETGRnJ3LlzqV27NiNGjMDZ2Zn09HTWrl3L3Llzad1aTg0KC6YoKLI4qBAVyqELsaRlGulpfczUkLOEjKhYCl3sDBw4kLp163L06FE+/fRTrly5wsKFC0symxDFr+nDqIqeFrpzxEUcI/R6ktaJhBAlaNe5aFxJpJGaMxJLip0KqdDFzp9//skTTzzBzJkz6d+/P3q9rCkiyiAnT5Q6DwCmjsqyOKgQ5dvOczfopDuODiN4NACXqlpHEhoodLGzc+dOEhMTadmyJW3btuXzzz8nOjq6JLMJUTJyOioP1f/LukPhZGUbNQ4khCgJ8SmZHLsU919/nVo9tQ0kNFPoYqddu3Z89913XL16laeffprly5fj4+OD0Whk8+bNJCYmlmROIYpPrd6ojp5UVhJpkrKXHWeva51ICFEC9oRFo6pGelhJf52KrsijsRwcHHj88cfZuXMnx44d4+WXX2bu3Ll4eHjw0EMPlURGIYqX3oDS9GEgp6PyAbmUJUR5tPNcNPWVCCqrsWBlD9Xbax1JaOSeh54D1K1bl3nz5nHp0iWWLVtWXJmEKHk5y0d01R3h+KmT3EhK1ziQEKK47TwbTVfdUdMd/y5gsNE2kNDMfRU7N+n1egYPHsy6deuKY3dClDz3WlC9A3pFZRDbWRt8RetEQohidDEmhfM3Uuiqv9lfRy5hVWTFUuwIUSbldFQeqd/GrwcuyOKgQpQju0OjcSSFVrqcJSKk2KnQpNgRFVeDQajWjtTQXcPl+gGOXY7XOpEQopj8ezaaDroTGMgGtwBw89c6ktCQFDui4rJ2QGk8HDCd3ZE5d4QoH4xGld2hN/7rryNndSo8KXZExZbTUbmfbh//BJ8hLTNb40BCiPt1MjKBmOR0ukt/HZFDih1RsVVtiVqlPrZKJt0zd7DpRKTWiYQQ92nn2WgClCv4KNGgtwG/jlpHEhqTYkdUbIqCcmtH5UNyKUuIsm7nuWi63Zw1uUYHsHbQNpDQnBQ7QjQZjaqzookunBuhh7gUm6J1IiHEPUrLzObA+Zj/loio3VvbQMIiSLEjhENllHr9ABih28Zvhy5rHEgIca8OX4iFzFTa6k+ZGqS/jkCKHSFMmo8FYLB+F/93KAyjUebcEaIs2nkumna6k9iQCS6+4F5H60jCAkixIwRAQHeMTj5UUpJoEP8ve8NvaJ1ICHEPdp2Lzr3KuaJoG0hYBCl2hADQ6dE1HwPInDtClFVxKRkcvRx/S7Ejl7CEiRQ7QtzUzFTsdNIdJ/jYURLSMjUOJIQoij2hN/Alipq6SNAZTIt/CoEUO0L8x80f1b8LOkXlIXUbfxy5qnUiIUQR7DwXTZebsyb7tgVbF20DCYshxY4Qt1ByOiqPMGxn1YELGqcRQhTFzlz9deQSlviPFDtC3Kr+AIw2zlRTonG4souzUYlaJxJCFMLFmBSu3oing+6EqUGKHXELKXaEuJWVHbomIwEYpd/KKplRWYgyYde5aFrqzuCgpIOjJ3g11jqSsCBS7Ahxu5zFQfvoDvL3oZNkZhs1DiSEuJt/z0XTTRdsuhMgQ85FblLsCHE7n2aono2xUbLonLaNraeuaZ1ICHEHRqPK7nPRdL3ZOblWT20DCYtTpoqduXPnoigKL774orktLS2NiRMnUrlyZRwdHRk2bBhRUVHahRTlgtLC1FF5lH4bqw5e1DaMEOKOQq4mYJMSST3dRVQUCOihdSRhYcpMsXPgwAG++eYbmjRpkqv9pZde4vfff2fVqlVs376dK1euMHToUI1SinKj8XCMehsa6C5w7cw+biSla51ICFGAneei6aI3ndVRqrYEezeNEwlLUyaKnaSkJMaMGcN3331HpUqVzO3x8fH88MMPzJ8/nx49etCyZUsWL17M7t272bt3r4aJRZln74au/gAAhitb2XBM5twRwlLlWiJCVjkX+SgTxc7EiRPp378/vXrlHkp46NAhMjMzc7XXq1eP6tWrs2fPntKOKcqbnI7Kg/S72RAUrnEYIUR+0jKzORR+nc6646YGGXIu8mHQOsDdLF++nMOHD3PgwIE8j0VGRmJtbY2rq2uudk9PTyIjIwvcZ3p6Ounp/12WSEhIKLa8ohzx70q2sy/OCRdxv/Q3F2Pa4utmr3UqIcQtDl2IpX72GZwNKah2lVB8mmsdSVggiz6zc/HiRSZPnkxgYCC2trbFtt85c+bg4uJivvn6+hbbvkU5otOhb/4/AIbrd/B/wZc1DiSEuN3Oc9F005suYSkBPUCn1ziRsEQWXewcOnSIa9eu0aJFCwwGAwaDge3bt7NgwQIMBgOenp5kZGQQFxeX63lRUVF4eXkVuN9p06YRHx9vvl28KKNtRAGajgags+4YOw8fRVVVjQMJIW61S5aIEIVg0cVOz549OXbsGMHBweZbq1atGDNmjPlrKysrtmzZYn7O6dOniYiIoH379gXu18bGBmdn51w3IfLlVpMs3/boFJUWsZsIuSqXPIWwFLHJGVy5HEETXU6fOhlyLgpg0X12nJycaNSoUa42BwcHKleubG5/4oknmDJlCm5ubjg7O/P888/Tvn172rVrp0VkUQ4ZWjwKF/cwTL+DFUGXaegjKykLYQn2hN2gk3LMdMerMTgVfEZfVGwWfWanMD755BMGDBjAsGHD6NKlC15eXqxevVrrWKI8aTCILL09AbqrhAdtJdsol7KEsAQ7z0XTVX/zEpYMORcFU1TphEBCQgIuLi7Ex8fLJS2Rr+zVz6A/uoxfsrrj99j3dAhw1zqSEBVe1w+2sDplHJWVRBi/Afw6ah1JlLLCfn6X+TM7QpQGfYtHABig38uGQ2EapxFCRNxIwTkuhMpKIqq1I/i20TqSsGBS7AhRGNU7kOboi7OSSlbIOtKzsrVOJESFtiv0v1XOlZrdQG+laR5h2aTYEaIwdDqsW44BoH/2Vraeuq5xICEqtp1no+mqv7nKuQw5F3cmxY4QhaRrZppgsKPuBDsOHNY4jRAVl9GocvTceZorZ00NtXpqG0hYPCl2hCisSjVI8umATlGpEraGhLRMrRMJUSGFXE2gcXoQekVFda8LrtW1jiQsnBQ7QhSBQxvT4qBDlO1sPCoroQuhhX/PRtNVZ7qEpcgq56IQpNgRogiUBoPI0Nvjp4vi5IG/tI4jRIW06+z1W+bXkUtY4u6k2BGiKKwdyKg7CIB6kb8TlZCmcSAhKpa0zGziLhzBS4nFaLCF6h20jiTKACl2hCgix7ZjAeiv28ufh0M1TiNExXLwfCwd1SAAFP8uYGWrcSJRFkixI0RRVW9Pgp0vjkoaNw7+qnUaISqUnbescq7IkHNRSFLsCFFUioIhZ86d9vEbOXctSeNAQlQch89G0Ep32nRHih1RSFLsCHEP7Fs9ghGFDvoQtu49oHUcISqE2OQMXKL2Yq1kk+1SA9xqah1JlBFS7AhxL1x9ia7SDgDdsRXIerpClLzdoTfoopguYenr9AFF0TiRKCuk2BHiHrm0HwdA7/S/CYqI0TiNEOXfzrPX6aa7OeRcLmGJwpNiR4h7ZNNoEKk6B6rrrhP87wat4whR7l04ewRf3XWMOivw66R1HFGGSLEjxL2ytifWfwAA7qG/kZlt1DiQEOVXxI0U6ibuA0Ct3h5sHDVOJMoSKXaEuA8enR8DoKdxN3tOXtA4jRDll2nIuWmJCL0sESGKSIodIe6DoUY7om18cVDSubRrudZxhCi39p25RDtdiOmO9NcRRSTFjhD3Q1FIbzQagFpX1pGSkaVxICHKn2yjSkbYTmyVTDLsvcCjvtaRRBkjxY4Q98mny3iMKLRRQth14KDWcYQod0KuJNAq8zAAhroy5FwUnRQ7QtwnxaUaEa5tAEjZ/7PGaYQof/49d928RISutlzCEkUnxY4QxcC2tWnOnZZxfxKTJCuhC1GcTp86Ti3dFYyKHvy7ah1HlEFS7AhRDLzaDCVJcaCaEs2hbf+ndRwhyo20zGxcLu8AIN2rJdi5ahtIlElS7AhRHKzsuOj9AADWx1doHEaI8uPA+Rg6EQyAbb0+2oYRZZYUO0IUE48uTwDQJvVfLl2N0jiNEOXD7tNX6aA7AYAi/XXEPZJiR4hiUrluBy4bfLFTMjiz9Set4whR5qVnZRN2+B8clTTSbSqDV1OtI4kySoodIYqLonCj1nAAqoT+JiuhC3Gffj9yleYZBwCwqtMLdPKRJe6NfOcIUYz8ez5OtqrQODuEc6eOah1HiDJLVVV++vcUI/TbAdDV66dxIlGWSbEjRDFyqlKdkw6tAbj27yKN0whRdu0Ju0Hj639QWUkk26U61BugdSRRhkmxI0Qxy2r8MAC1rvyOMUuWjxDiXiz59xxP6dcDoO/wPOgNGicSZZkUO0IUs3rdRhGPA57c4NTe9VrHEaLMCbuehPWZP6ihu0a2bSVoPkbrSKKMk2JHiGJma+fACTfTfCDpB2RUlhBFtXhnOE8bfgdA3+4ZsHbQOJEo66TYEaIEOLYdC0D9+G2kJ8VqnEaIsiMuJYPLh/+kse482XpbaP2U1pFEOSDFjhAloGGrboQqvtiSydl/5OyOEIW1bP9FHsO05Iqu5VhwqKxxIlEeSLEjRAnQ63WEVx0EgH3IMo3TCFE2ZGYb2btzC531xzEqepT2k7SOJMoJKXaEKCHVuo4nS9VRMy2EpMshWscRwuJtOHaV4em/AaA2GAKVamicSJQXUuwIUULq1qrFAauWAFzc+oPGaYSwbKqqsn77bvrp9gGg7/yitoFEuSLFjhAlRFEU4mqblo/wDF8LxmxtAwlhwQ5diKXT9RXoFZUMv+7g1VjrSKIckWJHiBLUqPsoYlVH3LKjiT3+l9ZxhLBYK7YHMVK/DQDrrlM0zSLKHyl2hChBvh6V2G3fA4CYXYs1TiOEZboYk4Lv2Z+wVTJJrdIU/DprHUmUM1LsCFHC1Gb/A8A36h9IlTl3hLhd4L8hjNWbznzadZsCiqJxIlHeSLEjRAlr36E7p4y+WJPJ9b0yDF2IWyWmZcLhn3BVkklxrAH1B2odSZRDUuwIUcIqO9kSVLk/AOqBRaCqGicSwnKs3BfGI/wBgG3XF0Gn1zaQKJek2BGiFLi0H0uSaotHylkyTm3SOo4QFiHbqHJ5ZyDVlGhSrd3QNXtY60iinJJiR4hS0KtFfdYZ+gIQs+kDjdMIYRn+On6VEemrATB0eA6s7DROJMorKXaEKAXWBh22XZ4nXTXgFXeY9LBdWkcSQnOH/1lFfd1FMnT2WLV9Uus4ohyTYkeIUjKgY0s26rsDcG3DHI3TCKGtIxfj6Blj6rCf1Xws2FXSOJEoz6TYEaKUWBt0qB0nk60q+Eb/S/qlo1pHEkIzf29eTzvdSbLRY9/lea3jiHJOih0hStGDXTvwj74DAFf+eF/jNEJo42p8Kg3PLwEgofYQcKmmbSBR7kmxI0QpsjHoSW/7AgDVIzeRfu2cxomEKH2/b9lBH+UAAJV6v6JxGlERSLEjRCnr3bM3u5UW6DFy4fe5WscRolSlZGThdvQbdIrKde/u4FFf60iiApBiR4hSZmPQE9/K1EfB7+Ia0mMva5xIiNKzYXcQA9XtALj1napxGlFRSLEjhAa69xnEEaUe1mQRum6e1nGEKBVGo0r6rq+wUbK45tIEfY32WkcSFYQUO0JowNZKz7WmzwHgF76cjMQYjRMJUfK2HwtjYMafADj3elUW/BSlRoodITTSud8YzlADe9I4ue5jreMIUeIub/kSZyWFaNsa2DYcoHUcUYFIsSOERmytDVxu9AwA1c/+SEZKosaJhCg5IRev0Sv+NwD0nSeDTj5+ROmR7zYhNNR+4BNcwpNKJHD894VaxxGixBz98we8lFji9O5UavuI1nFEBSPFjhAasrWx4Xxd05pAVU99T2ZGmsaJhCh+1xJSaH35RwCSWzwFBhuNE4mKRoodITTWctBEonHFU71B0B/fah1HiGK3Z8PPBChXSFbsqdrzWa3jiApIih0hNGZn78C5gHEAeB77mszMTI0TCVF80jKzqXHqewCu1h4Dti4aJxIVkRQ7QliAJoNfIgEHaqiXObDxJ63jCFFsdm75nWacJgMDfv2maB1HVFBS7AhhAeydKnG2xsMAuAV9TlZWtsaJhLh/qqricPALAMK8B2Jw9dE4kaiopNgRwkLUG/wqqVhTzxjKnr9/0zqOEPft0IHdtM/aj1FVqDZAloYQ2pFiRwgL4VDJi7NVh5m+PrCArGyjxomEuD8p2z8F4LRrFxyrNtA2jKjQpNgRwoLUGvQ6mehpkX2Mnds2ah1HiHsWHnqadklbAHDt86rGaURFZ9HFzpw5c2jdujVOTk54eHgwePBgTp8+nWubtLQ0Jk6cSOXKlXF0dGTYsGFERUVplFiI+2Pv4cc5z34AGPZ8SrZR1TiREPfm4p/zsVayOWPbBO+GnbWOIyo4iy52tm/fzsSJE9m7dy+bN28mMzOTPn36kJycbN7mpZde4vfff2fVqlVs376dK1euMHToUA1TC3F/qg96AyMKnbL2sX3ndq3jCFFksTeu0fL6WgCMHSZrG0YIQFFVtcz86Xj9+nU8PDzYvn07Xbp0IT4+nipVqvDLL78wfPhwAE6dOkX9+vXZs2cP7dq1K9R+ExIScHFxIT4+Hmdn55J8C0IUSujngwmI3spfhm70fGMtep2sDi3Kjl1fTKDj9RWc19egxpvBKLIOlighhf38LlPfgfHx8QC4ubkBcOjQITIzM+nVq5d5m3r16lG9enX27NmjSUYhioNX/zcA6JG5g3/2HtQ4jRCFd3DrWjpeXwFAcucZUugIi1BmvguNRiMvvvgiHTt2pFGjRgBERkZibW2Nq6trrm09PT2JjIwscF/p6ekkJCTkuglhSRz82xDh2haDYiRl63yM0ndHlAHXrkVRdbtp4sCgKoNp2G2ExomEMCkzxc7EiRM5fvw4y5cvv+99zZkzBxcXF/PN19e3GBIKUbwqP/g6AH0zNvP3wWMapxHizoxGlTNLnsWbG1zRedPwsYVaRxLCrEwUO5MmTeKPP/5g69atVKtWzdzu5eVFRkYGcXFxubaPiorCy8urwP1NmzaN+Ph48+3ixYslFV2Ie+ZQpztXnRphq2RyY8tncnZHWLStv31Dp5QtZKsKxsFfY20v/R+F5bDoYkdVVSZNmsSaNWv4559/8Pf3z/V4y5YtsbKyYsuWLea206dPExERQfv27Qvcr42NDc7OzrluQlgcRcG5t2nW2f5p69kcdFbjQELk79SZ07Q8PguAk7WfolqTbtoGEuI2Fl3sTJw4kZ9//plffvkFJycnIiMjiYyMJDU1FQAXFxeeeOIJpkyZwtatWzl06BCPPfYY7du3L/RILCEsmUOjgUTb+eOspHLpr4VydkdYnJT0DBJXTMBVSeaCTR0ajp6tdSQh8rDoYuerr74iPj6ebt264e3tbb6tWLHCvM0nn3zCgAEDGDZsGF26dMHLy4vVq1drmFqIYqTTYd/DNPvsQ2lr2Xz0vLZ5hLjN30vfp3V2MGlY4zpmMYrBWutIQuRRpubZKSkyz46waNmZxM9rjEv6VT63e4bnXp2LTubdERbg3927aL1pELZKJmGt3qLmgJe1jiQqmHI5z44QFZLeCqvOplloByX/xubjlzUOJARExiTi9tckbJVMwp3bULPfS1pHEqJAUuwIUQbYtx1PslUlfHXXObpxEXJCVmgp26iya9FUGhJGouJI1fGLQSYPFBZMvjuFKAus7NC1ew6AQUnL2XziqsaBREX2f7+vZXDiMgBSes/D2q3aXZ4hhLak2BGijLDr+DTpegfq6C6zb2OgnN0RmjgefpkWh19Hr6hc8OmPZ4cxWkcS4q6k2BGirLB1wdjqCQAGJCznt0OXNA4kKprk9CzCAl/CT4kk1lCF6o9+oXUkIQpFih0hyhC7zs+TqdjQXHeOP1cv5rO/z8rcO6LUrPjlex7K2gSA1bBvUOwqaZxIiMKRYkeIssTRA12rsQB8Y/UJyVs/5rmfD5CUnqVxMFHe/X3wBAPPvw/A1fqP41i/p8aJhCg8KXaEKGP0vWdCo2EYFCNvWC1j+NmpjPt8IxduJGsdTZRTV2JTUP6YTBUlnmg7f7yHztE6khBFIsWOEGWNtQMM+wEGfIJRb00vfRCfJUzmzYWL+ffsda3TiXIm26iyZsmH9OQAmRhwGbMErGy1jiVEkUixI0RZpCjQ6nF0T24hy9Wfako0i9W32LH0bb7fESojtUSxCdy4g7FxXwGQ1P5VrKo10zaQEPdAih0hyjLvJhie2UF2/cFYKdm8aQikxuanmL7sX9Iys7VOJ8q44As3qLd3Kk5KKtGVmlOp96taRxLinkixI0RZZ+uMfuQS1H4fk61Y0Vt/iGdPP8b0zxdzJS5V63SijEpKz2Lvz+/QRneKNMWOyo8uBp1e61hC3BMpdoQoDxQFpc2T6CdsIdWpOtWUaN6Pm8qyBa9zIPyG1ulEGfT1iv/j8YxAAIwPzEVx89c4kRD3ToodIcoT76bYTdxJSq0BWCvZvGxcQuzikazaeUzrZKIMWX84nAHn3sZaySbGtw/2bcZpHUmI+yLFjhDlja0L9mN+JqPPB2QqVvTRHaTdX0P4MnAlGVlGrdMJC3cpNoXr66ZTT3eRZCs33EZ/ZeoQL0QZJsWOEOWRomDd4RkMT24m3rYqvrrrPHnmGQI/m0Z0YprW6YSFyso28v2PSxmrrgfAdugX4OCucSoh7p8UO0KUY0rV5rhM3s21an2xVrJ5LPFrjn0yiBOhEVpHExbo+7+P8FTMh+gUlcSGj6Cv30/rSEIUCyl2hCjv7FzxeGIF1zu/SyYGuhv34vxjT7Zv3aR1MmEBMrON/HnsKo9//y9eO9+gqnKDJAdfnB76QOtoQhQbRZXZx0hISMDFxYX4+HicnZ21jiNEiUkK30dq4FiqZEWSoerZVmMyPcfNQK+Xv3sqmogbKazcd5arB9fTKXMnvXSHcVJSMaJD98Qm8G2jdUQh7qqwn99S7CDFjqhYslNiCf1+PHVitgFw0LYD1h2eoV7bvljbyDIA5VlGlpF/jkdwcuca/KP+oqcuCCflv7mYshy8MfSaDs0f0TClEIUnxU4RSLEjKhxV5cSaD6h9ZB7Wimmm5WRsOefYGqVOH2p1GIK9u6/GIUVxuRB5g4NbfsX+3Do6GQ/lKnBS7bywbjIEfcMhUK016OQsnyg7pNgpAil2REUVcXwX17d8jl/sbioTl/sx6wCSfHtQre1gnGu1l9lzy5iM1GSObvuVjKOraZKyF0flv1F4CdYeKA0G49RyBFRtJQWOKLOk2CkCKXZERWfMzuZ08L9cP/wHla9up372WXTKf78aEhUnrnl0xLXZACo36QcOlTVMKwqUmUrU4fXc2LecGjH/4sB/Bc4NfRUSa/anWqeHMfi2kQJHlAtS7BSBFDtC/EdVVULPnydsz/9hc34LzdIP4qKkmB83ohDl1Airen2p3HwAildT+eAsbaoK2ZmQlQZZaWSe3821vStwu7wVO/W/S1SRuHPJuw/VO/8Pj3od5f9JlDtS7BSBFDtCFOxidAJH9v5N5smN1E3cSwPdhVyPJ1lVJs2vB27NBqCr0dE0CV1FmnHXaISsVMhMhcyUW/5Nu+V+aj7bpEJWuqlgyc7IKVxM99WsdLIz0jBmpqFmpZn2lZ2Bkp2OLjsdgzG9wDiXVXeOu3SjUuuRtGjfE4PBUIoHQ4jSJcVOEUixI0Th3EhKZ/fho8QcWY/P9Z10UI7ioOT+4M1SrEi1qUKWgyc4+WBdyQdbt6roXaqCkxc4eZtuNo4avYtCMBoh8QrcCIWYUIgJwxgdihp3ETUzGTJTUTJTUbJS0WUXXHiUlkuqO9v1HdA1GkKX7g9QtZK91pGEKBVS7BSBFDtCFF1Sehb/hlwm7PBfOEVspaN6mADd1UI/P0PvQJqtB0YnL3TO3ti6VcXatdp/BZF9ZbB1BhsnMNgWeLYo26iSkWUkPSs751/T1+k3v840kpqZRUpGNikZ2aTe/Dc9A0NyJPZJF3BOicA19SKVMy5SJeMKntlXsSGjyMckTbUiDWtSsSFVtSYNG1Kxzvk6575qejwd07bpqhXpWJGB6d9b7xv11uit7TBY22FlY4u1jR1WNvbY2Nlja2ePnZ09DnZ2BHg407m2OwaZL0lUMFLsFIEUO0Lcn4wsI3vDbnD6cjTJNy6TEXsFEq9ilRyFfcZ1qhCDJ7F4KrF4KLE43zL0uTAyMZCi2JGMPUnYk6jakaDakWC0JUG1IxF7klQ7EnL+TcKORNWeJOxIwQYvJQY/JTLnFoWfEkkNJQpbJbPg11T1RKgeXFA9Oa96cV71JEL1IEm1I1tvR7bBFqM+52awQzXYYmVlwFqvw8agx9qgM99s9P99ba3XYWNl2sbJ1oCTrVXOvwacbP772tHWgI1BRsAJcSdS7BSBFDtClByjUSU6OZ2o+HQiE9KITEgjJuYGqTFXyI67gpJ8FZuUa7hm38BTicFTicWLWFyUZBxJzTUqrLhlK3oSbKqS6FCdZMfqpDv5keniT3Ylf3SVamBva4OdtR57az32VgZsrU3FilKR+iQJYcEK+/ktPdeEECVKp1PwcLLFw8mWxrjktNYAWuTaLjk9i8iENKLi0ziQkEa2UcXGoGCnpuFAMnbGFOyMKdhmJ2NjTMY6KxGrrBSsMhMxZCWhz0hEl5EI6QmQnmi6pSVARjI4eoBbTagcAG4BOV/XRO9SnUp6A5VK/agIIUqTFDtCCIvgYGMgoIojAVUsuOOyEKJMkt5sQgghhCjXpNgRQgghRLkmxY4QQgghyjUpdoQQQghRrkmxI4QQQohyTYodIYQQQpRrUuwIIYQQolyTYkcIIYQQ5ZoUO0IIIYQo16TYEUIIIUS5JsWOEEIIIco1KXaEEEIIUa5JsSOEEEKIck2KHSGEEEKUawatA1gCVVUBSEhI0DiJEEIIIQrr5uf2zc/xgkixAyQmJgLg6+urcRIhhBBCFFViYiIuLi4FPq6odyuHKgCj0ciVK1dwcnJCUZRi229CQgK+vr5cvHgRZ2fnYtuvyE2Oc+mRY1065DiXDjnOpaMkj7OqqiQmJuLj44NOV3DPHDmzA+h0OqpVq1Zi+3d2dpYfpFIgx7n0yLEuHXKcS4cc59JRUsf5Tmd0bpIOykIIIYQo16TYEUIIIUS5JsVOCbKxseHtt9/GxsZG6yjlmhzn0iPHunTIcS4dcpxLhyUcZ+mgLIQQQohyTc7sCCGEEKJck2JHCCGEEOWaFDtCCCGEKNek2BFCCCFEuSbFzn364osv8PPzw9bWlrZt27J///47br9q1Srq1auHra0tjRs3ZsOGDaWUtGwrynH+7rvv6Ny5M5UqVaJSpUr06tXrrv8vwqSo3883LV++HEVRGDx4cMkGLEeKeqzj4uKYOHEi3t7e2NjYUKdOHfn9UQhFPc6ffvopdevWxc7ODl9fX1566SXS0tJKKW3ZtGPHDgYOHIiPjw+KorB27dq7Pmfbtm20aNECGxsbatWqxZIlS0o2pCru2fLly1Vra2t10aJF6okTJ9SnnnpKdXV1VaOiovLdfteuXaper1fnzZunhoSEqNOnT1etrKzUY8eOlXLysqWox/l///uf+sUXX6hBQUHqyZMn1fHjx6suLi7qpUuXSjl52VLU43xTeHi4WrVqVbVz587qoEGDSidsGVfUY52enq62atVK7devn7pz5041PDxc3bZtmxocHFzKycuWoh7nwMBA1cbGRg0MDFTDw8PVTZs2qd7e3upLL71UysnLlg0bNqhvvvmmunr1ahVQ16xZc8ftw8LCVHt7e3XKlClqSEiIunDhQlWv16sbN24ssYxS7NyHNm3aqBMnTjTfz87OVn18fNQ5c+bku/3IkSPV/v3752pr27at+vTTT5dozrKuqMf5dllZWaqTk5O6dOnSkopYLtzLcc7KylI7dOigfv/99+q4ceOk2Cmkoh7rr776Sq1Zs6aakZFRWhHLhaIe54kTJ6o9evTI1TZlyhS1Y8eOJZqzPClMsTN16lS1YcOGudpGjRql9u3bt8RyyWWse5SRkcGhQ4fo1auXuU2n09GrVy/27NmT73P27NmTa3uAvn37Fri9uLfjfLuUlBQyMzNxc3MrqZhl3r0e51mzZuHh4cETTzxRGjHLhXs51uvWraN9+/ZMnDgRT09PGjVqxPvvv092dnZpxS5z7uU4d+jQgUOHDpkvdYWFhbFhwwb69etXKpkrCi0+C2Uh0HsUHR1NdnY2np6eudo9PT05depUvs+JjIzMd/vIyMgSy1nW3ctxvt1rr72Gj49Pnh8u8Z97Oc47d+7khx9+IDg4uBQSlh/3cqzDwsL4559/GDNmDBs2bODcuXM899xzZGZm8vbbb5dG7DLnXo7z//73P6Kjo+nUqROqqpKVlcUzzzzDG2+8URqRK4yCPgsTEhJITU3Fzs6u2F9TzuyIcm3u3LksX76cNWvWYGtrq3WcciMxMZFHH32U7777Dnd3d63jlHtGoxEPDw++/fZbWrZsyahRo3jzzTf5+uuvtY5Wrmzbto3333+fL7/8ksOHD7N69WrWr1/Pu+++q3U0cZ/kzM49cnd3R6/XExUVlas9KioKLy+vfJ/j5eVVpO3FvR3nmz766CPmzp3L33//TZMmTUoyZplX1OMcGhrK+fPnGThwoLnNaDQCYDAYOH36NAEBASUbuoy6l+9pb29vrKys0Ov15rb69esTGRlJRkYG1tbWJZq5LLqX4zxjxgweffRRnnzySQAaN25McnIyEyZM4M0330Snk/MDxaGgz0JnZ+cSOasDcmbnnllbW9OyZUu2bNlibjMajWzZsoX27dvn+5z27dvn2h5g8+bNBW4v7u04A8ybN493332XjRs30qpVq9KIWqYV9TjXq1ePY8eOERwcbL499NBDdO/eneDgYHx9fUszfplyL9/THTt25Ny5c+aCEuDMmTN4e3tLoVOAeznOKSkpeQqamwWmKstIFhtNPgtLrOtzBbB8+XLVxsZGXbJkiRoSEqJOmDBBdXV1VSMjI1VVVdVHH31Uff31183b79q1SzUYDOpHH32knjx5Un377bdl6HkhFPU4z507V7W2tlZ//fVX9erVq+ZbYmKiVm+hTCjqcb6djMYqvKIe64iICNXJyUmdNGmSevr0afWPP/5QPTw81Pfee0+rt1AmFPU4v/3226qTk5O6bNkyNSwsTP3rr7/UgIAAdeTIkVq9hTIhMTFRDQoKUoOCglRAnT9/vhoUFKReuHBBVVVVff3119VHH33UvP3NoeevvvqqevLkSfWLL76QoeeWbuHChWr16tVVa2trtU2bNurevXvNj3Xt2lUdN25cru1Xrlyp1qlTR7W2tlYbNmyorl+/vpQTl01FOc41atRQgTy3t99+u/SDlzFF/X6+lRQ7RVPUY7179261bdu2qo2NjVqzZk119uzZalZWVimnLnuKcpwzMzPVd955Rw0ICFBtbW1VX19f9bnnnlNjY2NLP3gZsnXr1nx/5948tuPGjVO7du2a5znNmjVTra2t1Zo1a6qLFy8u0YyKqsq5OSGEEEKUX9JnRwghhBDlmhQ7QgghhCjXpNgRQgghRLkmxY4QQgghyjUpdoQQQghRrkmxI4QQQohyTYodIYQQQpRrUuwIISoMPz8/Pv300yI/T1EU1q5dW+x5hBClQ4odIYQmxo8fz+DBg7WOIYSoAKTYEUIIIUS5JsWOEMLizJ8/n8aNG+Pg4ICvry/PPfccSUlJ5seXLFmCq6srf/zxB3Xr1sXe3p7hw4eTkpLC0qVL8fPzo1KlSrzwwgtkZ2fn2ndiYiIPP/wwDg4OVK1alS+++CLX42fPnqVLly7Y2trSoEEDNm/enCffa6+9Rp06dbC3t6dmzZrMmDGDzMzMkjkYQoj7ZtA6gBBC3E6n07FgwQL8/f0JCwvjueeeY+rUqXz55ZfmbVJSUliwYAHLly8nMTGRoUOHMmTIEFxdXdmwYQNhYWEMGzaMjh07MmrUKPPzPvzwQ9544w1mzpzJpk2bmDx5MnXq1KF3794YjUaGDh2Kp6cn+/btIz4+nhdffDFPPicnJ5YsWYKPjw/Hjh3jqaeewsnJialTp5bG4RFCFFWJLjMqhBAFKMoq6atWrVIrV65svr948WIVUM+dO2due/rpp1V7e3s1MTHR3Na3b1/16aefNt+vUaOG+sADD+Ta96hRo9QHH3xQVVVV3bRpk2owGNTLly+bH//zzz9VQF2zZk2B+T788EO1ZcuWhXovQojSJ2d2hBAW5++//2bOnDmcOnWKhIQEsrKySEtLIyUlBXt7ewDs7e0JCAgwP8fT0xM/Pz8cHR1ztV27di3Xvtu3b5/n/s0RWidPnsTX1xcfH58CtwdYsWIFCxYsIDQ0lKSkJLKysnB2dr7v9y2EKBnSZ0cIYVHOnz/PgAEDaNKkCb/99huHDh0y96vJyMgwb2dlZZXreYqi5NtmNBqLNd+ePXsYM2YM/fr1448//iAoKIg333wzVzYhhGWRMztCCIty6NAhjEYjH3/8MTqd6e+xlStXFtv+9+7dm+d+/fr1Aahfvz4XL17k6tWreHt757v97t27qVGjBm+++aa57cKFC8WWTwhR/KTYEUJoJj4+nuDg4Fxt7u7uZGZmsnDhQgYOHMiuXbv4+uuvi+01d+3axbx58xg8eDCbN29m1apVrF+/HoBevXpRp04dxo0bx4cffkhCQkKuogagdu3aREREsHz5clq3bs369etZs2ZNseUTQhQ/uYwlhNDMtm3baN68ea7bTz/9xPz58/nggw9o1KgRgYGBzJkzp9he8+WXX+bgwYM0b96c9957j/nz59O3b1/ANApszZo1pKam0qZNG5588klmz56d6/kPPfQQL730EpMmTaJZs2bs3r2bGTNmFFs+IUTxU1RVVbUOIYQQQghRUuTMjhBCCCHKNSl2hBBCCFGuSbEjhBBCiHJNih0hhBBClGtS7AghhBCiXJNiRwghhBDlmhQ7QgghhCjXpNgRQgghRLkmxY4QQgghyjUpdoQQQghRrkmxI4QQQohyTYodIYQQQpRr/w/55qBs+9qxEQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}